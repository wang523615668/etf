# pages/2_ğŸ“ˆ_Performance_Analysis.py (V22.1 - é£é™©ä¸æ”¶ç›Šè¯„ä¼°)

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import os
import sys
from datetime import datetime, timedelta

# --- å¯¼å…¥æ ¸å¿ƒæ•°æ®å’Œå‡½æ•° (ä¿æŒå¢å¼ºå¯¼å…¥å…¼å®¹æ€§) ---
try:
    # ----------------------------------------------------
    # V22.1 å¢å¼ºä¿®å¤ï¼šç¡®ä¿ Streamlit é¡µé¢èƒ½æ‰¾åˆ°çˆ¶ç›®å½•çš„æ¨¡å—
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.abspath(os.path.join(current_dir, '..'))
    if parent_dir not in sys.path:
        sys.path.insert(0, parent_dir)
    # ----------------------------------------------------
    
    # å¯¼å…¥ V22.0 dashboard æ¨¡å—ä¸­çš„å‡½æ•°
    from dashboard import TARGETS, load_state, get_metrics_from_csv, find_latest_data_file
except ImportError:
    st.error("æ— æ³•å¯¼å…¥ dashboard.pyã€‚è¯·ç¡®ä¿æ‚¨çš„æ–‡ä»¶ç»“æ„æ­£ç¡®ï¼Œä¸” dashboard.py å­˜åœ¨äºé¡¹ç›®æ ¹ç›®å½•ã€‚")
    st.stop()

st.set_page_config(page_title="æŒ‡æ•°æ€§èƒ½åˆ†æ", layout="wide", page_icon="ğŸ“ˆ")

# ========================= æ–°å¢ï¼šé£é™©ä¸æ”¶ç›Šè®¡ç®—å‡½æ•° (V22.1) =========================

def calculate_cagr(start_price, end_price, days):
    """è®¡ç®—å¤åˆå¹´å‡å¢é•¿ç‡ (CAGR)ã€‚"""
    if days == 0 or start_price == 0:
        return np.nan
    years = days / 365.25
    cagr = (end_price / start_price)**(1 / years) - 1
    return cagr

def calculate_max_drawdown(series):
    """è®¡ç®—æœ€å¤§å›æ’¤ (Max Drawdown)ã€‚"""
    if series.empty:
        return 0.0
    # è®¡ç®—ç´¯è®¡æœ€å¤§å€¼ (å³°å€¼)
    cumulative_max = series.cummax()
    # è®¡ç®—å›æ’¤ (å½“å‰å€¼ / ç´¯è®¡æœ€å¤§å€¼) - 1
    drawdown = (series / cumulative_max) - 1
    # æ‰¾å‡ºæœ€å¤§å›æ’¤
    max_drawdown = drawdown.min()
    return max_drawdown

# ========================= è¾…åŠ©æ•°æ®å¤„ç† (ä¿æŒ V20.0 åŸºç¡€é€»è¾‘) =========================

@st.cache_data(ttl=3600)
def load_all_index_data():
    """åŠ è½½æ‰€æœ‰æŒ‡æ•°çš„æ”¶ç›˜ä»·æ•°æ®ï¼Œå¹¶ç»Ÿä¸€å¤„ç†ï¼Œç”¨äºæ€§èƒ½å¯¹æ¯”ã€‚"""
    
    st.info("ğŸ”„ æ­£åœ¨åŠ è½½æ‰€æœ‰æŒ‡æ•°æ•°æ®å¹¶è¿›è¡Œç»Ÿä¸€å¤„ç†ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    data_dict = {}
    
    # ... (åŠ è½½å’Œåˆå¹¶æ•°æ®é€»è¾‘ï¼Œä¿æŒä¸å˜) ...
    for fixed_filename_key, name in TARGETS.items():
        prefix = fixed_filename_key.split('.')[0]
        actual_file_path, _, _ = find_latest_data_file(prefix)
        
        if actual_file_path and os.path.exists(actual_file_path):
            try:
                metrics_result = get_metrics_from_csv(actual_file_path)
                if metrics_result:
                    df = metrics_result[5]
                    df = df.rename(columns={'Date': 'date', 'Close': 'close'})
                    df['date'] = pd.to_datetime(df['date'], errors='coerce')
                    df['close'] = pd.to_numeric(df['close'], errors='coerce')
                    df = df.dropna(subset=['date', 'close']).set_index('date').sort_index()

                    data_dict[name] = df['close']

            except Exception as e:
                st.warning(f"åŠ è½½ {name} çš„æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                
    if not data_dict:
        st.error("æ— æ³•åŠ è½½ä»»ä½•æŒ‡æ•°æ•°æ®ã€‚è¯·æ£€æŸ¥ DATA_DIR å’Œ CSV æ–‡ä»¶ã€‚")
        return None

    combined_index = pd.Index([])
    for series in data_dict.values():
        combined_index = combined_index.union(series.index)
        
    combined_df = pd.DataFrame(index=combined_index)
    for name, series in data_dict.items():
        combined_df[name] = series
        
    combined_df = combined_df.ffill() 
    
    st.success(f"âœ… å·²æˆåŠŸåŠ è½½ {len(data_dict)} ä¸ªæŒ‡æ•°æ•°æ®ã€‚")
    return combined_df

def calculate_relative_return(df, start_date):
    """è®¡ç®—ä»èµ·å§‹æ—¥æœŸå¼€å§‹çš„ç›¸å¯¹æ”¶ç›Šç‡ (åŸºå‡†åŒ–ä¸º1)ã€‚"""
    
    df_filtered = df[df.index >= start_date].copy()
    
    if df_filtered.empty:
        return pd.DataFrame()
        
    initial_values = df_filtered.iloc[0].replace(0, np.nan).dropna()
    
    if initial_values.empty:
        return pd.DataFrame()

    relative_returns = df_filtered.div(initial_values, axis=1)
    
    return relative_returns

# ========================= Streamlit App =========================

def app():
    st.header("ğŸ“ˆ æŒ‡æ•°æ€§èƒ½åˆ†æ (æ¨ªå‘å¯¹æ¯”)")
    st.markdown("---")

    combined_df = load_all_index_data()

    if combined_df is None or combined_df.empty:
        st.warning("æ•°æ®åŠ è½½å¤±è´¥æˆ–æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
        return
        
    # --- 1. ç”¨æˆ·é€‰æ‹© ---
    st.subheader("é€‰æ‹©åˆ†æå‚æ•°")
    
    col_index_select, col_date_select, col_period_select = st.columns([2, 1, 1])
    
    # 1.1 æŒ‡æ•°é€‰æ‹©
    index_names = list(combined_df.columns)
    default_selection = index_names[:5] if len(index_names) >= 5 else index_names
    
    with col_index_select:
        selected_indices = st.multiselect(
            "é€‰æ‹©è¦å¯¹æ¯”çš„æŒ‡æ•° (æœ€å¤š10ä¸ª):",
            index_names,
            default=default_selection,
            max_selections=10
        )
        
    if not selected_indices:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæŒ‡æ•°è¿›è¡Œåˆ†æã€‚")
        return

    # 2.1 èµ·å§‹æ—¥æœŸé€‰æ‹©
    min_date = combined_df.index.min().date()
    max_date = combined_df.index.max().date()
    default_start_date = max_date - timedelta(days=365) # é»˜è®¤ä»ä¸€å¹´å‰å¼€å§‹
    
    with col_date_select:
        start_date = st.date_input(
            "è‡ªå®šä¹‰èµ·å§‹æ—¥æœŸ:",
            value=default_start_date if default_start_date > min_date else min_date,
            min_value=min_date,
            max_value=max_date
        )

    # 2.2 é¢„è®¾å‘¨æœŸé€‰æ‹©
    with col_period_select:
        period_options = {
            "è‡ªå®šä¹‰æ—¥æœŸ": None, "æœ€è¿‘ä¸€å¹´": 365, "æœ€è¿‘ä¸‰å¹´": 365*3, 
            "æœ€è¿‘äº”å¹´": 365*5, "å¹´åˆè‡³ä»Š (YTD)": 0
        }
        selected_period_label = st.selectbox("æˆ–é€‰æ‹©é¢„è®¾å‘¨æœŸ:", list(period_options.keys()))
        
        if selected_period_label != "è‡ªå®šä¹‰æ—¥æœŸ":
            days = period_options[selected_period_label]
            if days is not None:
                if days == 0: # YTD
                    start_date = datetime(max_date.year, 1, 1).date()
                else:
                    start_date = max_date - timedelta(days=days)
                    start_date = start_date.date()
            
            col_date_select.date_input(
                "è‡ªå®šä¹‰èµ·å§‹æ—¥æœŸ:", 
                value=start_date, 
                min_value=min_date, 
                max_value=max_date, 
                key='fixed_date_view'
            )
            
    start_dt = datetime.combine(start_date, datetime.min.time())
    
    # --- 2. è®¡ç®—ç›¸å¯¹æ”¶ç›Šç‡ ---
    df_subset = combined_df[selected_indices]
    df_returns = calculate_relative_return(df_subset, start_dt)

    if df_returns.empty:
        st.error(f"åœ¨ {start_date.strftime('%Y-%m-%d')} ä¹‹åæ²¡æœ‰æœ‰æ•ˆæ•°æ®ï¼Œè¯·è°ƒæ•´èµ·å§‹æ—¥æœŸã€‚")
        return

    st.markdown("---")
    
    # --- 3. æ€§èƒ½èµ°åŠ¿å›¾ (ä¿æŒä¸å˜) ---
    st.subheader(f"1. ğŸ’° æ”¶ç›Šç‡èµ°åŠ¿å¯¹æ¯” ({start_date.strftime('%Y-%m-%d')} è‡³ä»Š)")
    
    fig = px.line(
        df_returns.reset_index(), 
        x='index', 
        y=df_returns.columns, 
        title='æ ‡å‡†åŒ–æ”¶ç›Šç‡èµ°åŠ¿ (èµ·å§‹ç‚¹ä¸º 1.0)'
    )
    
    fig.update_layout(
        xaxis_title="æ—¥æœŸ",
        yaxis_title="ç›¸å¯¹æ”¶ç›Šç‡ (åŸºå‡†åŒ– 1.0)",
        legend_title="æŒ‡æ•°",
        height=600,
        hovermode="x unified"
    )
    st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    
    # --- 4. æ±‡æ€»è¡¨æ ¼ (V22.1: æ·»åŠ  CAGR å’Œ Max Drawdown) ---
    st.subheader("2. ğŸ“Š æ€§èƒ½æ±‡æ€» (é£é™©ä¸æ”¶ç›Š)")
    
    # è®¡ç®—ç»å¯¹æ”¶ç›Šç‡ (Total Return)
    last_row = df_returns.iloc[-1]
    start_row = df_returns.iloc[0] # æ ‡å‡†åŒ–ä¸º 1.0
    
    total_returns = (last_row - 1) * 100
    
    # è®¡ç®— Max Drawdown å’Œ CAGR
    max_drawdowns = {}
    cagr_results = {}
    
    # è®¡ç®—å‘¨æœŸå¤©æ•°
    delta_days = (df_returns.index.max() - df_returns.index.min()).days
    
    for index_name in selected_indices:
        # ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ”¶ç›Šç‡æ›²çº¿è®¡ç®—æœ€å¤§å›æ’¤
        max_drawdowns[index_name] = calculate_max_drawdown(df_returns[index_name]) * 100
        
        # ä½¿ç”¨èµ·å§‹å’Œç»“æŸæ—¶çš„æ ‡å‡†åŒ–ä»·æ ¼è®¡ç®— CAGR
        start_val = start_row[index_name] 
        end_val = last_row[index_name]
        cagr_results[index_name] = calculate_cagr(start_val, end_val, delta_days) * 100
        
    summary_data = {
        "æŒ‡æ•°åç§°": selected_indices,
        "æ€»æ”¶ç›Š (%)": total_returns.values,
        "å¹´åŒ–æ”¶ç›Šç‡ (CAGR %)": [cagr_results.get(name) for name in selected_indices],
        "æœ€å¤§å›æ’¤ (Max Drawdown %)": [max_drawdowns.get(name) for name in selected_indices]
    }
    
    df_summary = pd.DataFrame(summary_data).set_index('æŒ‡æ•°åç§°')
    
    # æ ¼å¼åŒ–è¡¨æ ¼æ˜¾ç¤º
    def highlight_max_min(s):
        # çªå‡ºæ˜¾ç¤º CAGR å’Œæ€»æ”¶ç›Šçš„ Max/Minï¼Œä»¥åŠ Max Drawdown çš„ Min (æœ€å°å›æ’¤å³è¡¨ç°æœ€å¥½)
        if s.name in ["æ€»æ”¶ç›Š (%)", "å¹´åŒ–æ”¶ç›Šç‡ (CAGR %)"]:
            is_extreme = s == s.max()
        elif s.name == "æœ€å¤§å›æ’¤ (Max Drawdown %)":
             is_extreme = s == s.max() # æœ€å¤§å›æ’¤è¶Šå°è¶Šå¥½ï¼Œä½†è¿™é‡Œçªå‡ºæœ€å¤§çš„è´Ÿæ•°ï¼ˆæœ€å·®è¡¨ç°ï¼‰
        else:
             is_extreme = pd.Series([False] * len(s), index=s.index)

        return [
            'background-color: #d4edda; font-weight: bold' if v else ''
            for v in is_extreme
        ]

    st.dataframe(
        df_summary.style.format("{:.2f}").apply(highlight_max_min, axis=0),
        use_container_width=True
    )
    
    st.markdown("---")


if __name__ == "__main__":
    app()
