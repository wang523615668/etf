# pages/9_ğŸ“‚_Data_Manager.py (V25.19 - ä¿®å¤åˆ—åå†²çª+å¼ºåŠ›å»é‡)

import streamlit as st
import pandas as pd
import os
import time
import glob
from datetime import datetime

# ================= é…ç½® =================
DATA_DIR = "index_data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# ç›®æ ‡æŒ‡æ•°åˆ—è¡¨ (åŒ¹é…è§„åˆ™)
TARGETS_MAP = {
    "ä¸­è¯å…¨æŒ‡.csv": ["ä¸­è¯å…¨æŒ‡", "000985", "å…¨A"],
    "æ²ªæ·±300.csv": ["æ²ªæ·±300", "000300"],
    "ä¸­è¯500.csv": ["ä¸­è¯500", "000905"],
    "ä¸Šè¯50.csv": ["ä¸Šè¯50", "000016"],
    "åˆ›ä¸šæ¿æŒ‡.csv": ["åˆ›ä¸šæ¿", "399006"],
    
    "å…¨æŒ‡åŒ»è¯.csv": ["å…¨æŒ‡åŒ»è¯", "åŒ»è¯å«ç”Ÿ", "000991", "åŒ»è¯"],
    "å…»è€äº§ä¸š.csv": ["å…»è€", "399812"],
    "ä¸­è¯çº¢åˆ©.csv": ["çº¢åˆ©", "000922"],
    "ä¸­è¯ç¯ä¿.csv": ["ç¯ä¿", "000827"],
    "ä¸­è¯ä¼ åª’.csv": ["ä¼ åª’", "399971"],
    "å…¨æŒ‡é‡‘è.csv": ["å…¨æŒ‡é‡‘è", "é‡‘è", "000992"],
    "è¯åˆ¸å…¬å¸.csv": ["è¯åˆ¸", "399975"],
    "å…¨æŒ‡æ¶ˆè´¹.csv": ["å…¨æŒ‡æ¶ˆè´¹", "å¯é€‰æ¶ˆè´¹", "000990", "æ¶ˆè´¹"],
    "å…¨æŒ‡ä¿¡æ¯.csv": ["å…¨æŒ‡ä¿¡æ¯", "ä¿¡æ¯æŠ€æœ¯", "000993", "ä¿¡æ¯"],
    "ä¸­è¯åŒ»ç–—.csv": ["åŒ»ç–—", "399989"],
    "ä¸­è¯ç™½é…’.csv": ["ç™½é…’", "399997"],
}

st.set_page_config(page_title="æ•°æ®ç»´æŠ¤åå°", page_icon="ğŸ“‚", layout="wide")

st.title("ğŸ“‚ ç¦»çº¿æ•°æ®ç»´æŠ¤ä¸­å¿ƒ")
st.info("ğŸ’¡ ä¿®å¤ç‰ˆ V25.19ï¼šè§£å†³äº†åˆ—åå†²çªï¼ˆDataFrame object has no attribute dtypeï¼‰é—®é¢˜ã€‚")
st.markdown("---")

# ================= åŠŸèƒ½1ï¼šæ‹–æ‹½ä¸Šä¼ ä¸è‡ªåŠ¨å½’æ¡£ =================
st.subheader("ğŸ“¤ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ–°æ•°æ®")

uploaded_files = st.file_uploader("æ‹–å…¥æ–‡ä»¶ (æ”¯æŒå¤šé€‰)", type=['csv'], accept_multiple_files=True)

if uploaded_files:
    success_count = 0
    fail_count = 0
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, file in enumerate(uploaded_files):
        # 1. åŒ¹é…æ–‡ä»¶å
        matched_target = None
        for target_filename, keywords in TARGETS_MAP.items():
            for kw in keywords:
                if kw in file.name:
                    matched_target = target_filename
                    break
            if matched_target: break
        
        status_text.text(f"æ­£åœ¨å¤„ç†: {file.name} ...")
        
        if matched_target:
            try:
                # å°è¯•è¯»å– (å…¼å®¹ä¸åŒç¼–ç )
                try:
                    df = pd.read_csv(file, encoding='utf-8')
                except:
                    file.seek(0)
                    df = pd.read_csv(file, encoding='gbk')
                
                # 2. æ™ºèƒ½åˆ—åæ˜ å°„
                rename_dict = {}
                for col in df.columns:
                    c = str(col).lower()
                    if "date" in c or "æ—¥æœŸ" in c: rename_dict[col] = "Date"
                    elif "pe" in c or "å¸‚ç›ˆç‡" in c: 
                        if "åˆ†ä½" not in c: rename_dict[col] = "pe"
                    elif "åˆ†ä½" in c: rename_dict[col] = "pe_percentile"
                    elif "close" in c or "æ”¶ç›˜" in c or "ç‚¹ä½" in c: rename_dict[col] = "Close"
                
                df = df.rename(columns=rename_dict)
                
                # 3. âš ï¸ æ ¸å¿ƒä¿®å¤ï¼šç«‹å³å»é‡ï¼
                # é˜²æ­¢æœ‰å¤šä¸ªåˆ—éƒ½è¢«å‘½åä¸º 'pe'ï¼Œå¯¼è‡´ df['pe'] è¿”å› DataFrame è€Œä¸æ˜¯ Series
                df = df.loc[:, ~df.columns.duplicated()]
                
                # 4. å¼ºåŠ›æ•°æ®æ¸…æ´—
                if "Date" in df.columns and "pe" in df.columns:
                    
                    # A. æ¸…æ´— Excel åƒåœ¾ç¬¦å· (="23.5", 1,000)
                    cols_to_clean = ['pe', 'Close', 'pe_percentile']
                    for col in cols_to_clean:
                        if col in df.columns: # å¿…é¡»å…ˆæ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
                            if df[col].dtype == object:
                                df[col] = df[col].astype(str).str.replace('=', '').str.replace('"', '').str.replace(',', '')
                            df[col] = pd.to_numeric(df[col], errors='coerce')
                    
                    # B. æ—¥æœŸå¼ºè½¬
                    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                    
                    # C. åˆ é™¤æ— æ•ˆè¡Œ (ç©ºæ—¥æœŸã€ç©ºPE)
                    df = df.dropna(subset=['Date', 'pe'])
                    
                    # D. æ ¼å¼åŒ–ä¸å»é‡
                    df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
                    df = df.sort_values("Date").drop_duplicates(subset=["Date"], keep='last')
                    
                    # 5. ä¿å­˜
                    save_path = os.path.join(DATA_DIR, matched_target)
                    df.to_csv(save_path, index=False, encoding='utf-8-sig')
                    
                    st.success(f"âœ… **{file.name}** -> è¯†åˆ«ä¸º **{matched_target}** (æ¸…æ´—åå‰©ä½™ {len(df)} æ¡)")
                    success_count += 1
                else:
                    st.error(f"âŒ {file.name}: ç¼ºå°‘å¿…è¦åˆ—ï¼Œè¯·æ£€æŸ¥æ˜¯å¦åŒ…å«'æ—¥æœŸ'å’Œ'PE'")
                    fail_count += 1
                    
            except Exception as e:
                st.error(f"âŒ {file.name}: å¤„ç†å¤±è´¥ - {str(e)}")
                fail_count += 1
        else:
            st.warning(f"âš ï¸ {file.name}: æ— æ³•è¯†åˆ«æ˜¯å“ªä¸ªæŒ‡æ•°ï¼Œæ–‡ä»¶åéœ€åŒ…å«å¦‚ 'ç™½é…’'ã€'æ²ªæ·±300' ç­‰å…³é”®è¯")
            fail_count += 1
            
        progress_bar.progress((i + 1) / len(uploaded_files))
    
    status_text.text("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼")
    if success_count > 0:
        st.balloons()
        time.sleep(2)
        st.rerun()

# ================= åŠŸèƒ½2ï¼šçŠ¶æ€ç›‘æ§ =================
st.markdown("---")
st.subheader("ğŸ“Š æ•°æ®çŠ¶æ€ä¸€è§ˆ")

status_data = []
now = datetime.now()

for filename in TARGETS_MAP.keys():
    file_path = os.path.join(DATA_DIR, filename)
    index_name = filename.replace(".csv", "")
    
    status = "âŒ ç¼ºå¤±"
    data_date_str = "â€”"
    
    if os.path.exists(file_path):
        try:
            # å¿«é€Ÿè¯»å–æ£€æŸ¥
            df_check = pd.read_csv(file_path)
            if not df_check.empty and 'Date' in df_check.columns:
                last_date_val = df_check['Date'].iloc[-1]
                last_date = pd.to_datetime(last_date_val)
                data_date_str = last_date.strftime("%Y-%m-%d")
                days_lag = (now - last_date).days
                
                if days_lag <= 7: status = "ğŸŸ¢ æ–°é²œ"
                elif days_lag <= 30: status = "ğŸŸ¡ è¾ƒæ—§"
                else: status = f"ğŸ”´ è¿‡æœŸ ({days_lag}å¤©)"
            else:
                status = "âšª ç©ºæ–‡ä»¶"
        except:
            status = "âŒ æŸå"

    status_data.append({
        "æŒ‡æ•°": index_name,
        "çŠ¶æ€": status,
        "æœ€æ–°æ—¥æœŸ": data_date_str
    })

st.dataframe(
    pd.DataFrame(status_data).style.applymap(
        lambda v: 'background-color: #ffe6e6' if 'ğŸ”´' in str(v) or 'âŒ' in str(v) else 
                 ('background-color: #e6fffa' if 'ğŸŸ¢' in str(v) else ''), 
        subset=['çŠ¶æ€']
    ),
    use_container_width=True,
    height=600
)
