import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import time
import os
import json
import re
from io import BytesIO, StringIO
from datetime import datetime, timedelta

# ==================== 1. é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="æ™ºèƒ½èµ„äº§é…ç½® Pro (å…¨æ™¯å›¾å®šåˆ¶ç‰ˆ)",
    page_icon="ğŸ’¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== 2. å…¨å±€é…ç½® ====================
DEFAULT_TOKEN = "71f8bc4a-2a8c-4a38-bc43-4bede4dba831"
TOKEN_FILE = "token.conf"
CUSTOM_INDEX_FILE = "custom_indices.json" 
TRADE_RECORD_FILE = "trade_records.json" 

MARKET_INDEX_CODE = "000985" 
MARKET_INDEX_NAME = "Aè‚¡å…¨æŒ‡"

DEFAULT_INDEX_MAP = {
    "æ²ªæ·±300": "000300", "ä¸Šè¯50": "000016", "ä¸­è¯500": "000905", "åˆ›ä¸šæ¿æŒ‡": "399006",
    "ç§‘åˆ›50": "000688", "ä¸­è¯çº¢åˆ©": "000922", "ä¸­è¯ç™½é…’": "399997", "ä¸­è¯åŒ»ç–—": "399989", 
    "ä¸­è¯ä¼ åª’": "399971", "è¯åˆ¸å…¬å¸": "399975", "ä¸­è¯é“¶è¡Œ": "399986", "ä¸­è¯ç¯ä¿": "000827", 
    "å…¨æŒ‡æ¶ˆè´¹": "000990", "å…¨æŒ‡åŒ»è¯": "000991", "å…¨æŒ‡é‡‘è": "000992", "å…¨æŒ‡ä¿¡æ¯": "000993", 
    "å…»è€äº§ä¸š": "399812"
}

DATA_DIR = "market_data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# ==================== 3. åŸºç¡€å‡½æ•°åº“ ====================
def load_all_indices():
    indices = DEFAULT_INDEX_MAP.copy()
    if os.path.exists(CUSTOM_INDEX_FILE):
        try:
            with open(CUSTOM_INDEX_FILE, "r", encoding='utf-8') as f:
                indices.update(json.load(f))
        except: pass
    return indices

def save_custom_index(name, code):
    current = {}
    if os.path.exists(CUSTOM_INDEX_FILE):
        try:
            with open(CUSTOM_INDEX_FILE, "r", encoding='utf-8') as f:
                current = json.load(f)
        except: pass
    current[name] = code
    with open(CUSTOM_INDEX_FILE, "w", encoding='utf-8') as f:
        json.dump(current, f, ensure_ascii=False, indent=4)

def load_trade_records():
    if os.path.exists(TRADE_RECORD_FILE):
        try:
            with open(TRADE_RECORD_FILE, "r", encoding='utf-8') as f:
                return json.load(f)
        except: return []
    return []

def save_trade_record(date, op, idx):
    recs = load_trade_records()
    recs.append({"æ—¥æœŸ": date, "æ“ä½œç±»å‹": op, "æŒ‡æ•°": idx, "timestamp": time.time()})
    with open(TRADE_RECORD_FILE, "w", encoding='utf-8') as f:
        json.dump(recs, f, ensure_ascii=False, indent=4)

INDEX_MAP = load_all_indices()

# ==================== 4. æ•°æ®è·å–æ ¸å¿ƒ ====================
def get_token():
    if os.path.exists(TOKEN_FILE):
        try:
            with open(TOKEN_FILE, "r") as f:
                t = f.read().strip()
                if len(t) > 5: return t
        except: pass
    return DEFAULT_TOKEN

def save_token(new_token):
    with open(TOKEN_FILE, "w") as f:
        f.write(new_token.strip())

def fetch_chunk(token, url, payload, start, end):
    p = payload.copy()
    p['startDate'] = start.strftime("%Y-%m-%d")
    p['endDate'] = end.strftime("%Y-%m-%d")
    try:
        r = requests.post(url, json=p, headers={'Content-Type': 'application/json'}, timeout=10)
        if r.json().get("code") == 1:
            return pd.DataFrame(r.json().get("data", []))
        return None
    except: return None

@st.cache_data(ttl=3600*4)
def fetch_bond_yield(token):
    url = "https://open.lixinger.com/api/cn/macro/bond/yield"
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)
    payload = {
        "token": token, "areaCode": "cn",
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "metricsList": ["tcm_y10"]
    }
    try:
        res = requests.post(url, json=payload, headers={'Content-Type': 'application/json'}, timeout=5)
        data = res.json().get("data", [])
        if data:
            df = pd.DataFrame(data)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date') 
            return df.iloc[-1]['tcm_y10'] * 100
    except: pass
    return None

@st.cache_data(ttl=3600*4)
def fetch_usd_cny(token):
    url = "https://open.lixinger.com/api/cn/macro/fx/quote"
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)
    payload = {
        "token": token,
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "fromCurrency": "USD", "toCurrency": "CNY"
    }
    try:
        res = requests.post(url, json=payload, headers={'Content-Type': 'application/json'}, timeout=5)
        data = res.json().get("data", [])
        if data:
            df = pd.DataFrame(data)
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date') 
            return df.iloc[-1]['close']
    except: pass
    return None

def fetch_incremental(token, code, years, local_df):
    end = datetime.now()
    start = datetime(2005, 1, 1) if years > 10 else end - timedelta(days=years * 365 + 60)
    
    if local_df is not None and not local_df.empty:
        if local_df.index[0] <= start + timedelta(30):
            start = local_df.index[-1] + timedelta(1)
        else: start = start 
    
    if start.date() > end.date(): return local_df, "latest"

    url_f = "https://open.lixinger.com/api/cn/index/fundamental"
    metrics = ["pe_ttm.ewpvo", "pe_ttm.median", "pb.median", "turnover_rate.ew"] 
    url_k = "https://open.lixinger.com/api/cn/index/candlestick"
    
    dfs_f, dfs_k = [], []
    curr = start
    while curr < end:
        next_end = min(curr + timedelta(3000), end)
        f_chunk = fetch_chunk(token, url_f, {"token": token, "stockCodes": [code], "metricsList": metrics}, curr, next_end)
        k_chunk = fetch_chunk(token, url_k, {"token": token, "stockCode": code, "type": "normal", "qType": "1d"}, curr, next_end)
        if f_chunk is not None: dfs_f.append(f_chunk)
        if k_chunk is not None: dfs_k.append(k_chunk)
        curr = next_end + timedelta(1)
        time.sleep(0.05)

    if not dfs_f: return local_df, "no_data"
    
    df_f = pd.concat(dfs_f).drop_duplicates('date')
    df_f['date'] = pd.to_datetime(df_f['date']).dt.tz_localize(None)
    df_f = df_f.set_index('date').sort_index()
    
    df_new = df_f
    if dfs_k:
        df_k = pd.concat(dfs_k).drop_duplicates('date')
        df_k['date'] = pd.to_datetime(df_k['date']).dt.tz_localize(None)
        df_k = df_k.set_index('date')[['close']] 
        df_new = df_f.join(df_k, how='inner')
    else:
        df_new['close'] = None

    cols = {
        "pe_ttm.ewpvo": "PE_æ­£æ•°ç­‰æƒ", "pe_ttm.median": "PE_ä¸­ä½æ•°", 
        "pb.median": "PB_ä¸­ä½æ•°", "turnover_rate.ew": "æ¢æ‰‹ç‡",
        "close": "æŒ‡æ•°ç‚¹ä½"
    }
    df_new = df_new.rename(columns=cols)
    for c in cols.values(): 
        if c in df_new: df_new[c] = pd.to_numeric(df_new[c], errors='coerce')

    if local_df is not None:
        df_new = df_new[~df_new.index.isin(local_df.index)]
        return pd.concat([local_df, df_new]).sort_index(), "updated"
    return df_new, "new"

def get_smart_data(token, code, years, force):
    name = "æœªçŸ¥"
    if code == MARKET_INDEX_CODE: name = MARKET_INDEX_NAME
    else: 
        matches = [k for k, v in INDEX_MAP.items() if v == code]
        if matches: name = matches[0]
            
    path = os.path.join(DATA_DIR, f"{name}_{code}.csv")
    local = None
    if os.path.exists(path):
        try: 
            local = pd.read_csv(path)
            local['date'] = pd.to_datetime(local['date'])
            local = local.set_index('date').sort_index()
        except: local = None

    is_sufficient = False
    req_start = datetime(2005, 1, 1) if years > 10 else datetime.now() - timedelta(days=years * 365 + 30)
    if local is not None and not local.empty:
        if local.index[0] <= req_start + timedelta(days=30):
            is_sufficient = True

    is_fresh = False
    if local is not None and not local.empty:
        if local.index[-1].strftime("%Y-%m-%d") == datetime.now().strftime("%Y-%m-%d"):
            is_fresh = True
    
    if is_fresh and is_sufficient and not force: return local, "cache"

    df, status = fetch_incremental(token, code, years, local)
    
    if df is not None and not df.empty:
        try: df.to_csv(path, encoding='utf-8-sig')
        except: pass
        return df, status
        
    return local_df, "no_action"

# ==================== 5. æ ¸å¿ƒæ‰“åˆ†å¼•æ“ (æ··åˆç­–ç•¥) ====================
def calc_indicators(df):
    if df is None or len(df) < 30: return df
    close = df['æŒ‡æ•°ç‚¹ä½']
    df['BBI'] = (close.rolling(3).mean() + close.rolling(6).mean() + close.rolling(12).mean() + close.rolling(24).mean()) / 4
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    df['DIF'] = ema12 - ema26
    df['DEA'] = df['DIF'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = (df['DIF'] - df['DEA']) * 2
    return df

def resample_weekly(df):
    if df is None: return None
    return df.resample('W-FRI').last().dropna()

def calculate_score(df_day, lookback, bond_yield=None):
    if df_day is None or df_day.empty: return None
    
    latest = df_day.iloc[-1]
    pe_cur = latest.get("PE_æ­£æ•°ç­‰æƒ", 0)
    pb_cur = latest.get("PB_ä¸­ä½æ•°", 0)
    pe_med_cur = latest.get("PE_ä¸­ä½æ•°", 0)
    to_cur = latest.get("æ¢æ‰‹ç‡", 0)
    
    start_dt = datetime(2005,1,1) if lookback > 10 else df_day.index[-1] - timedelta(days=lookback*365)
    hist = df_day[df_day.index >= start_dt]
    
    if hist.empty: return None

    pe_pct = (hist["PE_æ­£æ•°ç­‰æƒ"] < pe_cur).mean() * 100
    pb_pct = (hist["PB_ä¸­ä½æ•°"] < pb_cur).mean() * 100
    to_pct = (hist["æ¢æ‰‹ç‡"] < to_cur).mean() * 100 if "æ¢æ‰‹ç‡" in hist else 50
    
    df_5y = df_day.iloc[-1250:] if len(df_day) > 1250 else df_day
    df_10y = df_day.iloc[-2500:] if len(df_day) > 2500 else df_day
    pe_avg_5y = df_5y["PE_æ­£æ•°ç­‰æƒ"].mean()
    pe_avg_10y = df_10y["PE_æ­£æ•°ç­‰æƒ"].mean()
    
    dev_5y = (pe_cur - pe_avg_5y) / pe_avg_5y * 100 if pe_avg_5y else 0
    dev_10y = (pe_cur - pe_avg_10y) / pe_avg_10y * 100 if pe_avg_10y else 0
    
    df_week = resample_weekly(df_day.copy())
    df_week = calc_indicators(df_week)
    wk_now = df_week.iloc[-1] if len(df_week) >= 2 else None
    
    score = 0
    reasons = []
    
    if pe_pct <= 10: score += 60; reasons.append("ğŸ’ æä½ä¼°")
    elif pe_pct <= 20: score += 50; reasons.append("ğŸŸ¢ ä½ä¼°")
    elif pe_pct <= 40: score += 30
    elif pe_pct >= 80: score -= 30; reasons.append("âš ï¸ é«˜ä¼°")
    elif pe_pct >= 60: score -= 10
        
    if wk_now is not None:
        if wk_now['æŒ‡æ•°ç‚¹ä½'] > wk_now['BBI']: score += 20; reasons.append("ğŸ“ˆ è¶‹åŠ¿å¥½")
        if wk_now['DIF'] > wk_now['DEA']: score += 10; reasons.append("ğŸ”¥ é‡‘å‰")
            
    erp = 0
    if bond_yield and pe_cur > 0:
        erp = (1/pe_cur*100) - bond_yield
        if erp > 3.0: score += 10; reasons.append(f"ğŸ’° èµ”ç‡é«˜")
            
    if to_pct < 10: score += 5
    if to_pct > 90: score -= 5

    signal = "âš–ï¸ è§‚æœ›"
    if score >= 85: signal = "ğŸš€ è¶‹åŠ¿å…±æŒ¯"
    elif score >= 60: signal = "ğŸ“‰ å·¦ä¾§å»ºä»“"
    elif score <= 20: signal = "â„ï¸ å‡ä»“/å›é¿"
    
    return {
        "å½“å‰ç‚¹ä½": latest.get("æŒ‡æ•°ç‚¹ä½", 0),
        "PE": pe_cur, "PEåˆ†ä½": pe_pct, 
        "PB": pb_cur, "PBåˆ†ä½": pb_pct,
        "5å¹´å‡PE": pe_avg_5y, "10å¹´å‡PE": pe_avg_10y, "PE(ä¸­ä½)": pe_med_cur,
        "åç¦»5å¹´": dev_5y, "åç¦»10å¹´": dev_10y,
        "æ€»åˆ†": score, "ä¿¡å·": signal, "ç†ç”±": " | ".join(reasons)
    }

def scan_market_with_score(token, indices, lookback, force, bond_yield):
    res = []
    prog = st.progress(0)
    msg = st.empty()
    
    for i, (name, code) in enumerate(indices.items()):
        msg.text(f"æ­£åœ¨åˆ†æ: {name} (å‘¨æœŸ{lookback}å¹´)...")
        prog.progress((i)/len(indices))
        df, _ = get_smart_data(token, code, lookback, force)
        
        if df is not None:
            s = calculate_score(df, lookback, bond_yield)
            if s:
                res.append({
                    "æŒ‡æ•°": name, "ä»£ç ": code,
                    "å¾—åˆ†": s['æ€»åˆ†'], "å†³ç­–": s['ä¿¡å·'],
                    "å½“å‰PE": s['PE'], "PEåˆ†ä½": s['PEåˆ†ä½'],
                    "5å¹´å‡PE": s['5å¹´å‡PE'], "10å¹´å‡PE": s['10å¹´å‡PE'], "PE(ä¸­ä½)": s['PE(ä¸­ä½)'],
                    "åç¦»5å¹´(%)": s['åç¦»5å¹´'], "åç¦»10å¹´(%)": s['åç¦»10å¹´'],
                    "PB(ä¸­ä½)": s['PB'], "PBåˆ†ä½": s['PBåˆ†ä½'],
                    "åˆ†æ": s['ç†ç”±']
                })
        time.sleep(0.02)
        
    prog.empty()
    msg.empty()
    return pd.DataFrame(res)

# ==================== 6. ä¸»ç•Œé¢ ====================
def main():
    st.title("ğŸ›¡ï¸ æ™ºèƒ½èµ„äº§é…ç½® Pro (å…¨èƒ½ä¿®æ­£ç‰ˆ)")
    
    # âœ… 1. ä¼šè¯çŠ¶æ€ç®¡ç†ï¼šä¿å­˜ä¸Šä¼ /ç²˜è´´çš„äº¤æ˜“è®°å½•
    if 'uploaded_trades' not in st.session_state:
        st.session_state['uploaded_trades'] = pd.DataFrame()
    if 'force' not in st.session_state: st.session_state['force'] = False

    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶å°")
        
        # âœ… åŠŸèƒ½1ï¼šæ›´æ¢ Token
        with st.expander("ğŸ”‘ API Token ç®¡ç†", expanded=False):
            current_token = get_token()
            masked = current_token[:4] + "*"*10 + current_token[-4:] if len(current_token)>10 else "æœªé…ç½®"
            st.text(f"å½“å‰: {masked}")
            new_token_input = st.text_input("è¾“å…¥æ–° Token", type="password")
            if st.button("ğŸ’¾ ä¿å­˜ Token"):
                if len(new_token_input) > 10:
                    save_token(new_token_input)
                    st.success("å·²ä¿å­˜ï¼Œè¯·åˆ·æ–°")
                    time.sleep(1)
                    st.rerun()
                else: st.error("Token æ— æ•ˆ")

        # âœ… ä¿®æ­£ï¼šé»˜è®¤å›æº¯å‘¨æœŸæ”¹ä¸º12å¹´
        lookback = st.slider("ä¼°å€¼å‚è€ƒå‘¨æœŸ(å¹´)", 3, 20, 12)
        
        if 'last_lookback' not in st.session_state:
            st.session_state['last_lookback'] = lookback
        if st.session_state['last_lookback'] != lookback:
            st.session_state['force'] = True
            st.session_state['last_lookback'] = lookback

        st.markdown("---")
        with st.expander("ğŸ“ æ‰‹å·¥è®°è´¦", expanded=False):
            rec_date = st.date_input("äº¤æ˜“æ—¥æœŸ")
            rec_idx = st.selectbox("äº¤æ˜“æŒ‡æ•°", list(INDEX_MAP.keys()))
            rec_op = st.selectbox("æ“ä½œ", ["ä¹°å…¥", "å–å‡º"])
            if st.button("ğŸ’¾ è®°å½•"):
                save_trade_record(rec_date.strftime("%Y-%m-%d"), rec_op, rec_idx)
                st.toast(f"å·²è®°å½•")

        with st.expander("â• æ·»åŠ æ–°æŒ‡æ•°", expanded=False):
            new_name = st.text_input("æŒ‡æ•°åç§°", placeholder="ä¾‹å¦‚: çº³æŒ‡100")
            new_code = st.text_input("æŒ‡æ•°ä»£ç ", placeholder="ä¾‹å¦‚: NDX")
            if st.button("ç¡®è®¤æ·»åŠ "):
                if new_name and new_code:
                    save_custom_index(new_name, new_code)
                    st.success(f"å·²æ·»åŠ  {new_name}")
                    time.sleep(1)
                    st.rerun()

        st.markdown("---")
        st.markdown("### ğŸŒ å®è§‚å¤©çœ¼")
        token = get_token()
        auto_bond = fetch_bond_yield(token)
        auto_usd = fetch_usd_cny(token)
        
        default_bond = auto_bond if auto_bond else 2.25
        default_usd = auto_usd if auto_usd else 7.00
        
        macro_bond = st.number_input("CN 10å¹´å›½å€º (%)", value=float(default_bond), step=0.01)
        macro_usd = st.number_input("USD/CNY æ±‡ç‡", value=float(default_usd), step=0.01)
        
        st.markdown("---")
        if st.button("ğŸ”„ å…¨é‡åˆ·æ–°æ•°æ®", type="primary"):
            st.session_state['force'] = True
            st.cache_data.clear()
            st.rerun()
            
        st.markdown("---")
        # âœ… åŠŸèƒ½2ï¼šäº¤æ˜“å¯¼å…¥ (å­˜å…¥ Session ç¡®ä¿ä¸ä¸¢)
        with st.expander("ğŸ“‚ äº¤æ˜“å¯¼å…¥ (Excel/CSV)", expanded=True):
            pasted = st.text_area("ç²˜è´´æ•°æ® (è‡ªåŠ¨ä¿å­˜åˆ°ä¼šè¯)", height=100)
            if st.button("ğŸ“¥ ç¡®è®¤ç²˜è´´"):
                if pasted:
                    try:
                        # å°è¯•å¤šç§è§£ææ–¹å¼
                        try:
                            # 1. æœ‰è¡¨å¤´
                            df_paste = pd.read_csv(StringIO(pasted), sep=None, engine='python')
                            # ç®€å•æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åƒæ—¥æœŸï¼Œå¦‚æœåƒï¼Œè¯´æ˜æ²¡è¡¨å¤´
                            if len(df_paste) > 0 and isinstance(df_paste.columns[0], str) and re.match(r'\d{4}', df_paste.columns[0]):
                                df_paste = pd.read_csv(StringIO(pasted), sep=None, engine='python', header=None)
                                df_paste.columns = ['æ—¥æœŸ', 'æ“ä½œç±»å‹', 'æŒ‡æ•°']
                        except:
                            # 2. å…œåº•æ— è¡¨å¤´
                            df_paste = pd.read_csv(StringIO(pasted), sep=None, engine='python', header=None)
                            df_paste.columns = ['æ—¥æœŸ', 'æ“ä½œç±»å‹', 'æŒ‡æ•°']
                            
                        st.session_state['uploaded_trades'] = df_paste
                        st.success(f"å·²åŠ è½½ {len(df_paste)} æ¡")
                    except Exception as e: st.error(f"å¤±è´¥: {e}")
            
            uploaded = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (è‡ªåŠ¨ä¿å­˜)", type=['xlsx','csv'])
            if uploaded:
                try:
                    try: df_up = pd.read_excel(uploaded)
                    except: 
                        uploaded.seek(0)
                        encs = ['utf-8', 'gbk', 'gb18030']
                        for enc in encs:
                            try:
                                uploaded.seek(0)
                                df_up = pd.read_csv(uploaded, encoding=enc, on_bad_lines='skip')
                                if df_up.shape[1]>1: break
                            except: continue
                    st.session_state['uploaded_trades'] = df_up
                except: pass
            
            # æ˜¾ç¤ºçŠ¶æ€
            if not st.session_state['uploaded_trades'].empty:
                st.caption(f"ğŸ’¾ å½“å‰ä¼šè¯å·²æš‚å­˜ {len(st.session_state['uploaded_trades'])} æ¡è®°å½•")
                if st.button("ğŸ’¾ æ°¸ä¹…ä¿å­˜åˆ°è´¦æœ¬æ–‡ä»¶"):
                    # å†™å…¥ JSON
                    new_recs = st.session_state['uploaded_trades'].to_dict('records')
                    curr = load_trade_records()
                    # æ¸…æ´—
                    clean_news = []
                    for r in new_recs:
                        cr = {}
                        for k,v in r.items():
                            k_s = str(k).strip()
                            if "æŒ‡æ•°" in k_s: cr["æŒ‡æ•°"]=str(v).strip()
                            elif "æ“ä½œ" in k_s: cr["æ“ä½œç±»å‹"]=str(v).strip()
                            elif "æ—¥æœŸ" in k_s: 
                                # å¼ºåˆ¶è½¬å­—ç¬¦ä¸²
                                if isinstance(v, (pd.Timestamp, datetime)):
                                    cr["æ—¥æœŸ"]=v.strftime("%Y-%m-%d")
                                else: cr["æ—¥æœŸ"]=str(v).strip()
                            else: cr[k_s] = v
                        if "æŒ‡æ•°" in cr: clean_news.append(cr)
                    
                    curr.extend(clean_news)
                    with open(TRADE_RECORD_FILE, "w", encoding='utf-8') as f:
                        json.dump(curr, f, ensure_ascii=False, indent=4)
                    st.success("ä¿å­˜æˆåŠŸï¼")

    force = st.session_state['force']

    # --- å®è§‚é¢æ¿ ---
    c1, c2, c3 = st.columns([1, 1, 2])
    with c1: 
        bond_delta = "å¹³ç¨³"
        if macro_bond > 3.0: bond_delta = "âš ï¸ åˆ©ç‡é«˜"
        elif macro_bond < 2.5: bond_delta = "ğŸ’§ æµåŠ¨æ€§å¥½"
        st.metric("æ— é£é™©åˆ©ç‡ (10Y)", f"{macro_bond:.2f}%", bond_delta, delta_color="inverse")
    with c2:
        usd_delta = "ç¨³å®š"
        if macro_usd > 7.3: usd_delta = "âš ï¸ æ±‡ç‡è´¬å€¼"
        st.metric("USD/CNY", f"{macro_usd:.4f}", usd_delta, delta_color="inverse")
    with c3:
        env_score = "ğŸŒ¤ï¸ å®è§‚ä¸­æ€§"
        if macro_bond < 2.6 and macro_usd < 7.3: env_score = "â˜€ï¸ å®è§‚é¡ºé£ (åˆ©å¤šæƒç›Š)"
        elif macro_bond > 3.2: env_score = "ğŸŒ§ï¸ å®è§‚é€†é£"
        st.info(f"**{env_score}** | æ··åˆç­–ç•¥ï¼šä½ä¼°ä¹°å…¥ï¼Œè¶‹åŠ¿åŠ ä»“")

    st.markdown("---")

    # --- âœ… å¤æ´»ï¼šå…¨æ™¯å·¡ç¤¼ (ä¸é™æ ¸å¿ƒï¼Œéå†æ‰€æœ‰) ---
    st.subheader("ğŸ¢ å…¨å¸‚åœºä¸­ä½æ•°ä¼°å€¼å·¡ç¤¼ (å…¨æ™¯å›¾)")
    with st.expander("ğŸ“Š ç‚¹å‡»å±•å¼€/æ”¶èµ· å…¨æ™¯å¯¹æ¯”å›¾", expanded=False):
        if st.button("ğŸš€ åŠ è½½å…¨æ™¯å¯¹æ¯” (æ‰€æœ‰æŒ‡æ•°)"):
            with st.spinner("æ­£åœ¨åŠ è½½å…¨å¸‚åœºæ•°æ®..."):
                fig_all = go.Figure()
                for name, code in INDEX_MAP.items():
                    df_tmp, _ = get_smart_data(token, code, lookback, False)
                    if df_tmp is not None and not df_tmp.empty:
                        fig_all.add_trace(go.Scatter(x=df_tmp.index, y=df_tmp["PE_ä¸­ä½æ•°"], name=name, line=dict(width=1.5)))
                
                # âœ… ä¿®æ­£ï¼šYè½´é”å®š
                fig_all.update_layout(height=600, title=f"å…¨å¸‚åœº PE(ä¸­ä½æ•°) èµ°åŠ¿å¯¹æ¯” ({lookback}å¹´)", template="plotly_white")
                fig_all.update_yaxes(range=[0, 90], dtick=5, title="PE (TTM) ä¸­ä½æ•°")
                
                st.plotly_chart(fig_all, use_container_width=True)

    st.markdown("---")

    # --- ç»¼åˆæ¦œå• (å…¨æŒ‡æ ‡) ---
    st.subheader(f"ğŸ“Š æœºä¼šæ‰«æ ({lookback}å¹´å‘¨æœŸ)")
    if 'scan_res' not in st.session_state or force:
        with st.spinner(f"æ­£åœ¨é‡ç®— {lookback} å¹´ç»´åº¦ä¼°å€¼åˆ†ä½..."):
            st.session_state['scan_res'] = scan_market_with_score(token, INDEX_MAP, lookback, force, macro_bond)
        st.session_state['force'] = False
    
    df_scan = st.session_state['scan_res']
    
    if not df_scan.empty:
        def style_df(df):
            def color_score(v):
                if v >= 85: return 'color: #2ECC71; font-weight: bold'
                if v >= 60: return 'color: #3498DB; font-weight: bold'
                if v <= 20: return 'color: #E74C3C'
                return 'color: #F39C12'
            def color_dev(v):
                if v > 0: return 'color: #E74C3C' 
                return 'color: #2ECC71' 
            
            return df.style.map(color_score, subset=['å¾—åˆ†'])\
                           .map(color_dev, subset=['åç¦»5å¹´(%)', 'åç¦»10å¹´(%)'])\
                           .format("{:.2f}", subset=['å½“å‰PE','5å¹´å‡PE','10å¹´å‡PE','PE(ä¸­ä½)','PB(ä¸­ä½)'])\
                           .format("{:.1f}", subset=['å¾—åˆ†','PEåˆ†ä½','PBåˆ†ä½'])\
                           .format("{:+.1f}%", subset=['åç¦»5å¹´(%)', 'åç¦»10å¹´(%)'])
        
        df_show = df_scan.sort_values("å¾—åˆ†", ascending=False)
        st.dataframe(
            style_df(df_show),
            column_config={
                "æŒ‡æ•°": st.column_config.TextColumn("æŒ‡æ•°", width="small", pinned=True),
                "å¾—åˆ†": st.column_config.NumberColumn("å¾—åˆ†", help="æ»¡åˆ†100"),
                "å†³ç­–": st.column_config.TextColumn("å»ºè®®", width="small"),
                "åˆ†æ": st.column_config.TextColumn("æ ¸å¿ƒé€»è¾‘", width="large"),
                "PEåˆ†ä½": st.column_config.NumberColumn("PEåˆ†ä½", format="%.1f%%"),
                "PBåˆ†ä½": st.column_config.NumberColumn("PBåˆ†ä½", format="%.1f%%"),
            }, use_container_width=True, height=500, hide_index=True
        )
    else:
        st.info("ğŸ‘ˆ è¯·ç‚¹å‡»åˆ·æ–°æŒ‰é’®")

    # --- æ·±åº¦é€è§† ---
    st.markdown("---")
    st.subheader("ğŸ” æ·±åº¦é€è§†")
    
    with st.expander("ğŸ› ï¸ ä¸ºä»€ä¹ˆä¹°å–ç‚¹æ²¡æ˜¾ç¤ºï¼Ÿç‚¹å‡»è‡ªæŸ¥", expanded=False):
        st.info("ğŸ’¡ ç³»ç»Ÿæ­£åœ¨å°è¯•æ¨¡ç³ŠåŒ¹é…æ‚¨çš„äº¤æ˜“è®°å½•...")
        st.write("1. **ç³»ç»Ÿå½“å‰é€‰ä¸­çš„æŒ‡æ•°åç§°**:", st.session_state.get('last_sel_name', 'æœªé€‰æ‹©'))
        if not st.session_state['uploaded_trades'].empty:
            sample_names = st.session_state['uploaded_trades'].iloc[:, 2].unique()[:10] 
            st.write("2. **æ‚¨ä¸Šä¼ æ–‡ä»¶ä¸­çš„æŒ‡æ•°åç§° (å‰10ä¸ª)**:", sample_names)
        else:
            st.write("2. **æ‚¨å°šæœªä¸Šä¼ æ–‡ä»¶æˆ–ç²˜è´´æ•°æ®**")

    c_sel, c_chart = st.columns([1, 3])
    with c_sel:
        sel_name = st.selectbox("é€‰æ‹©æŒ‡æ•°", list({MARKET_INDEX_NAME: MARKET_INDEX_CODE, **INDEX_MAP}.keys()))
        st.session_state['last_sel_name'] = sel_name
        period = st.radio("å‘¨æœŸ", ["æ—¥çº¿", "å‘¨çº¿"], horizontal=True)
        view_mode = st.radio("è§†å›¾æ¨¡å¼", ["ä¼°å€¼åˆ†æ (PE/PBé€šé“)", "æŠ€æœ¯åˆ†æ (è¶‹åŠ¿/ä¹°å–)"], index=0)
        
        code = MARKET_INDEX_CODE if sel_name == MARKET_INDEX_NAME else INDEX_MAP[sel_name]
        df_raw, _ = get_smart_data(token, code, lookback, False)
        
        if df_raw is not None:
            score_res = calculate_score(df_raw, lookback, macro_bond)
            if score_res:
                st.metric("ç»¼åˆå¾—åˆ†", f"{score_res['æ€»åˆ†']}", score_res['ä¿¡å·'])
                st.caption(f"å› å­: {score_res['ç†ç”±']}")
                st.divider()
                st.metric("å½“å‰PE", f"{score_res['PE']:.2f}", f"åˆ†ä½: {score_res['PEåˆ†ä½']:.1f}%")
                st.metric("5å¹´åç¦»", f"{score_res['åç¦»5å¹´']:+.1f}%", delta_color="inverse")
                st.metric("10å¹´åç¦»", f"{score_res['åç¦»10å¹´']:+.1f}%", delta_color="inverse")
                
    with c_chart:
        if df_raw is not None:
            df_plot = df_raw.copy()
            if period == "å‘¨çº¿": df_plot = resample_weekly(df_plot)
            df_plot = calc_indicators(df_plot)
            
            if "æŠ€æœ¯" in view_mode:
                fig = make_subplots(rows=3, cols=1, shared_xaxes=True, row_heights=[0.6, 0.2, 0.2], vertical_spacing=0.03,
                                    subplot_titles=(f"{sel_name} ä»·æ ¼ & BBI", "MACD", "æ¢æ‰‹ç‡"))
                
                # âœ… å®çº¿
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["æŒ‡æ•°ç‚¹ä½"], name="ä»·æ ¼", line=dict(color="#2C3E50", width=1.5)), row=1, col=1)
                if "BBI" in df_plot.columns:
                    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["BBI"], name="BBIå‡çº¿", line=dict(color="#8E44AD", width=1.5)), row=1, col=1)
                
                if "DIF" in df_plot.columns:
                    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["DIF"], name="DIF", line=dict(color="#E67E22", width=1), showlegend=False), row=2, col=1)
                    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["DEA"], name="DEA", line=dict(color="#3498DB", width=1), showlegend=False), row=2, col=1)
                    colors = ['#2ECC71' if v >= 0 else '#E74C3C' for v in df_plot["MACD_Hist"]]
                    fig.add_trace(go.Bar(x=df_plot.index, y=df_plot["MACD_Hist"], name="MACD", marker_color=colors, showlegend=False), row=2, col=1)

                if "æ¢æ‰‹ç‡" in df_plot.columns:
                    fig.add_trace(go.Area(x=df_plot.index, y=df_plot["æ¢æ‰‹ç‡"], name="æ¢æ‰‹ç‡", line=dict(color="#16A085", width=1), fill='tozeroy'), row=3, col=1)
            
            else:
                # ä¼°å€¼å›¾
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["PE_æ­£æ•°ç­‰æƒ"], name="PE(ç­‰æƒ)", line=dict(color="red", width=2)), secondary_y=False)
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["PE_ä¸­ä½æ•°"], name="PE(ä¸­ä½)", line=dict(color="orange", width=1.5)), secondary_y=False)
                
                window_5y = 250 * 5 if period == "æ—¥çº¿" else 52 * 5
                window_10y = 250 * 10 if period == "æ—¥çº¿" else 52 * 10
                
                df_plot['MA5_PE'] = df_plot['PE_æ­£æ•°ç­‰æƒ'].rolling(window=window_5y, min_periods=1).mean()
                df_plot['MA10_PE'] = df_plot['PE_æ­£æ•°ç­‰æƒ'].rolling(window=window_10y, min_periods=1).mean()
                
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["MA5_PE"], name="5å¹´å‡çº¿", line=dict(color="#7F8C8D", width=1.5)), secondary_y=False)
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["MA10_PE"], name="10å¹´å‡çº¿", line=dict(color="#2C3E50", width=1.5)), secondary_y=False)
                
                fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["æŒ‡æ•°ç‚¹ä½"], name="æŒ‡æ•°ç‚¹ä½", line=dict(color="#34495E", width=1.5), opacity=0.3), secondary_y=True)
                fig.update_yaxes(title_text="PE ä¼°å€¼", secondary_y=False)
                fig.update_yaxes(title_text="æŒ‡æ•°ç‚¹ä½", secondary_y=True, showgrid=False)

            # âœ… äº¤æ˜“ç‚¹ä½æ¸²æŸ“ (è¶…çº§å¢å¼ºåŒ¹é…)
            all_trades_df = pd.DataFrame()
            trade_sources = []
            
            if not st.session_state['uploaded_trades'].empty:
                trade_sources.append(st.session_state['uploaded_trades'])
            
            saved_recs = load_trade_records()
            if saved_recs:
                trade_sources.append(pd.DataFrame(saved_recs))
            
            if trade_sources:
                try:
                    all_trades_df = pd.concat(trade_sources, ignore_index=True)
                    plot_df = all_trades_df.copy()
                    
                    plot_df.columns = [str(c).strip() for c in plot_df.columns]
                    rmap = {}
                    for c in plot_df.columns:
                        if "æŒ‡æ•°" in c: rmap[c]="æŒ‡æ•°"
                        if "æ“ä½œ" in c: rmap[c]="æ“ä½œç±»å‹"
                        if "æ—¥æœŸ" in c: rmap[c]="æ—¥æœŸ"
                    plot_df = plot_df.rename(columns=rmap)
                    if "æŒ‡æ•°" in plot_df.columns: 
                        plot_df["æŒ‡æ•°"] = plot_df["æŒ‡æ•°"].astype(str).str.strip().replace("ä¸­è¯50","ä¸­è¯500")
                    
                    if {'æ—¥æœŸ','æ“ä½œç±»å‹','æŒ‡æ•°'}.issubset(plot_df.columns):
                        plot_df['æ—¥æœŸ'] = pd.to_datetime(plot_df['æ—¥æœŸ'], errors='coerce')
                        
                        sel_name_clean = sel_name.replace("æŒ‡æ•°", "").strip()
                        plot_df['æŒ‡æ•°_clean'] = plot_df['æŒ‡æ•°'].astype(str).str.replace("æŒ‡æ•°", "").str.strip()
                        
                        # æ¨¡ç³ŠåŒ¹é…
                        def is_match(row_idx):
                            return sel_name_clean in row_idx or row_idx in sel_name_clean
                        
                        ct = plot_df[plot_df['æŒ‡æ•°_clean'].apply(is_match)]
                        
                        if not ct.empty:
                            st.caption(f"ğŸ“Š å›¾ä¸­å·²æ ‡è®° {len(ct)} æ¡äº¤æ˜“")
                        
                        buys = ct[ct['æ“ä½œç±»å‹'].astype(str).str.contains('ä¹°')]
                        sells = ct[ct['æ“ä½œç±»å‹'].astype(str).str.contains('å–')]
                        
                        def get_y(dates, df_p):
                            ys = []
                            for d in dates:
                                try:
                                    idx = df_p.index.get_indexer([d], method='nearest')[0]
                                    ys.append(df_p.iloc[idx]['æŒ‡æ•°ç‚¹ä½'])
                                except: ys.append(None)
                            return ys

                        is_sec = True if "ä¼°å€¼" in view_mode else False
                        tar_row = 1
                        
                        if not buys.empty:
                            fig.add_trace(go.Scatter(x=buys['æ—¥æœŸ'], y=get_y(buys['æ—¥æœŸ'], df_plot), mode='markers', name='ä¹°å…¥', marker=dict(symbol='triangle-up', size=12, color='red', line=dict(width=1, color='black'))), row=tar_row, col=1, secondary_y=is_sec)
                        if not sells.empty:
                            fig.add_trace(go.Scatter(x=sells['æ—¥æœŸ'], y=get_y(sells['æ—¥æœŸ'], df_plot), mode='markers', name='å–å‡º', marker=dict(symbol='triangle-down', size=12, color='green', line=dict(width=1, color='black'))), row=tar_row, col=1, secondary_y=is_sec)
                except Exception as e:
                    pass

            fig.update_layout(height=600 if "ä¼°å€¼" in view_mode else 700, hovermode="x unified", xaxis_rangeslider_visible=False)
            st.plotly_chart(fig, use_container_width=True)
            
            if not all_trades_df.empty:
                st.markdown("---")
                st.subheader("ğŸ“‹ å®Œæ•´äº¤æ˜“è´¦æœ¬")
                st.dataframe(all_trades_df, use_container_width=True)

if __name__ == "__main__":
    main()