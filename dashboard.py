# dashboard.py (V22.0 - ç­–ç•¥å‚æ•°åŒ–ã€å›å¡«ä¼˜åŒ–ã€æˆæœ¬ç²¾ç¡®åŒ–)

import streamlit as st
import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
import time
import glob

# ================= é…ç½®åŒºåŸŸ (V22.0) =================

# å®Œæ•´çš„æŒ‡æ•°åˆ—è¡¨ (ä¿ç•™æ‚¨ V21.1 æä¾›çš„é…ç½®)
TARGETS = {
    "å¤§ç›˜.csv": "å¤§ç›˜æŒ‡æ•°",
    "æ²ªæ·±300.csv": "æ²ªæ·±300æŒ‡æ•°",
    "ä¸­è¯500.csv": "ä¸­è¯500æŒ‡æ•°",
    
    # å…¶ä»–æŒ‡æ•°
    "å…¨æŒ‡åŒ»è¯.csv": "å…¨æŒ‡åŒ»è¯",
    "ä¸Šè¯50.csv": "ä¸Šè¯50",
    "åˆ›ä¸šæ¿æŒ‡.csv": "åˆ›ä¸šæ¿æŒ‡",
    "å…»è€äº§ä¸š.csv": "å…»è€äº§ä¸š",
    "ä¸­è¯çº¢åˆ©.csv": "ä¸­è¯çº¢åˆ©",
    "ä¸­è¯ç¯ä¿.csv": "ä¸­è¯ç¯ä¿",
    "ä¸­è¯ä¼ åª’.csv": "ä¸­è¯ä¼ åª’",
    "å…¨æŒ‡é‡‘è.csv": "å…¨æŒ‡é‡‘è",
    "è¯åˆ¸å…¬å¸.csv": "è¯åˆ¸å…¬å¸",
    "å…¨æŒ‡æ¶ˆè´¹.csv": "å…¨æŒ‡æ¶ˆè´¹",
    "å…¨æŒ‡ä¿¡æ¯.csv": "å…¨æŒ‡ä¿¡æ¯",
    "ä¸­è¯åŒ»ç–—.csv": "ä¸­è¯åŒ»ç–—",
    "ä¸­è¯ç™½é…’.csv": "ä¸­è¯ç™½é…’",
}

DATA_DIR = "index_data"
STATE_FILE = "portfolio_status.json"

# V23.2: èµ„é‡‘/ä»½æ•°å›ºå®šé‡‘é¢é…ç½®
FIXED_AMOUNT_PER_PORTION = 300.0 # æ¯ä»½å›ºå®šé‡‘é¢# åˆå§‹é»˜è®¤å€¼ï¼Œç”¨äºé¦–æ¬¡åŠ è½½ Session State
DEFAULT_STRATEGY_PARAMS = {
    "MAX_UNITS": 150,                 # æœ€å¤§ä¹°å…¥ä»½æ•° (ç°åœ¨æ˜¯æ€»ä»½æ•° 150 ä»½)
    "STEP_PERCENT": 0.06,            # é˜¶æ¢¯ä¹°å…¥è·Œå¹… (6%)
    "MIN_INTERVAL_DAYS": 30,         # æœ€å°æ“ä½œé—´éš”å¤©æ•° (30å¤©)
    "VOLATILITY_OVERRIDE_PCT": 0.12, # æ³¢åŠ¨ç‡é™åˆ¶è¦†ç›–æ¯”ä¾‹ (12%)
}
MAX_UNITS_DEFAULT = DEFAULT_STRATEGY_PARAMS["MAX_UNITS"]
MIN_INTERVAL_DAYS = DEFAULT_STRATEGY_PARAMS["MIN_INTERVAL_DAYS"]
VOLATILITY_OVERRIDE_PCT = DEFAULT_STRATEGY_PARAMS["VOLATILITY_OVERRIDE_PCT"]

# V23.3: èµ„é‡‘/ä»½æ•°å›ºå®šé‡‘é¢é…ç½®
FIXED_AMOUNT_PER_PORTION = 300.0 # æ¯ä»½å›ºå®šé‡‘é¢


# ====================================================================
# æ ¸å¿ƒçŠ¶æ€å‡½æ•° (V23.3: å¼•å…¥ portions å­—æ®µ)
# ====================================================================

def initialize_session_state():
    """åˆå§‹åŒ– Streamlit Session Stateï¼ŒåŒ…æ‹¬ç­–ç•¥å‚æ•°ã€‚"""
    if 'strategy_params' not in st.session_state:
        st.session_state['strategy_params'] = DEFAULT_STRATEGY_PARAMS

def get_strategy_param(key):
    """è·å–å½“å‰ç­–ç•¥å‚æ•°å€¼ã€‚"""
    initialize_session_state()
    return st.session_state['strategy_params'].get(key, DEFAULT_STRATEGY_PARAMS.get(key))

def load_state():
    """åŠ è½½åº”ç”¨çŠ¶æ€ï¼Œå¥å£®åœ°å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨ã€æ–‡ä»¶ä¸ºç©ºæˆ–æ–‡ä»¶æŸåçš„æƒ…å†µã€‚"""
    
    # å‡è®¾ STATE_FILE æ˜¯å…¨å±€å®šä¹‰çš„ï¼ˆå¦‚ "user_state.json"ï¼‰
    # å‡è®¾ TARGETS æ˜¯å…¨å±€å®šä¹‰çš„æŒ‡æ•°åˆ—è¡¨
    
    # å®šä¹‰åˆå§‹çŠ¶æ€ï¼Œç”¨äºæ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸåæ—¶é‡ç½®
    initial_state = {
        code: {"holdings": 0.0, "total_cost": 0.0, "portions_held": 0.0, "history": []} 
        for code in TARGETS.keys()
    }

    if os.path.exists(STATE_FILE):
        
        # ğŸš¨ å…³é”®ä¿®å¤ï¼šåœ¨è¯»å– JSON ä¹‹å‰æ£€æŸ¥æ–‡ä»¶å¤§å°
        if os.path.getsize(STATE_FILE) == 0:
            st.warning("è­¦å‘Š: çŠ¶æ€æ–‡ä»¶ä¸ºç©ºï¼ˆ0å­—èŠ‚ï¼‰ï¼Œå·²é‡ç½®ã€‚")
            return initial_state
            
        try:
            # ä¼˜åŒ–ï¼šä½¿ç”¨ with open è¯­å¥
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                state = json.load(f)
                
            # ç¡®ä¿æ‰€æœ‰æŒ‡æ•°éƒ½æœ‰å®Œæ•´çš„ç»“æ„
            for code in TARGETS.keys():
                if code not in state:
                    state[code] = initial_state[code]
                else:
                    # å…¼å®¹æ€§æ£€æŸ¥ï¼šç¡®ä¿æ‰€æœ‰å…³é”®å­—æ®µéƒ½å­˜åœ¨
                    if "total_cost" not in state[code]: state[code]["total_cost"] = 0.0 
                    if "holdings" not in state[code]: state[code]["holdings"] = 0.0
                    if "portions_held" not in state[code]: state[code]["portions_held"] = 0.0 
                    if "history" not in state[code]: state[code]["history"] = []
                    
                    # ç¡®ä¿ history è®°å½•ä¸­åŒ…å« 'portions' å’Œ 'fund_name' å­—æ®µ (å…¼å®¹æ—§æ•°æ®)
                    for h in state[code]["history"]:
                        if "portions" not in h:
                            # å…¼å®¹æ—§è®°å½•çš„ portions ä¼°ç®—é€»è¾‘
                            if h.get('price') and h.get('unit'):
                                # å‡è®¾ FIXED_AMOUNT_PER_PORTION åœ¨å…¨å±€èŒƒå›´å†…å¯ç”¨
                                h['portions'] = round((h['price'] * h['unit']) / FIXED_AMOUNT_PER_PORTION, 0)
                            else:
                                h['portions'] = 0 # æ— æ³•ä¼°ç®—
                        
                        if "fund_name" not in h:
                            h['fund_name'] = ""
                            
            # ç¡®ä¿åœ¨è¿”å›å‰ï¼Œé‡æ–°è®¡ç®—æŒä»“å’Œæˆæœ¬ï¼ˆé‡è¦ï¼‰
            return recalculate_holdings_and_cost(state) 
            
        except json.JSONDecodeError as e:
            # æ•è· JSON æ ¼å¼é”™è¯¯
            st.error(f"è­¦å‘Š: çŠ¶æ€æ–‡ä»¶æŸå ({STATE_FILE})ï¼Œå·²é‡ç½®ã€‚é”™è¯¯: {e}")
            return initial_state
            
        except Exception as e:
            # æ•è·å…¶ä»–å¦‚ AttributeError ç­‰æœªçŸ¥é”™è¯¯
            st.error(f"è­¦å‘Š: çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå·²é‡ç½®ã€‚é”™è¯¯: {e}")
            return initial_state
            
    # æ–‡ä»¶ä¸å­˜åœ¨
    return initial_state


def save_state(state):
    """å°†å½“å‰çŠ¶æ€ä¿å­˜åˆ°æœ¬åœ° JSON æ–‡ä»¶ã€‚"""
    try:
        # V22.0: åœ¨ä¿å­˜å‰ï¼Œç¡®ä¿ history ä¸­çš„ date æ˜¯å­—ç¬¦ä¸²æ ¼å¼
        state_to_save = {}
        for k, data in state.items():
            data_to_save = data.copy()
            if 'history' in data_to_save:
                data_to_save['history'] = [
                    {**h, 'date': h['date'].strftime('%Y-%m-%d') if hasattr(h['date'], 'strftime') else h['date']}
                    for h in data_to_save['history']
                ]
            state_to_save[k] = data_to_save
            
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state_to_save, f, ensure_ascii=False, indent=4)
        return True
    except Exception as e:
        st.error(f"ä¿å­˜çŠ¶æ€åˆ° {STATE_FILE} å¤±è´¥ã€‚é”™è¯¯: {e}")
        return False


def calculate_total_portions(history):
    """V23.3: æ ¹æ®å†å²è®°å½•ä¸­æ–°å¢çš„ 'portions' å­—æ®µè®¡ç®—å½“å‰æŒæœ‰çš„æ€»ä»½æ•°ã€‚"""
    total_portions = 0.0
    for transaction in history:
        # å…¼å®¹æ€§è¯´æ˜: äº¤æ˜“è®°å½•å¿…é¡»åŒ…å« portions å­—æ®µ
        portions = transaction.get('portions', 0.0) 
        
        if transaction.get('type') == 'ä¹°å…¥':
            total_portions += portions
        elif transaction.get('type') == 'å–å‡º':
            total_portions -= portions
    return max(0.0, total_portions)


def recalculate_holdings_and_cost(state):
    """V23.3: éå†æ‰€æœ‰æŒ‡æ•°ï¼Œé‡æ–°è®¡ç®—å¹¶æ›´æ–°çŠ¶æ€ä¸­çš„æŒä»“ã€æ€»æˆæœ¬å’Œæ€»ä»½æ•°ã€‚"""
    for code, data in state.items():
        if 'history' in data:
            # 1. è®¡ç®—åŸºé‡‘ä»½é¢å’Œæ€»æˆæœ¬ï¼ˆä½¿ç”¨æ—§çš„ calculate_index_costï¼‰
            total_units, total_cost = calculate_index_cost(data['history'])
            
            # 2. è®¡ç®—ä»½æ•°ï¼ˆä½¿ç”¨æ–°çš„ calculate_total_portionsï¼‰
            total_portions = calculate_total_portions(data['history']) 
            
            state[code]['holdings'] = total_units # ä»æ˜¯åŸºé‡‘ä»½é¢
            state[code]['total_cost'] = total_cost
            state[code]['portions_held'] = total_portions # V23.3 æ–°å¢å­—æ®µä¿å­˜æ€»ä»½æ•°
    return state


def calculate_index_cost(history):
    """
    æ ¹æ®å†å²è®°å½•è®¡ç®—å½“å‰æŒä»“ä»½é¢å’Œæ€»æˆæœ¬ã€‚
    é€»è¾‘æ›´æ–°ï¼šç›´æ¥ä½¿ç”¨ 'unit'(ä»½é¢) å’Œ 'price'(å‡€å€¼) è®¡ç®—ã€‚
    Total Cost = Sum(Buy Price * Buy Unit) - Cost of Sold Units
    """
    total_units = 0.0
    total_cost = 0.0
    
    for transaction in history:
        # è·å–ä»½é¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ä¸º0
        unit = float(transaction.get('unit', 0.0))
        price = float(transaction.get('price', 0.0))
        
        # å…¼å®¹æ—§æ•°æ®ï¼šå¦‚æœæ—§æ•°æ®åªæœ‰ 'portions' æ²¡æœ‰ 'unit'ï¼Œåœ¨è¿™é‡Œåšä¸€ä¸ªä¸´æ—¶è½¬æ¢(å¯é€‰)
        # if unit == 0 and transaction.get('portions'):
        #     unit = transaction.get('portions') * 300 / price 
        
        if transaction.get('type') == 'ä¹°å…¥':
            cost_increase = price * unit
            total_cost += cost_increase
            total_units += unit
            
        elif transaction.get('type') == 'å–å‡º':
            if total_units > 0:
                # å–å‡ºæ—¶ï¼ŒæŒ‰å¹³å‡æˆæœ¬å‡å°‘æ€»æˆæœ¬
                avg_cost_per_unit = total_cost / total_units
                cost_decrease = avg_cost_per_unit * unit
                
                total_cost -= cost_decrease
                total_units -= unit
                
                # é˜²æ­¢æµ®ç‚¹æ•°è¯¯å·®
                if total_units < 1e-6:
                    total_units = 0.0
                    total_cost = 0.0
            
    return max(0.0, total_units), max(0.0, total_cost)

# åŒæ—¶æ›´æ–° recalculate_holdings_and_cost å‡½æ•°
def recalculate_holdings_and_cost(state):
    for code, data in state.items():
        if 'history' in data:
            total_units, total_cost = calculate_index_cost(data['history'])
            state[code]['holdings'] = total_units # ç°åœ¨çš„ holdings å°±æ˜¯çœŸå®çš„åŸºé‡‘ä»½é¢
            state[code]['total_cost'] = total_cost
            # portions_held å­—æ®µä¸å†éœ€è¦ç”¨äºæ ¸å¿ƒè®¡ç®—ï¼Œä½†å¯ä»¥ä¿ç•™ä¸º 0 é˜²æ­¢æŠ¥é”™
            state[code]['portions_held'] = 0 
    return state

# ================= æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•° (V22.0 ä¼˜åŒ–) =================

# V22.0: æ”¹è¿› find_pe_by_dateï¼Œæ”¯æŒå‘å‰æŸ¥æ‰¾ (Forward Fill)
def find_pe_by_date(df, target_date_str):
    """æ ¹æ®æ—¥æœŸæŸ¥æ‰¾å¯¹åº”çš„ PE å€¼å’Œæ”¶ç›˜ç‚¹ä½ã€‚å¦‚æœå½“å¤©æ— æ•°æ®ï¼Œå‘å‰æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥ã€‚"""
    try:
        target_date = pd.to_datetime(target_date_str)
        # ç¡®ä¿ df ç´¢å¼•æ˜¯ datetime
        df_temp = df.copy()
        df_temp['Date'] = pd.to_datetime(df_temp['Date'], errors='coerce')
        df_temp = df_temp.set_index('Date').sort_index()
        
        # å°è¯•ç²¾ç¡®åŒ¹é…å½“å¤©æ•°æ®
        if target_date in df_temp.index:
             row = df_temp.loc[target_date]
             return row['pe'], row['Close']
             
        # å¦‚æœå½“å¤©æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨ reindex/ffill æŸ¥æ‰¾æœ€è¿‘çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ®
        # åˆ›å»ºä¸€ä¸ªåŒ…å«ç›®æ ‡æ—¥æœŸçš„ä¸´æ—¶ç´¢å¼•
        temp_index = df_temp.index.union([target_date]).sort_values()
        df_reindexed = df_temp.reindex(temp_index)
        
        # ä½¿ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……ç›®æ ‡æ—¥æœŸ
        df_reindexed = df_reindexed.ffill()
        
        # æŸ¥æ‰¾ç›®æ ‡æ—¥æœŸçš„ PE å’Œ Close
        if target_date in df_reindexed.index:
            row = df_reindexed.loc[target_date]
            # ç¡®ä¿è¿™ä¸æ˜¯ä¸€ä¸ª NaN å¡«å……çš„ç»“æœ
            if pd.notna(row['pe']):
                return row['pe'], row['Close']

        return np.nan, np.nan
    except Exception as e:
        # st.error(f"æŸ¥æ‰¾ PE/Close å¤±è´¥: {e}")
        return np.nan, np.nan


def find_latest_data_file(prefix):
    """æŸ¥æ‰¾åŒ¹é…å‰ç¼€çš„æœ€æ–°æ•°æ®æ–‡ä»¶ï¼Œå¹¶è¿”å›æ–‡ä»¶è·¯å¾„å’Œä¿®æ”¹æ—¶é—´ (æ”¯æŒæ¨¡ç³ŠåŒ¹é…)"""
    # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒåœ¨æ‚¨çš„ V21.1 ä¸­å·²ç»å·¥ä½œæ­£å¸¸) ...
    search_pattern = os.path.join(DATA_DIR, f"{prefix}_*.csv")
    matching_files = glob.glob(search_pattern)
    
    actual_file_path = None
    file_source_name = None
    last_modified_time = None
    
    if matching_files:
        actual_file_path = max(matching_files, key=os.path.getmtime)
        file_source_name = os.path.basename(actual_file_path)
        last_modified_time = datetime.fromtimestamp(os.path.getmtime(actual_file_path)).strftime('%Y-%m-%d %H:%M:%S')
    else:
        # æŸ¥æ‰¾å›ºå®šæ–‡ä»¶åä½œä¸ºå¤‡ä»½
        fixed_path = os.path.join(DATA_DIR, f"{prefix}.csv")
        if os.path.exists(fixed_path):
            actual_file_path = fixed_path
            file_source_name = f"{prefix}.csv"
            last_modified_time = datetime.fromtimestamp(os.path.getmtime(fixed_path)).strftime('%Y-%m-%d %H:%M:%S')
        
    return actual_file_path, file_source_name, last_modified_time


@st.cache_data(ttl=3600)
def get_metrics_from_csv(file_path):
 
    if not os.path.exists(file_path): return None
    try:
        df = pd.read_csv(file_path, encoding='utf-8', sep=',')
        if len(df) == 0: return None
        
        # V22.0: å…¼å®¹æ€§è°ƒæ•´ï¼Œä¼˜å…ˆä½¿ç”¨ç®€çŸ­çš„åˆ—å
        df = df.rename(columns={'PE-TTMæ­£æ•°ç­‰æƒ': 'pe', 'æ—¥æœŸ': 'Date', 
                                'PE-TTM åˆ†ä½ç‚¹': 'pe_percentile', 
                                'æ”¶ç›˜ç‚¹ä½': 'Close', 'æ”¶ç›˜': 'Close', 
                                'Close': 'Close', 'Date': 'Date'})
        
        for col in ['pe', 'pe_percentile', 'Close']:
             if col in df.columns:
                 df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
                 df[col] = pd.to_numeric(df[col], errors='coerce') 
        
     # 1. å¿…é¡»ç¡®ä¿ Date æ˜¯ datetime ç±»å‹å¹¶è®¾ä¸ºç´¢å¼•ï¼Œæ‰èƒ½ä½¿ç”¨åŸºäºæ—¶é—´çš„ rolling
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # <--- è¿™è¡Œæ˜¯æŠ¥é”™è¡Œ
        df = df[['Date', 'pe', 'pe_percentile', 'Close']].dropna(subset=['pe', 'Date', 'pe_percentile', 'Close'])
        df = df.sort_values('Date', ascending=True).reset_index(drop=True)
    
        if df.empty: return None
    
    # === å…³é”®ä¿®æ”¹ï¼šè®¾ç½®ç´¢å¼•ä¸ºæ—¥æœŸï¼Œä»¥ä¾¿è¿›è¡Œæ—¶é—´çª—å£è®¡ç®— ===
        df = df.set_index('Date') 
    
    # 2. å®šä¹‰æ—¶é—´çª—å£ (365å¤©*N)
        WINDOW_3Y = '1095D'  # 365 * 3
        WINDOW_5Y = '1825D'  # 365 * 5
        WINDOW_10Y = '3650D' # 365 * 10
    
    # 3. ä½¿ç”¨åŸºäºæ—¶é—´çš„ rolling (closed='left' è¡¨ç¤ºä¸åŒ…å«å½“å¤©)
        df['avg_3yr_roll'] = df['pe'].rolling(window=WINDOW_3Y, min_periods=1, closed='left').mean()
        df['avg_5yr_roll'] = df['pe'].rolling(window=WINDOW_5Y, min_periods=1, closed='left').mean()
        df['avg_10yr_roll'] = df['pe'].rolling(window=WINDOW_10Y, min_periods=1, closed='left').mean()
        # ==========================================
 # 4. === æ ¸å¿ƒä¿®æ­£ï¼šåŸºäºæ—¶é—´é•¿åº¦å¼ºåˆ¶ NaN ===
        earliest_date = df.index[0]
        
        # è®¡ç®— 3 å¹´åçš„æ—¥æœŸï¼ˆå³å¼€å§‹è®¡ç®—ä¸‰å¹´å¹³å‡å€¼çš„æ—¥æœŸï¼‰
        START_DATE_3Y = earliest_date + pd.Timedelta(days=1095)
        # å¼ºåˆ¶å°†æ—©äºè¯¥æ—¥æœŸçš„æ»šåŠ¨å¹³å‡å€¼è®¾ä¸º NaN
        df.loc[df.index < START_DATE_3Y, 'avg_3yr_roll'] = np.nan
        
        # 5 å¹´
        START_DATE_5Y = earliest_date + pd.Timedelta(days=1825)
        df.loc[df.index < START_DATE_5Y, 'avg_5yr_roll'] = np.nan
        
        # 10 å¹´
        START_DATE_10Y = earliest_date + pd.Timedelta(days=3650)
        df.loc[df.index < START_DATE_10Y, 'avg_10yr_roll'] = np.nan
        # ==========================================
           
        df['benchmark_roll'] = df['avg_3yr_roll'] 
        df['deviation_pct'] = (df['pe'] - df['benchmark_roll']) / df['benchmark_roll'] * 100
        
        max_dev = df['deviation_pct'].max(); min_dev = df['deviation_pct'].min()
        
        if not np.isnan(max_dev): max_dev_date = df[df['deviation_pct'] == max_dev].iloc[-1].name.strftime('%Y-%m-%d')
        else: max_dev_date = 'N/A'
        if not np.isnan(min_dev): min_dev_date = df[df['deviation_pct'] == min_dev].iloc[-1].name.strftime('%Y-%m-%d')
        else: min_dev_date = 'N/A'
        
        # (å¯é€‰) æ›´æ–°å•ç‚¹å‡å€¼å˜é‡ï¼Œä½¿å…¶ä¸ä¸º NaNï¼Œè™½ç„¶ç»˜å›¾ä¸»è¦ç”¨ä¸Šé¢çš„ roll æ•°ç»„
        avg_3yr = df['avg_3yr_roll'].iloc[-1]
        avg_5yr = df['avg_5yr_roll'].iloc[-1]
        avg_10yr = df['avg_10yr_roll'].iloc[-1] # è¿™é‡ŒåŸæ¥æ˜¯ np.nanï¼Œç°åœ¨å¯ä»¥å–å€¼äº†
        df = df.reset_index().rename(columns={'index': 'Date'}); df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
        current_pe = df.iloc[-1]['pe']; current_percentile = df.iloc[-1]['pe_percentile']

    # è®¡ç®—æœ€å¤§/æœ€å°åç¦»åº¦ (ç”¨äºè¡¨æ ¼å±•ç¤º)
        max_dev = df['deviation_pct'].max()
        min_dev = df['deviation_pct'].min()
        
        return (current_pe, current_percentile, avg_3yr, avg_5yr, avg_10yr, 
                df, max_dev, min_dev, max_dev_date, min_dev_date)
        
    except Exception as e:
        st.error(f"[{file_path}] è¯»å–æˆ–å¤„ç†æ•°æ®å¤±è´¥: {e}")
        return None

# V22.0: é‡å‘½åå¹¶æ”¹è¿›ç›ˆäºè®¡ç®—ï¼ŒåŸºäºç²¾ç¡®çš„æ€»æˆæœ¬
def calculate_index_pl_metrics(s, current_close_index, df_full):
    """
    V22.0: è®¡ç®—å•ä¸ªæŒ‡æ•°çš„å¹³å‡æˆæœ¬å’Œæµ®åŠ¨ç›ˆäºã€‚
    ä½¿ç”¨ç²¾ç¡®çš„ total_cost å’Œ holdings è®¡ç®—å¹³å‡æˆæœ¬ã€‚
    """
    total_units = s.get('holdings', 0.0)
    total_cost = s.get('total_cost', 0.0)

    if total_units == 0:
        return np.nan, np.nan, np.nan  # avg_cost, floating_pl_pct, total_market_value

    # 1. è®¡ç®—å¹³å‡æˆæœ¬
    avg_cost = total_cost / total_units

    # 2. ä¼°ç®—å½“å‰å¸‚åœºä»·å€¼ (ä½¿ç”¨æœ€æ–°çš„ ETF ä»·æ ¼)
    
    # æŸ¥æ‰¾æœ€è¿‘ä¸€æ¬¡æ“ä½œçš„ ETF æˆäº¤ä»·å’Œå¯¹åº”çš„æŒ‡æ•°ç‚¹ä½
    last_trade = next((t for t in reversed(s['history']) if t.get('price') is not None and t.get('close') is not None), None)

    if last_trade and last_trade['close'] > 0:
        last_trade_etf_price = last_trade['price']
        last_trade_index_close = last_trade['close']
        
        # æ ¸å¿ƒå‡è®¾ï¼šETFä»·æ ¼æ³¢åŠ¨ä¸æŒ‡æ•°ç‚¹ä½æ³¢åŠ¨ä¸€è‡´
        estimated_current_etf_price = last_trade_etf_price * (current_close_index / last_trade_index_close)
        
        total_market_value = estimated_current_etf_price * total_units
        floating_pl_pct = (total_market_value / total_cost) - 1
        
        return avg_cost, floating_pl_pct, total_market_value
    else:
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„äº¤æ˜“è®°å½•æ¥å»ºç«‹ä¼°ç®—åŸºå‡†ï¼Œåˆ™æ— æ³•è®¡ç®—ç›ˆäº
        return avg_cost, np.nan, np.nan

def get_full_index_metrics(index_key, state, full_data_frames):
    """
    V22.0: è·å–å•ä¸ªæŒ‡æ•°çš„å®Œæ•´æŒ‡æ ‡ã€æŒä»“å’Œç›ˆäºä¿¡æ¯ï¼Œç”¨äºå­é¡µé¢è°ƒç”¨ã€‚
    """
    
    # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒæ˜¯ V21.1 ä¸­çš„è°ƒç”¨æ¥å£ï¼Œæˆ‘ä»¬åªæ”¹å˜å…¶è°ƒç”¨çš„å­å‡½æ•°) ...
    result = {
        "current_pe": np.nan, "current_close": np.nan, "holdings": 0.0, 
        "avg_cost": np.nan, "pl_pct": np.nan, "df_full": None, 
        "history": state.get(index_key, {}).get("history", [])
    }
    
    df_full = full_data_frames.get(index_key)
    s = state.get(index_key, {})
    result["holdings"] = s.get("holdings", 0.0)
    
    if df_full is None:
        prefix = index_key.split('.')[0]
        actual_file_path, _, _ = find_latest_data_file(prefix)
        metrics_result = get_metrics_from_csv(actual_file_path)
        if metrics_result:
            df_full = metrics_result[5]
            result["current_pe"] = metrics_result[0]
            result["current_close"] = df_full.iloc[-1]['Close']
            
    if df_full is not None and not df_full.empty:
        result["df_full"] = df_full
        result["current_pe"] = df_full.iloc[-1]['pe']
        result["current_close"] = df_full.iloc[-1]['Close']
        
        # V22.0: è°ƒç”¨æ–°çš„ç›ˆäºè®¡ç®—å‡½æ•°
        avg_cost, pl_pct, total_market_val = calculate_index_pl_metrics(s, current_close_index, df_full) # æ³¨æ„ï¼šåŸå‡½æ•°ç¬¬3ä¸ªè¿”å›å€¼æ˜¯å¸‚å€¼

        # === æ–°å¢ï¼šæ”¶é›†é¥¼å›¾æ•°æ® ===
        # å¦‚æœæœ‰æŒä»“ï¼Œåˆ™è®°å½•å¸‚å€¼ï¼ˆä¼˜å…ˆï¼‰æˆ–æˆæœ¬
        if current_holdings > 0:
            # å¦‚æœ calculate_index_pl_metrics è¿”å›äº†å¸‚å€¼åˆ™ç”¨å¸‚å€¼ï¼Œå¦åˆ™ç”¨æ€»æˆæœ¬
            value_for_pie = total_market_val if (total_market_val is not None and not np.isnan(total_market_val)) else current_total_cost
            pie_chart_data.append({
                "name": name,
                "value": value_for_pie
            })
        # ========================
        result["avg_cost"] = avg_cost
        result["pl_pct"] = pl_pct
        result["total_market_val"] = value_for_pie
    return result

# ================= é¢œè‰²é«˜äº®å‡½æ•° =================

# ... (é«˜äº®å‡½æ•°ä¿æŒä¸å˜) ...

def highlight_percentile(val):
    """æ ¹æ®ä¼°å€¼ç™¾åˆ†ä½è¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    try:
        if isinstance(val, str) and val.endswith('%'):
            pct = float(val.strip('%'))
        else: return '' 
            
        if pct < 20: return 'background-color: #d4edda; color: #155724; font-weight: bold' 
        elif 20 <= pct <= 50: return 'background-color: #fff3cd; color: #856404;' 
        elif 50 < pct <= 80: return 'background-color: #f8d7da; color: #721c24;' 
        elif pct > 80: return 'background-color: #dc3545; color: white; font-weight: bold' 
        else: return ''
    except: return ''

def highlight_signal(val):
    """æ ¹æ®å»ºè®®ä¿¡å·è¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    if 'ä¹°å…¥' in str(val):
        return f'background-color: #d4edda; color: #155724; font-weight: bold' 
    elif 'å–å‡º' in str(val):
        return f'background-color: #f8d7da; color: #721c24; font-weight: bold'
    elif 'æ•°æ®ç§¯ç´¯ä¸­' in str(val):
         return f'background-color: #fffac0; color: #b58d09; font-weight: bold'
    elif 'è·Œå¹…ä¸è¶³' in str(val):
         return 'background-color: #e0f7fa; color: #00796b; font-weight: bold' 
    elif 'é™åˆ¶' in str(val): 
         return 'background-color: #e9ecef; color: #495057; font-weight: bold'
    else:
        return 'background-color: #f0f0f0; color: black;'

def highlight_pl(val):
    """æ ¹æ®æµ®åŠ¨ç›ˆäºè¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    try:
        if isinstance(val, str) and val.endswith('%'):
            pct = float(val.strip('%'))
        else: return '' 
            
        if pct > 0: return 'color: #155724; font-weight: bold' # ç»¿è‰²å­—ä½“
        elif pct < 0: return 'color: #721c24; font-weight: bold' # çº¢è‰²å­—ä½“
        else: return ''
    except: return ''

# ================= é¡µé¢å¸ƒå±€ï¼ˆä¸»ä½“é€»è¾‘ï¼‰ (V22.0 ä¼˜åŒ–) =================
st.set_page_config(page_title="æŒ‡æ•°å®šæŠ•çœ‹æ¿", layout="wide", page_icon="ğŸ“ˆ")

# --- é¡µé¢å¤´éƒ¨ç¾åŒ–ä¸CSSè®¾ç½® ---
st.markdown("""
<style>
/* å¼ºåˆ¶ç¼©å° st.metric çš„æ•°å­—å­—ä½“ */
div[data-testid="stMetricValue"] > div {
    font-size: 16px !important; /* åŸæ¥å¯èƒ½æ˜¯ 24px æˆ– 30pxï¼Œæ”¹å° */
    font-weight: bold;
}
/* ç¼©å°æ ‡é¢˜å­—ä½“ */
div[data-testid="stMetricLabel"] label {
    font-size: 13px !important;
}
/* è°ƒæ•´ Metric å®¹å™¨çš„ç´§å‡‘åº¦ */
div[data-testid="stMetric"] {
    background-color: #f9f9f9;
    padding: 5px 10px;
    border-radius: 5px;
}
</style>
""", unsafe_allow_html=True)

# ===========================================

# V22.0: åˆå§‹åŒ– Session State
initialize_session_state()

# --- é¡µé¢å¤´éƒ¨ç¾åŒ– ---
with st.container(border=True):
    st.markdown("## ğŸ“Š æ™ºèƒ½å®šæŠ•çœ‹æ¿ï¼šä¼°å€¼æ€»è§ˆä¸ç­–ç•¥å»ºè®® (V22.0 - ä¼˜åŒ–ç‰ˆ)")
    
    # V22.0: ä» Session State è¯»å–å‚æ•°
    MIN_INTERVAL_DAYS = get_strategy_param("MIN_INTERVAL_DAYS")
    VOLATILITY_OVERRIDE_PCT = get_strategy_param("VOLATILITY_OVERRIDE_PCT")
    
    st.markdown(f"**ç­–ç•¥é™åˆ¶**: æ¯æ¬¡æ“ä½œé—´éš”éœ€å¤§äº **{MIN_INTERVAL_DAYS}** å¤©ï¼Œé™¤é PE æ³¢åŠ¨å¹…åº¦å¤§äº **{VOLATILITY_OVERRIDE_PCT*100:.0f}%**ã€‚")

# --- ä¾§è¾¹æ å’Œæ•°æ®æ–°é²œåº¦æ£€æŸ¥ (V22.0 ç­–ç•¥é…ç½®) ---
st.sidebar.header("ğŸ•¹ï¸ ç­–ç•¥é…ç½® (V22.0)")

# V22.0: ç­–ç•¥å‚æ•°åŒ–é…ç½®
with st.sidebar.expander("âš™ï¸ ç­–ç•¥å‚æ•°è®¾ç½®"):
    
    MAX_UNITS = st.number_input(
        "æœ€å¤§æŒä»“ä»½æ•° (MAX_UNITS):", 
        min_value=1, value=get_strategy_param("MAX_UNITS"), step=1, key='param_max_units'
    )
    STEP_PERCENT = st.number_input(
        "é˜¶æ¢¯ä¹°å…¥è·Œå¹… (STEP_PERCENT, %):", 
        min_value=1.0, max_value=20.0, value=get_strategy_param("STEP_PERCENT")*100, step=0.5, format="%.1f"
    ) / 100
    MIN_INTERVAL_DAYS = st.number_input(
        "æœ€å°æ“ä½œé—´éš” (å¤©):", 
        min_value=1, value=get_strategy_param("MIN_INTERVAL_DAYS"), step=1, key='param_min_days'
    )
    VOLATILITY_OVERRIDE_PCT = st.number_input(
        "æ³¢åŠ¨ç‡è¦†ç›–æ¯”ä¾‹ (%):", 
        min_value=1.0, max_value=50.0, value=get_strategy_param("VOLATILITY_OVERRIDE_PCT")*100, step=1.0, format="%.0f"
    ) / 100
    
    if st.button("ä¿å­˜ç­–ç•¥å‚æ•°å¹¶åˆ·æ–°", type="primary"):
        st.session_state['strategy_params'] = {
            "MAX_UNITS": MAX_UNITS,
            "STEP_PERCENT": STEP_PERCENT,
            "MIN_INTERVAL_DAYS": MIN_INTERVAL_DAYS,
            "VOLATILITY_OVERRIDE_PCT": VOLATILITY_OVERRIDE_PCT,
        }
        st.success("å‚æ•°å·²æ›´æ–°ï¼")
        st.cache_data.clear()
        st.rerun()

# V22.0: è¯»å–æœ€æ–°çš„å‚æ•°å€¼
MAX_UNITS = get_strategy_param("MAX_UNITS")
STEP_PERCENT = get_strategy_param("STEP_PERCENT")
MIN_INTERVAL_DAYS = get_strategy_param("MIN_INTERVAL_DAYS")
VOLATILITY_OVERRIDE_PCT = get_strategy_param("VOLATILITY_OVERRIDE_PCT")


st.sidebar.info(f"æ•°æ®ç›®å½•: **{DATA_DIR}/**")

# æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶ï¼Œè·å–æ›´æ–°æ—¶é—´
latest_modified_time = None
for prefix in [f.split('.')[0] for f in TARGETS.keys()]:
    _, _, mod_time = find_latest_data_file(prefix)
    if mod_time:
        if latest_modified_time is None or mod_time > latest_modified_time:
            latest_modified_time = mod_time

if latest_modified_time:
    st.sidebar.markdown(f"**æœ€åæ•°æ®æ›´æ–°æ—¶é—´ï¼š** `{latest_modified_time}`")
else:
    st.sidebar.warning("âš ï¸ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ index_data æ–‡ä»¶å¤¹ã€‚")

# V22.0: åŠ è½½çŠ¶æ€ï¼Œå¹¶é‡æ–°è®¡ç®—æŒä»“å’Œæˆæœ¬ (é‡è¦æ­¥éª¤)
state = load_state()
state = recalculate_holdings_and_cost(state)
# save_state(state) # é¿å…åœ¨ rerurn ä¹‹å‰é‡å¤ä¿å­˜

# ä¸»æ•°æ®è¡¨æ ¼æ„å»º
table_data = []
decision_logs = {} 
pie_chart_data = [] # <--- æ–°å¢ï¼šç”¨äºå­˜å‚¨é¥¼å›¾æ•°æ®

progress_bar = st.progress(0, text="è®¡ç®—ä¸­...")
total_targets = len(TARGETS)
full_data_frames = {} 

# --- å¤§ç›˜æ•´ä½“ä»“ä½æŒ‡æ ‡è®¡ç®— (ä¿æŒä¸å˜) ---
overall_position_pct = 0
overall_pe_percentile = np.nan

if "å¤§ç›˜.csv" in TARGETS:
    prefix = "å¤§ç›˜"
    actual_file_path, file_source_name, _ = find_latest_data_file(prefix)
    if actual_file_path:
        metrics_result_overall = get_metrics_from_csv(actual_file_path)
        if metrics_result_overall:
            _, overall_pe_percentile, _, _, _, _, _, _, _, _ = metrics_result_overall
            if not np.isnan(overall_pe_percentile):
                overall_position_pct = (1 - overall_pe_percentile) * 100
    
# --- æ•°æ®åŠ è½½ã€è‡ªåŠ¨å›å¡«å’ŒæŒ‡æ ‡è®¡ç®— ---
updated_records_count = 0 

for i, (fixed_filename_key, name) in enumerate(TARGETS.items()): 
    
    prefix = fixed_filename_key.split('.')[0]
    progress_bar.progress((i + 1) / total_targets, text=f"æ­£åœ¨å¤„ç† {name} ({i+1}/{total_targets}) - åŒ¹é…æ–‡ä»¶...")
    
    actual_file_path, file_source_name, _ = find_latest_data_file(prefix)
        
    if not actual_file_path:
        continue

    metrics_result = get_metrics_from_csv(actual_file_path) 
    code = fixed_filename_key
    s = state[code]
    current_holdings = s["holdings"]
    
    # V22.0: ä»çŠ¶æ€ä¸­ç›´æ¥è¯»å–æ€»æˆæœ¬
    current_total_cost = s["total_cost"]
    
    days_since_last_op_display = 'â€”'
    avg_cost_display = 'â€”'
    pl_pct_display = 'â€”'

    current_decision_log = [] 

    if metrics_result:
        (curr_pe, curr_percentile, avg3, avg_5yr, avg_10yr, df_full, 
         max_dev, min_dev, max_dev_date, min_dev_date) = metrics_result
        
        full_data_frames[fixed_filename_key] = df_full 

        # --- V22.0: è‡ªåŠ¨å›å¡«ç¼ºå¤±æ•°æ® (ä½¿ç”¨æ”¹è¿›çš„ find_pe_by_date) ---
        for trade in s['history']:
            if trade['pe'] is None or trade['close'] is None or np.isnan(trade.get('pe', np.nan)):
                new_pe, new_close = find_pe_by_date(df_full, trade['date'])
                if not np.isnan(new_pe) and not np.isnan(new_close):
                    trade['pe'] = round(new_pe, 2)
                    trade['close'] = round(new_close, 2)
                    updated_records_count += 1
        
        # --- V22.0: P&L è®¡ç®— (ä½¿ç”¨æ–°çš„ calculate_index_pl_metrics) ---
        current_close_index = df_full.iloc[-1]['Close']
        avg_cost, pl_pct, _ = calculate_index_pl_metrics(s, current_close_index, df_full)

        if not np.isnan(avg_cost):
            avg_cost_display = f"{avg_cost:.4f}"
        if not np.isnan(pl_pct):
            pl_pct_display = f"{pl_pct * 100:.2f}%"

        # --- é˜¶æ¢¯ä¹°å…¥/æ—¶é—´é™åˆ¶åˆ¤æ–­ ---
        last_op = s["history"][-1] if s["history"] else None
        time_limit_suppression = False
        
        # ... (æ­¤å¤„é€»è¾‘ä¸ V21.1 ä¿æŒä¸€è‡´ï¼Œä½†ä½¿ç”¨ V22.0 çš„åŠ¨æ€å‚æ•°) ...
        if last_op and 'pe' in last_op and last_op['pe'] is not None and not np.isnan(last_op['pe']):
            last_op_date_str = last_op.get("date", datetime.now().strftime("%Y-%m-%d"))
            last_op_date = datetime.strptime(last_op_date_str, "%Y-%m-%d").date()
            days_since_last_op = (datetime.now().date() - last_op_date).days
            days_since_last_op_display = str(days_since_last_op)
            
            current_decision_log.append(f"ä¸Šæ¬¡æ“ä½œè·ä»Š: {days_since_last_op} å¤© (è¦æ±‚ â‰¥ {MIN_INTERVAL_DAYS} å¤©)")
            
            if days_since_last_op < MIN_INTERVAL_DAYS:
                last_op_pe = last_op['pe']
                pe_change_pct = (curr_pe - last_op_pe) / last_op_pe
                current_decision_log.append(f"ä¸Šæ¬¡æ“ä½œPE: {last_op_pe:.2f}, å½“å‰PE: {curr_pe:.2f}, å˜åŠ¨: {pe_change_pct*100:.1f}% (è¦æ±‚ Â±{VOLATILITY_OVERRIDE_PCT*100:.0f}% è¦†ç›–)")
                if abs(pe_change_pct) < VOLATILITY_OVERRIDE_PCT:
                    time_limit_suppression = True
                    current_decision_log.append("ç»“æœ: æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶ç”Ÿæ•ˆï¼ŒæŠ‘åˆ¶æ“ä½œã€‚")
                else:
                    current_decision_log.append("ç»“æœ: æ³¢åŠ¨ç‡è¾¾åˆ°è¦†ç›–æ¡ä»¶ï¼Œç»§ç»­è¯„ä¼°ã€‚")
            else:
                current_decision_log.append("ç»“æœ: å·²è¶…è¿‡æœ€å°æ—¶é—´é—´éš”ï¼Œç»§ç»­è¯„ä¼°ã€‚")
        else:
             current_decision_log.append("æ— ä¸Šæ¬¡æ“ä½œè®°å½•ï¼Œä¸æ£€æŸ¥æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶ã€‚")
        
        # --- æŸ¥æ‰¾ä¸Šæ¬¡ä¹°å…¥çš„PE (ç”¨äº6%é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥) ---
        last_buy_pe = None
        for trade in reversed(s["history"]):
            if trade['type'] == 'ä¹°å…¥' and trade['pe'] is not None and not np.isnan(trade['pe']):
                last_buy_pe = trade['pe']
                break
        
        last_op_hist = s["history"][-1] if s["history"] else {"date": "1900-01-01", "pe": 0, "close": 0}
        last_date = last_op_hist.get("date", "1900-01-01")
        last_pe = last_op_hist.get("pe") 
        if last_pe is None: last_pe = np.nan

        benchmark_pe = avg3 if not np.isnan(avg3) else 0 
        diff_pct = (curr_pe - benchmark_pe) / benchmark_pe * 100 if benchmark_pe > 0 else np.nan
        signal = "è§‚æœ›"
        
        # ==================== ä¿¡å·åˆ¤æ–­é€»è¾‘ (å«å†³ç­–æ—¥å¿— - V22.0 ä½¿ç”¨åŠ¨æ€å‚æ•°) ====================
        current_decision_log.append("--- ç­–ç•¥è¯„ä¼° ---")

        if benchmark_pe == 0 or np.isnan(benchmark_pe):
            signal = "âš ï¸ æ•°æ®ç§¯ç´¯ä¸­ (ä¸æ»¡ 3 å¹´)"
            current_decision_log.append(f"æ¡ä»¶: 3å¹´å‡å€¼ PE ({benchmark_pe:.2f}) ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°ã€‚")
        
        elif time_limit_suppression:
            signal = f"â¸ï¸ è§‚æœ› ({MIN_INTERVAL_DAYS}å¤©/Â±{VOLATILITY_OVERRIDE_PCT*100:.0f}%é™åˆ¶)" 
            current_decision_log.append("æ¡ä»¶: è¢«æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶æŠ‘åˆ¶ã€‚")

        else:
            current_decision_log.append(f"å½“å‰PE: {curr_pe:.2f}, PEåˆ†ä½ç‚¹: {curr_percentile*100:.1f}%, 3å¹´å‡å€¼PE: {avg3:.2f}")

            buy_condition_1 = curr_percentile < 0.20 
            buy_condition_2 = (not np.isnan(avg3) and curr_pe < avg3) and (not np.isnan(avg_5yr) and curr_pe < avg_5yr) 
            
            sell_condition_1 = curr_percentile > 0.75 
            sell_condition_2 = diff_pct > 30 
            
            if sell_condition_1 or sell_condition_2:
                current_decision_log.append(f"æ¡ä»¶: å–å‡ºæ¡ä»¶æ»¡è¶³ (åˆ†ä½ç‚¹ > 75% [{curr_percentile*100:.1f}%] æˆ–åç¦»åº¦ > 30% [{diff_pct:.1f}%])ã€‚")
                if current_holdings > 0: 
                    signal = "ğŸ”´ å»ºè®®å–å‡º"
                    current_decision_log.append("ç»“æœ: å»ºè®®å–å‡ºã€‚")
                else: 
                    signal = "ğŸ”´ å»ºè®®å–å‡º (æ— æŒä»“)ã€‚"
            
            elif buy_condition_1 or buy_condition_2:
                current_decision_log.append(f"æ¡ä»¶: ä¹°å…¥æ¡ä»¶æ»¡è¶³ (åˆ†ä½ç‚¹ < 20% [{curr_percentile*100:.1f}%] æˆ– PE < 3/5å¹´å‡å€¼)ã€‚")
                
                suppress_by_step = False
                if current_holdings > 0 and last_buy_pe is not None:
                    # V22.0: ä½¿ç”¨åŠ¨æ€ STEP_PERCENT
                    required_entry_pe = last_buy_pe * (1 - STEP_PERCENT)
                    current_decision_log.append(f"é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥: ä¸Šæ¬¡ä¹°å…¥PE {last_buy_pe:.2f}, ä¸‹æ¬¡ä¹°å…¥PEé˜ˆå€¼ {required_entry_pe:.2f} (è¦æ±‚è·Œå¹… â‰¥ {STEP_PERCENT*100:.0f}%)ã€‚")
                    if curr_pe > required_entry_pe:
                        suppress_by_step = True
                        current_decision_log.append(f"ç»“æœ: è·Œå¹…ä¸è¶³ {STEP_PERCENT*100:.0f}%ï¼ŒæŠ‘åˆ¶ä¹°å…¥ã€‚")
                else:
                    current_decision_log.append(f"é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥: æ— æŒä»“æˆ–æ— ä¸Šæ¬¡ä¹°å…¥PEï¼Œä¸æ£€æŸ¥è·Œå¹…é™åˆ¶ã€‚")
                        
                if suppress_by_step:
                    signal = f"â¸ï¸ è§‚æœ› (è·Œå¹…ä¸è¶³ {STEP_PERCENT*100:.0f}%)"
                elif current_holdings < MAX_UNITS:
                    signal = "ğŸŸ¢ å»ºè®®ä¹°å…¥"
                    current_decision_log.append("ç»“æœ: å»ºè®®ä¹°å…¥ã€‚")
                else:
                    signal = "ğŸŸ¢ å»ºè®®ä¹°å…¥ (å·²æ»¡ä»“)"
                    current_decision_log.append("ç»“æœ: å»ºè®®ä¹°å…¥ (å·²æ»¡ä»“)ã€‚")
            else:
                current_decision_log.append("æ¡ä»¶: æ— æ˜ç¡®ä¹°å…¥/å–å‡ºä¿¡å·ã€‚")
            
        decision_logs[code] = current_decision_log
        
        
        table_data.append({
            "æŒ‡æ•°åç§°": name,
            "å½“å‰PE": f"{curr_pe:.2f}", 
            "PEåˆ†ä½ç‚¹": f"{curr_percentile * 100:.1f}%", 
            "åç¦»åº¦(3å¹´%)": f"{diff_pct:.1f}%" if not np.isnan(diff_pct) else 'â€”',
            
            # === æ–°å¢ï¼šæœ€å¤§/æœ€å°åç¦» ===
            "æœ€å¤§åç¦»(3å¹´)": f"{max_dev:.1f}%" if not np.isnan(max_dev) else 'â€”',
            "æœ€å°åç¦»(3å¹´)": f"{min_dev:.1f}%" if not np.isnan(min_dev) else 'â€”',
            # =========================
            
            "å»ºè®®ä¿¡å·": signal,
            "ä¸Šæ¬¡æ“ä½œè·ä»Š(å¤©)": days_since_last_op_display,
            "å¹³å‡æˆæœ¬(ETF)": avg_cost_display,
            "æµ®åŠ¨ç›ˆäº(%)": pl_pct_display,
            "å½“å‰æŒä»“(ä»½é¢)": f"{current_holdings:.2f}", # æ”¹åï¼šä»½é¢
            "ä¸Šæ¬¡æ“ä½œæ—¥æœŸ": last_date, 
            "ä¸Šæ¬¡æ“ä½œPE": f"{last_pe:.2f}" if not np.isnan(last_pe) else 'â€”', 
        })
        
    else:
        # ... (æ•°æ®åŠ è½½å¤±è´¥å¤„ç†ä¿æŒä¸å˜) ...
        decision_logs[code] = ["æ•°æ®å¤„ç†å¤±è´¥æˆ–æ–‡ä»¶ç¼ºå¤±ï¼Œæ— æ³•è¯„ä¼°ç­–ç•¥ã€‚"]
        table_data.append({
            "æŒ‡æ•°åç§°": name, 
            "å»ºè®®ä¿¡å·": "âš ï¸ æ•°æ®å¤„ç†å¤±è´¥/æ–‡ä»¶ç¼ºå¤±",
            "PEåˆ†ä½ç‚¹": "â€”", "åç¦»åº¦(3å¹´%)": "â€”", "å½“å‰PE": "â€”", 
            "ä¸Šæ¬¡æ“ä½œè·ä»Š(å¤©)": 'â€”',
            "å¹³å‡æˆæœ¬(ETF)": 'â€”', "æµ®åŠ¨ç›ˆäº(%)": 'â€”',
            "å½“å‰æŒä»“(ä»½)": f"{s['holdings']:.1f}", 
            "ä¸Šæ¬¡æ“ä½œæ—¥æœŸ": last_date, "ä¸Šæ¬¡æ“ä½œPE": "â€”"
        })

progress_bar.empty()

# === æ–°å¢ï¼šä¾§è¾¹æ æŒä»“åˆ†å¸ƒå›¾ ===
with st.sidebar:
    st.markdown("---")
    st.markdown("### ğŸ° æŒä»“åˆ†å¸ƒ (å¸‚å€¼)")
    if pie_chart_data:
        import plotly.express as px
        df_pie = pd.DataFrame(pie_chart_data)
        # è¿‡æ»¤æ‰ 0 å€¼
        df_pie = df_pie[df_pie['value'] > 0]
        if not df_pie.empty:
            fig_pie = px.pie(df_pie, values='value', names='name', hole=0.4)
            fig_pie.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0), height=250)
            st.plotly_chart(fig_pie, use_container_width=True)
            
            total_asset = df_pie['value'].sum()
            st.caption(f"æ€»æŒä»“å¸‚å€¼ä¼°ç®—: Â¥{total_asset:,.0f}")
        else:
            st.info("æš‚æ— æŒä»“æ•°æ®")
    else:
        st.info("æš‚æ— æŒä»“æ•°æ®")
# ==============================


# --- æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜çŠ¶æ€å’Œé‡æ–°è¿è¡Œ (V22.0 ä¼˜åŒ–) ---
if updated_records_count > 0:
    save_state(state) # ä»…ä¿å­˜å†å²è®°å½•ï¼ŒæŒä»“å’Œæˆæœ¬å·²åœ¨ load æ—¶é‡æ–°è®¡ç®—
    st.success(f"âœ… å·²è‡ªåŠ¨è¡¥å½• {updated_records_count} æ¡äº¤æ˜“è®°å½•çš„ PE/ç‚¹ä½æ•°æ®!")
    st.cache_data.clear() 
    time.sleep(1)
    st.rerun()

# ... (æ ¸å¿ƒæŒ‡æ ‡æ˜¾ç¤ºåŒºä¿æŒä¸å˜) ...

# --- æ ¸å¿ƒæŒ‡æ ‡æ˜¾ç¤ºåŒº (é¡¶éƒ¨å¢åŠ æ•´ä½“ä»“ä½æŒ‡æ ‡) ---
st.subheader("æ ¸å¿ƒæŒ‡æ ‡")
col_overall_pos, col_curr_pe, col_percentile, col_deviation = st.columns([1,1,1,1]) 

with col_overall_pos.container(border=True):
    st.markdown("### ğŸŒ æ•´ä½“ä»“ä½æŒ‡æ ‡")
    if not np.isnan(overall_pe_percentile):
        overall_position_str = f"{overall_position_pct:.1f}%"
        st.metric(label="å»ºè®®æ•´ä½“ä»“ä½ (1-å¤§ç›˜åˆ†ä½)", value=overall_position_str)
        if overall_position_pct > 75:
            st.success("å¸‚åœºæ•´ä½“ä½ä¼°ï¼Œå¯ç§¯æå¸ƒå±€ã€‚")
        elif overall_position_pct < 25:
            st.error("å¸‚åœºæ•´ä½“é«˜ä¼°ï¼Œæ³¨æ„é£é™©ã€‚")
        else:
            st.info("å¸‚åœºä¼°å€¼é€‚ä¸­ã€‚")
    else:
        st.info("å¤§ç›˜æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®—ã€‚")

with col_curr_pe.container(border=True):
    st.markdown(f"### ğŸ¯ å½“å‰æŒ‡æ•°æ€»æ•°")
    st.metric(label="ç›‘æ§ä¸­æŒ‡æ•°æ•°é‡", value=len(TARGETS))
    st.markdown("æ•°æ®é©±åŠ¨æ‚¨çš„åˆ†æ•£æŠ•èµ„å†³ç­–ã€‚")

with col_percentile.container(border=True):
    st.markdown("### ğŸ“ˆ PEåˆ†ä½ç‚¹")
    st.info("ç»¿è‰²: <20% (ä½ä¼°) | çº¢è‰²: >80% (é«˜ä¼°)")
    st.markdown("è¯„ä¼°å½“å‰ä¼°å€¼åœ¨å†å²ä¸Šçš„ç›¸å¯¹ä½ç½®ã€‚")

with col_deviation.container(border=True):
    st.markdown("### ğŸ’¡ å»ºè®®ä¿¡å·")
    st.success("ğŸŸ¢: å»ºè®®ä¹°å…¥")
    st.error("ğŸ”´: å»ºè®®å–å‡º")
    st.markdown("åŸºäºå¤šé‡æŒ‡æ ‡(3/5å¹´å‡å€¼, åˆ†ä½ç‚¹)ç”Ÿæˆçš„ç­–ç•¥å»ºè®®ã€‚")

st.markdown("---")

st.subheader("ğŸ“‹ æŒ‡æ•°ä¼°å€¼ä¸ç­–ç•¥æ€»è§ˆ")

df_display = pd.DataFrame(table_data)

st.dataframe(
    df_display.style
        .applymap(highlight_signal, subset=['å»ºè®®ä¿¡å·'])
        .applymap(highlight_percentile, subset=['PEåˆ†ä½ç‚¹'])
        .applymap(highlight_pl, subset=['æµ®åŠ¨ç›ˆäº(%)']),
    use_container_width=True,
    height=500
)



# --- è¯¦ç»†çš„å†³ç­–ä¾æ®æ˜¾ç¤º (ä¿®æ”¹ç‰ˆï¼šä¸‹æ‹‰èœå•é€‰æ‹©) ---
st.markdown("---")
st.subheader("ğŸ” è¯¦ç»†å†³ç­–ä¾æ®")

# åˆ›å»ºä¸¤åˆ—ï¼Œå·¦ä¾§æ”¾é€‰æ‹©æ¡†ï¼Œå³ä¾§ç•™ç™½
col_log_select, _ = st.columns([1, 2])

with col_log_select:
    # è·å–æœ‰æ—¥å¿—çš„æŒ‡æ•°åˆ—è¡¨
    log_options = list(TARGETS.values())
    selected_log_name = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹å†³ç­–è¯¦æƒ…çš„æŒ‡æ•°ï¼š", log_options)

# æ ¹æ®åç§°æ‰¾åˆ°å¯¹åº”çš„ Key
selected_log_key = next((k for k, v in TARGETS.items() if v == selected_log_name), None)

with st.container(border=True):
    if selected_log_key and selected_log_key in decision_logs:
        st.markdown(f"#### {selected_log_name} ç­–ç•¥è¯„ä¼°æ—¥å¿—")
        for log_entry in decision_logs[selected_log_key]:
            #ç®€å•çš„æ ¼å¼åŒ–ï¼šæ ¹æ®å…³é”®è¯åŠ é¢œè‰²
            if "å»ºè®®ä¹°å…¥" in log_entry:
                st.markdown(f"- :green[{log_entry}]")
            elif "å»ºè®®å–å‡º" in log_entry:
                st.markdown(f"- :red[{log_entry}]")
            elif "è§‚æœ›" in log_entry:
                st.markdown(f"- :orange[{log_entry}]")
            else:
                st.markdown(f"- {log_entry}")
    else:
        st.info("è¯¥æŒ‡æ•°æš‚æ— å†³ç­–æ—¥å¿—ä¿¡æ¯ã€‚")

            

# --- äº¤æ˜“ç™»è®°é€»è¾‘ (æ–°å¢äº¤æ˜“ç®¡ç† - V23.4 å‡çº§ï¼šæ‰¹é‡å¯¼å…¥æ”¯æŒå¤šæŒ‡æ•°) ---
st.markdown("---")
st.header("ğŸ›’ äº¤æ˜“ç™»è®°ä¸ç®¡ç† (æœ¬åœ°æ–‡ä»¶æ¨¡å¼)")

# V23.4: æ–°å¢ "æ‰¹é‡å¯¼å…¥" æ ‡ç­¾é¡µ
tab_record, tab_manage, tab_import = st.tabs(["ğŸ“ ç™»è®°æ–°äº¤æ˜“", "âš™ï¸ ç®¡ç†/ä¿®æ”¹è®°å½•", "ğŸ“¤ æ‰¹é‡å¯¼å…¥"])

# å‡†å¤‡æŒ‡æ•°åç§°åˆ°æ–‡ä»¶åçš„åå‘æ˜ å°„ï¼Œç”¨äºå¯¼å…¥æŸ¥æ‰¾
TARGETS_REVERSE = {v: k for k, v in TARGETS.items()}


# ======================= Tab 1: ç™»è®°æ–°äº¤æ˜“ (ä¿æŒä¸å˜) =======================
with tab_record:
    # ç§»é™¤ FIXED_AMOUNT_PER_PORTION å’Œ MAX_UNITS çš„å¼•ç”¨å’Œæ˜¾ç¤º
    st.markdown("---")

    with st.container(border=True):
        # è°ƒæ•´åˆ—å®½ä»¥æ›´å¥½åœ°é€‚åº”ä»½é¢è¾“å…¥æ¨¡å¼
        col1, col2, col_fund, col3, col4 = st.columns([2, 1.5, 2.5, 2, 2.5])

        name_options = list(TARGETS.values())

        with col1:
            selected_name_r = st.selectbox("é€‰æ‹©æŒ‡æ•°", name_options, key="select_record_index")
            selected_file_r = next(f for f, n in TARGETS.items() if n == selected_name_r)
            # V23.4: æ˜¾ç¤ºå½“å‰æŒæœ‰ä»½é¢ï¼Œä¸å†æ˜¾ç¤ºä»½æ•°
            current_holdings = state[selected_file_r].get('holdings', 0.0)
            st.markdown(f"**å½“å‰æŒæœ‰ä»½é¢:** `{current_holdings:.2f} ä»½`")


        with col2:
            action_r = st.selectbox("æ“ä½œç±»å‹", ["ä¹°å…¥", "å–å‡º"], key="select_action")

        with col_fund:
            # V23.3 æ–°å¢å­—æ®µï¼šåŸºé‡‘åç§°/ä»£ç 
            fund_name_r = st.text_input("åŸºé‡‘åç§°/ä»£ç  (ä¾‹: 513050)", value="", key="input_fund_name")

        with col3:
            trade_date_r = st.date_input("æˆäº¤æ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date(), key="input_date")
            trade_date_str_r = trade_date_r.strftime("%Y-%m-%d")

        with col4:
            trade_price_r = st.number_input("åŸºé‡‘å‡€å€¼/æˆäº¤ä»·", min_value=0.0001, format="%.4f", value=1.0000, step=0.0001, key="input_price")

            # === æ ¸å¿ƒä¿®æ”¹ï¼šè¾“å…¥å…·ä½“ä»½é¢ ===
            trade_unit_r = st.number_input("äº¤æ˜“ä»½é¢ (Shares)", min_value=0.01, value=100.0, step=10.0, format="%.2f", key="input_unit")

            # å®æ—¶è®¡ç®—é¢„ä¼°é‡‘é¢æ˜¾ç¤ºç»™ç”¨æˆ·çœ‹
            est_amount = trade_price_r * trade_unit_r
            st.caption(f"äº¤æ˜“é‡‘é¢: Â¥{est_amount:,.2f}")

    if st.button("æäº¤æ–°è®°å½•", type="primary", use_container_width=True):

        # --- äº¤æ˜“å‰æ•°æ®å‡†å¤‡ ---
        s = state[selected_file_r]
        df_selected_r = full_data_frames.get(selected_file_r)

        if not fund_name_r.strip():
            st.error("è¯·è¾“å…¥åŸºé‡‘åç§°/ä»£ç ï¼Œä»¥ä¾¿åŒºåˆ†è¿½è¸ªåŒä¸€æŒ‡æ•°çš„ä¸åŒåŸºé‡‘ï¼")
            # ä¸åœæ­¢ç¨‹åºï¼Œåªæ˜¾ç¤ºé”™è¯¯

        elif df_selected_r is None:
            st.error(f"âš ï¸ æ— æ³•æäº¤è®°å½•ï¼šæ•°æ®æ–‡ä»¶ {selected_file_r} è¯»å–å¤±è´¥ã€‚")

        else:
            # æŸ¥æ‰¾ PE/Close
            trade_pe_r, trade_close_r = find_pe_by_date(df_selected_r, trade_date_str_r)
            saved_pe_r = round(trade_pe_r, 2) if not np.isnan(trade_pe_r) else None
            saved_close_r = round(trade_close_r, 2) if not np.isnan(trade_close_r) else None

            # --- æ ¸å¿ƒä¹°å–é€»è¾‘ (V23.4: ä»½é¢æ¨¡å¼) ---
            if action_r == "ä¹°å…¥":
                transaction_r = {
                    "date": trade_date_str_r, "type": action_r, "pe": saved_pe_r,
                    "close": saved_close_r, "price": trade_price_r,
                    "unit": trade_unit_r,   # ç›´æ¥å­˜å…¥è¾“å…¥çš„ä»½é¢
                    "fund_name": fund_name_r,
                    "portions": 0           # åºŸå¼ƒå­—æ®µ
                }
                s["history"].append(transaction_r)

                # é‡æ–°è®¡ç®—å¹¶ä¿å­˜
                state = recalculate_holdings_and_cost(state)
                if save_state(state):
                    st.success(f"âœ… å·²è®°å½•ï¼š{selected_name_r} ä¹°å…¥{trade_unit_r:.2f} ä»½é¢ã€‚")

            elif action_r == "å–å‡º":
                # æ£€æŸ¥æŒä»“æ˜¯å¦è¶³å¤Ÿ
                if current_holdings >= trade_unit_r:
                    transaction_r = {
                        "date": trade_date_str_r, "type": action_r, "pe": saved_pe_r,
                        "close": saved_close_r, "price": trade_price_r,
                        "unit": trade_unit_r,   # ç›´æ¥å­˜å…¥è¾“å…¥çš„ä»½é¢
                        "fund_name": fund_name_r,
                        "portions": 0
                    }
                    s["history"].append(transaction_r)

                    # é‡æ–°è®¡ç®—å¹¶ä¿å­˜
                    state = recalculate_holdings_and_cost(state)
                    if save_state(state):
                        st.warning(f"âš ï¸ å·²è®°å½•ï¼š{selected_name_r} å–å‡º{trade_unit_r:.2f} ä»½é¢ã€‚")
                else:
                    st.error(f"ä»½é¢ä¸è¶³ï¼å½“å‰æŒæœ‰ {current_holdings:.2f} ä»½é¢ï¼Œæ— æ³•å–å‡º {trade_unit_r} ä»½é¢ã€‚")

            # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæœ€æ–°æŒä»“
            time.sleep(1)
            st.cache_data.clear()
            st.rerun()

st.markdown("---")
st.subheader("å†å²äº¤æ˜“è®°å½• (æ¥è‡ªæœ¬åœ°æ–‡ä»¶)")


# å†å²è®°å½•æ˜¾ç¤º
if 'select_record_index' in st.session_state and st.session_state.select_record_index:
    selected_name = st.session_state.select_record_index
    selected_file = next(f for f, n in TARGETS.items() if n == selected_name)
    holding_info = state[selected_file]

    if holding_info['history']:
        # ç¡®ä¿ date å­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼Œé¿å… to_datetime è½¬æ¢é—®é¢˜
        df_history = pd.DataFrame([
            {**h, 'date': h['date'].strftime('%Y-%m-%d') if hasattr(h['date'], 'strftime') else h['date']}
            for h in holding_info['history']
        ])

        # V23.4: åªä¿ç•™ 'unit' å’Œ 'fund_name'
        df_display_history = df_history[['date', 'type', 'fund_name', 'price', 'unit', 'pe', 'close']].copy()
        df_display_history = df_display_history.rename(columns={
            'date': 'æˆäº¤æ—¥æœŸ', 'type': 'æ“ä½œç±»å‹', 'fund_name': 'åŸºé‡‘ä»£ç /åç§°', 'price': 'ETFæˆäº¤ä»·',
            'unit': 'åŸºé‡‘ä»½é¢', 'pe': 'æˆäº¤PE(è‡ªåŠ¨)', 'close': 'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)'
        })

        df_display_history = df_display_history.iloc[::-1] # å€’åºæ˜¾ç¤ºï¼Œæœ€æ–°è®°å½•åœ¨å‰

        st.dataframe(
            df_display_history.style.format({
                'ETFæˆäº¤ä»·': "Â¥ {:.4f}",
                'åŸºé‡‘ä»½é¢': "{:.2f}",
                'æˆäº¤PE(è‡ªåŠ¨)': "{:.2f}",
                'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)': "{:.2f}"
            }, na_rep='N/A'),
            use_container_width=True,
            hide_index=True
        )
    else:
        st.info(f"å½“å‰ {selected_name} æ²¡æœ‰äº¤æ˜“è®°å½•ã€‚")
else:
    st.info("è¯·åœ¨ä¸Šæ–¹é€‰æ‹©ä¸€ä¸ªæŒ‡æ•°ä»¥æŸ¥çœ‹å…¶å†å²äº¤æ˜“è®°å½•ã€‚")
# ======================= Tab 2: ç®¡ç†/ä¿®æ”¹äº¤æ˜“è®°å½• (ä¿æŒä¸å˜) =======================
with tab_manage:
    st.markdown("âš ï¸ **å±é™©æ“ä½œï¼** åˆ é™¤å’Œä¿®æ”¹è®°å½•å°†ç›´æ¥å½±å“æŒä»“å’Œæˆæœ¬è®¡ç®—ã€‚")

    name_options_m = list(TARGETS.values())
    selected_name_m = st.selectbox("é€‰æ‹©è¦ç®¡ç†è®°å½•çš„æŒ‡æ•°", name_options_m, key="select_manage_index_m") # ç¡®ä¿ key å”¯ä¸€
    selected_file_m = next(f for f, n in TARGETS.items() if n == selected_name_m)
    
    s_m = state[selected_file_m]
    
    if not s_m['history']:
        st.info("è¯¥æŒ‡æ•°å°šæ— äº¤æ˜“è®°å½•å¯ä¾›ç®¡ç†ã€‚")
    else:
        # å°†å†å²è®°å½•è½¬æ¢ä¸º DataFrame ä»¥ä¾¿å±•ç¤ºç´¢å¼•
        history_df_m_list = [{**h, 'date': h['date'].strftime('%Y-%m-%d') if hasattr(h['date'], 'strftime') else h['date']} for h in s_m['history']]
        history_df_m = pd.DataFrame(history_df_m_list)
        history_df_m['ç´¢å¼•'] = history_df_m.index # æ·»åŠ ç´¢å¼•åˆ—ç”¨äºè¯†åˆ«è®°å½•
        
        # V23.3: å¢åŠ  'portions' å’Œ 'fund_name' åˆ—æ˜¾ç¤º
        df_display_m = history_df_m[['ç´¢å¼•', 'date', 'type', 'portions', 'fund_name', 'price', 'unit', 'pe', 'close']].copy()
        df_display_m = df_display_m.rename(columns={'date': 'æˆäº¤æ—¥æœŸ', 'type': 'æ“ä½œç±»å‹', 'portions': 'äº¤æ˜“ä»½æ•°(300å…ƒ/ä»½)', 'fund_name': 'åŸºé‡‘ä»£ç /åç§°', 'price': 'ETFæˆäº¤ä»·', 'unit': 'åŸºé‡‘ä»½é¢', 'pe': 'æˆäº¤PE(è‡ªåŠ¨)', 'close': 'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)'})
        
        # æ ¼å¼åŒ– PE/Close/Price
        for col in ['ETFæˆäº¤ä»·', 'æˆäº¤PE(è‡ªåŠ¨)', 'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)', 'åŸºé‡‘ä»½é¢', 'äº¤æ˜“ä»½æ•°(300å…ƒ/ä»½)']:
             if col in df_display_m.columns:
                 if col == 'ETFæˆäº¤ä»·':
                     df_display_m[col] = df_display_m[col].apply(lambda x: f"{x:.4f}" if pd.notna(x) and x is not None else 'N/A')
                 else:
                     df_display_m[col] = df_display_m[col].apply(lambda x: f"{x:.2f}" if pd.notna(x) and x is not None else 'N/A')
        
        st.dataframe(df_display_m, use_container_width=True, hide_index=True)

        # --- åˆ é™¤æ“ä½œ ---
        st.subheader("åˆ é™¤è®°å½•")
        col_del, col_button_del = st.columns([1, 1])
        with col_del:
            index_to_delete = st.number_input("è¾“å…¥è¦åˆ é™¤çš„è®°å½•è¡Œç´¢å¼• (æœ€å·¦ä¾§åˆ—)", min_value=0, max_value=len(history_df_m) - 1, step=1, key="delete_index")
        
        with col_button_del:
            st.markdown("##### ")
            if st.button(f"ğŸ”´ ç¡®è®¤åˆ é™¤ç¬¬ {index_to_delete} è¡Œè®°å½•", key="confirm_delete_button"):
                if 0 <= index_to_delete < len(s_m['history']):
                    del s_m['history'][index_to_delete]
                    state = recalculate_holdings_and_cost(state) # ç«‹å³é‡æ–°è®¡ç®—
                    save_state(state) # ä¿å­˜åˆ°æœ¬åœ° JSON æ–‡ä»¶
                    st.success(f"âœ… è®°å½• {index_to_delete} å·²åˆ é™¤ï¼ŒæŒä»“å·²é‡æ–°è®¡ç®—ã€‚")
                    time.sleep(1)
                    st.cache_data.clear()  
                    st.rerun()
                else:
                    st.error("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")

        st.markdown("---")
        
        # --- ä¿®æ”¹æ“ä½œ (V23.3: éœ€åŒæ—¶ä¿®æ”¹ portions, unit, fund_name) ---
        st.subheader("ä¿®æ”¹è®°å½•")
        
        df_selected_m = full_data_frames.get(selected_file_m)

        col_mod_index, col_mod_type, col_mod_date, col_mod_price = st.columns(4)
        
        # 1. é€‰æ‹©è¦ä¿®æ”¹çš„ç´¢å¼•
        with col_mod_index:
            index_to_modify = st.number_input("è¾“å…¥è¦ä¿®æ”¹çš„è®°å½•è¡Œç´¢å¼•", min_value=0, max_value=len(history_df_m) - 1, step=1, key="modify_index")
        
        if 0 <= index_to_modify < len(s_m['history']):
            record_to_modify = s_m['history'][index_to_modify]
            
            # 2. ä¿®æ”¹æ“ä½œç±»å‹
            with col_mod_type:
                new_type = st.selectbox("æ–°æ“ä½œç±»å‹", ["ä¹°å…¥", "å–å‡º"], index=0 if record_to_modify.get('type') == 'ä¹°å…¥' else 1, key="modify_type")

            # 3. ä¿®æ”¹æˆäº¤æ—¥æœŸ
            with col_mod_date:
                try:
                    current_date = datetime.strptime(record_to_modify.get('date'), "%Y-%m-%d").date()
                except:
                    current_date = datetime.now().date()
                new_date = st.date_input("æ–°æˆäº¤æ—¥æœŸ", value=current_date, max_value=datetime.now().date(), key="modify_date")
                new_date_str = new_date.strftime("%Y-%m-%d")

            # 4. ä¿®æ”¹ ETF ä»·æ ¼å’Œä»½æ•°/ä»½é¢
            with col_mod_price:
                new_price = st.number_input("æ–°ETFæˆäº¤ä»·", min_value=0.0001, format="%.4f", value=record_to_modify.get('price', 1.0000), step=0.0001, key="modify_price")
            
            # V23.3: å…è®¸ç”¨æˆ·ç›´æ¥ä¿®æ”¹ 'portions' (ä»½æ•°)
            new_portions = st.number_input("æ–°äº¤æ˜“ä»½æ•° (300å…ƒ/ä»½)", min_value=1, value=int(record_to_modify.get('portions', 1)), step=1, key="modify_portions")
            
            # V23.3: å…è®¸ç”¨æˆ·ç›´æ¥ä¿®æ”¹ 'unit' (åŸºé‡‘ä»½é¢)
            new_unit = st.number_input("æ–°åŸºé‡‘ä»½é¢ (ä»…ç”¨äºå–å‡ºå¹³å‡ä»½é¢å¤±è´¥æ—¶æ‰‹åŠ¨è°ƒæ•´)", min_value=0.0, value=record_to_modify.get('unit', 1.0), step=0.01, key="modify_unit")
            
            # V23.3: å…è®¸ä¿®æ”¹åŸºé‡‘ä»£ç /åç§°
            new_fund_name = st.text_input("æ–°åŸºé‡‘ä»£ç /åç§°", value=record_to_modify.get('fund_name', ''), key="modify_fund_name")

            if st.button(f"ğŸŸ¡ ç¡®è®¤ä¿®æ”¹ç¬¬ {index_to_modify} è¡Œè®°å½•", key="confirm_modify_button"):
                
                # é‡æ–°æŸ¥æ‰¾æ–°çš„ PE/Close
                trade_pe_mod, trade_close_mod = find_pe_by_date(df_selected_m, new_date_str)
                saved_pe_mod = round(trade_pe_mod, 2) if not np.isnan(trade_pe_mod) else None
                saved_close_mod = round(trade_close_mod, 2) if not np.isnan(trade_close_mod) else None

                # V23.3: æ ¸å¿ƒä¿®æ”¹é€»è¾‘
                if new_type == 'ä¹°å…¥':
                     # é‡æ–°è®¡ç®—åŸºé‡‘ä»½é¢: ä»½æ•° * é‡‘é¢ / ä»·æ ¼
                     final_unit = (new_portions * FIXED_AMOUNT_PER_PORTION) / new_price
                elif new_type == 'å–å‡º':
                     final_unit = new_unit 
                     st.warning("âš ï¸ å–å‡ºè®°å½•ä¿®æ”¹æ—¶ï¼ŒåŸºé‡‘ä»½é¢(unit)ä¸ä¼šè‡ªåŠ¨é‡æ–°è®¡ç®—å¹³å‡ä»½é¢ã€‚è¯·ç¡®è®¤æ‚¨è¾“å…¥çš„ 'æ–°åŸºé‡‘ä»½é¢' æ˜¯æ­£ç¡®çš„ã€‚")
                else:
                     final_unit = new_unit
                     
                # æ›´æ–°è®°å½•
                s_m['history'][index_to_modify] = {
                    "date": new_date_str,
                    "type": new_type,
                    "pe": saved_pe_mod, 
                    "close": saved_close_mod,
                    "price": new_price, 
                    "unit": final_unit, # æœ€ç»ˆåŸºé‡‘ä»½é¢
                    "portions": new_portions, # æœ€ç»ˆä»½æ•°
                    "fund_name": new_fund_name # åŸºé‡‘åç§°
                }

                state = recalculate_holdings_and_cost(state)
                save_state(state)
                st.success(f"âœ… è®°å½• {index_to_modify} å·²æ›´æ–°å¹¶é‡æ–°è®¡ç®—æŒä»“ã€‚")
                time.sleep(1)
                st.cache_data.clear() 
                st.rerun()
        else:
            if len(s_m['history']) > 0:
                st.error("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
# ======================= Tab 3: æ‰¹é‡å¯¼å…¥ (V23.4.1 ä¿®å¤ openpyxl ä¾èµ–é—®é¢˜) =======================

with tab_import:
    st.header("ğŸ“¤ æ‰¹é‡å¯¼å…¥äº¤æ˜“è®°å½•")
    st.markdown("---")
    # æç¤ºç”¨æˆ·æ–‡ä»¶æ ¼å¼ï¼Œå·²åŒ…å« 'ä»½é¢' åˆ—
    st.info("è¯·ç¡®ä¿æ‚¨çš„å¯¼å…¥æ–‡ä»¶åŒ…å«ä»¥ä¸‹è¡¨å¤´ï¼š**`æ—¥æœŸ`**, **`æ“ä½œç±»å‹`**, **`å‡€å€¼`**, **`ä»½é¢`**, **`åŸºé‡‘ä»£ç `**, **`æ‰€å±æŒ‡æ•°`**ã€‚")
    # ç§»é™¤å…³äº FIXED_AMOUNT_PER_PORTION çš„æç¤º

    uploaded_file = st.file_uploader("é€‰æ‹©äº¤æ˜“è®°å½•æ–‡ä»¶ (.csv æˆ– .xlsx)", type=["csv", "xlsx"])

    if uploaded_file is not None:
        df_import = None
        file_ext = uploaded_file.name.split('.')[-1].lower()

        try:
            # --- æ–‡ä»¶è¯»å–é€»è¾‘ (V23.4.1 æ”¹è¿›é”™è¯¯å¤„ç†) ---
            if file_ext == 'csv':
                df_import = pd.read_csv(uploaded_file)
            elif file_ext == 'xlsx':
                try:
                    df_import = pd.read_excel(uploaded_file)
                except ImportError as ie:
                    # æ•è· openpyxl ç¼ºå¤±çš„é”™è¯¯
                    if 'openpyxl' in str(ie):
                        st.error("æ— æ³•è¯»å– .xlsx æ–‡ä»¶ã€‚ç¼ºå°‘ä¾èµ– 'openpyxl'ã€‚")
                        st.warning("æ‚¨éœ€è¦åœ¨æ‚¨çš„ç¯å¢ƒä¸­å®‰è£… openpyxl åº“ (`pip install openpyxl`)ï¼Œ**æˆ–è€…**è¯·å°†æ‚¨çš„æ–‡ä»¶ä¿å­˜ä¸º **.csv** æ ¼å¼åé‡æ–°ä¸Šä¼ ã€‚")
                        st.stop()
                    else:
                        raise # Re-raise if it's another import error
                except Exception as e:
                    st.error(f"è¯»å– .xlsx æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    st.stop()
            else:
                st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚è¯·ä¸Šä¼  .csv æˆ– .xlsx æ–‡ä»¶ã€‚")
                st.stop()

            # Check if df_import was successfully created and is not empty
            if df_import is None or df_import.empty:
                st.error("æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•è§£æã€‚")
                st.stop()

            # === ä¿®æ”¹ï¼šåˆ—éªŒè¯åŠ å…¥ 'ä»½é¢' ===
            required_cols = ['æ—¥æœŸ', 'æ“ä½œç±»å‹', 'å‡€å€¼', 'ä»½é¢', 'åŸºé‡‘ä»£ç ', 'æ‰€å±æŒ‡æ•°']
            if not all(col in df_import.columns for col in required_cols):
                st.error(f"å¯¼å…¥å¤±è´¥ï¼šç¼ºå¤±å¿…éœ€åˆ—ã€‚è¯·åŒ…å«: {required_cols}")
                st.stop()

            df_import = df_import[required_cols].dropna(subset=required_cols)
            df_import.columns = ['date_str', 'type', 'price', 'unit', 'fund_name', 'index_name']

            st.subheader("å¾…å¯¼å…¥è®°å½•é¢„è§ˆ")
            st.dataframe(df_import)

            # 2. ç¡®è®¤æŒ‰é’®
            if st.button(f"ç¡®è®¤å¯¼å…¥ {len(df_import)} æ¡è®°å½•", type="primary", use_container_width=True):

                # æš‚å­˜æ‰€æœ‰æ–°äº¤æ˜“ï¼ŒæŒ‰æŒ‡æ•°åˆ†ç»„
                new_transactions_by_index = {index_key: [] for index_key in TARGETS.keys()}
                total_transactions_processed = 0

                # --- äº¤æ˜“å¤„ç†ï¼šç¬¬ä¸€éï¼Œæ”¶é›†å¹¶è®¡ç®—ä»½é¢ ---
                for index, row in df_import.iterrows():

                    try:
                        date_obj = pd.to_datetime(row['date_str']).date()
                        date_str = date_obj.strftime("%Y-%m-%d")
                        trade_type = row['type'].strip()
                        trade_price = float(row['price'])
                        trade_unit = float(row['unit']) # ç›´æ¥è¯»å–ä»½é¢
                        fund_name = str(row['fund_name']).strip()
                        index_name = str(row['index_name']).strip() # V23.4: è¯»å–æŒ‡æ•°åç§°

                        # V23.4: æ ¸å¿ƒæ˜ å°„
                        index_key = TARGETS_REVERSE.get(index_name)

                        if not index_key:
                            st.warning(f"è·³è¿‡ç¬¬ {index+1} è¡Œï¼šæŒ‡æ•°åç§° '{index_name}' åœ¨é…ç½®ä¸­ä¸å­˜åœ¨ã€‚")
                            continue

                        if trade_type not in ['ä¹°å…¥', 'å–å‡º']:
                            st.warning(f"è·³è¿‡ç¬¬ {index+1} è¡Œï¼šæ“ä½œç±»å‹ '{trade_type}' æ— æ•ˆã€‚")
                            continue

                        df_full = full_data_frames.get(index_key)
                        if df_full is None:
                            st.warning(f"è·³è¿‡ç¬¬ {index+1} è¡Œï¼šæŒ‡æ•°æ•°æ®æ–‡ä»¶ {index_key} æœªåŠ è½½ï¼Œæ— æ³•å›å¡« PEã€‚")
                            continue

                        # æŸ¥æ‰¾ PE/Close
                        trade_pe, trade_close = find_pe_by_date(df_full, date_str)
                        saved_pe = round(trade_pe, 2) if not np.isnan(trade_pe) else None
                        saved_close = round(trade_close, 2) if not np.isnan(trade_close) else None

                        # --- æ ¸å¿ƒé€»è¾‘ï¼šç›´æ¥ä½¿ç”¨å¯¼å…¥çš„ 'unit' (ä»½é¢) ---
                        new_transactions_by_index[index_key].append({
                            "date": date_str,
                            "type": trade_type,
                            "pe": saved_pe,
                            "close": saved_close,
                            "price": trade_price,
                            "unit": trade_unit,   # ä½¿ç”¨å¯¼å…¥çš„ä»½é¢
                            "portions": 0,        # åºŸå¼ƒ
                            "fund_name": fund_name
                        })
                        total_transactions_processed += 1

                    except Exception as e:
                        st.error(f"å¤„ç†ç¬¬ {index+1} è¡Œ ({row['date_str']}) æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        continue

                # --- æœ€ç»ˆä¿å­˜ï¼šæŒ‰æŒ‡æ•°éå†å¹¶ä¿å­˜ ---

                saved_count = 0

                for index_key, new_tx_list in new_transactions_by_index.items():
                    if new_tx_list:
                        s = state[index_key]

                        # 1. é™„åŠ æ–°äº¤æ˜“
                        s['history'].extend(new_tx_list)

                        # 2. é‡æ–°è®¡ç®—æ‰€æœ‰æŒä»“ï¼ˆå…³é”®æ­¥éª¤ï¼‰
                        state = recalculate_holdings_and_cost(state)
                        saved_count += len(new_tx_list)

                if save_state(state):
                    st.success(f"âœ… æˆåŠŸå¯¼å…¥ {saved_count} æ¡è®°å½•ï¼æ•°æ®å·²é‡æ–°è®¡ç®—å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ã€‚")
                else:
                    st.error("âŒ å¯¼å…¥æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶å¤±è´¥ã€‚")

                time.sleep(1)
                st.cache_data.clear()
                st.rerun()

            else:
                st.info("æ²¡æœ‰æœ‰æ•ˆçš„è®°å½•è¢«å¯¼å…¥ã€‚")

        except Exception as e:
            # æ•è·é™¤ openpyxl ImportError ä¹‹å¤–çš„å…¶ä»–é”™è¯¯
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†å¤±è´¥ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚é”™è¯¯: {e}")
            st.warning("æç¤ºï¼šè¯·ç¡®ä¿æ‚¨çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ˆå¦‚æ—¥æœŸæ ¼å¼ï¼‰ï¼Œä¸” Excel æ–‡ä»¶ä¸­åªæœ‰**ä¸€ä¸ªå·¥ä½œè¡¨**ï¼Œè¡¨å¤´åœ¨**ç¬¬ä¸€è¡Œ**ã€‚")     
