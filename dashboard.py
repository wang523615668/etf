# dashboard.py (V22.0 - ç­–ç•¥å‚æ•°åŒ–ã€å›å¡«ä¼˜åŒ–ã€æˆæœ¬ç²¾ç¡®åŒ–)

import streamlit as st
import pandas as pd
import numpy as np
import json
import os
from datetime import datetime, timedelta
import time
import glob

# ================= é…ç½®åŒºåŸŸ (V22.0) =================

# å®Œæ•´çš„æŒ‡æ•°åˆ—è¡¨ (ä¿ç•™æ‚¨ V21.1 æä¾›çš„é…ç½®)
TARGETS = {
    "å¤§ç›˜.csv": "å¤§ç›˜æŒ‡æ•°",
    "æ²ªæ·±300.csv": "æ²ªæ·±300æŒ‡æ•°",
    "ä¸­è¯500.csv": "ä¸­è¯500æŒ‡æ•°",
    
    # å…¶ä»–æŒ‡æ•°
    "å…¨æŒ‡åŒ»è¯.csv": "å…¨æŒ‡åŒ»è¯",
    "ä¸Šè¯50.csv": "ä¸Šè¯50",
    "åˆ›ä¸šæ¿æŒ‡.csv": "åˆ›ä¸šæ¿æŒ‡",
    "å…»è€äº§ä¸š.csv": "å…»è€äº§ä¸š",
    "ä¸­è¯çº¢åˆ©.csv": "ä¸­è¯çº¢åˆ©",
    "ä¸­è¯ç¯ä¿.csv": "ä¸­è¯ç¯ä¿",
    "ä¸­è¯ä¼ åª’.csv": "ä¸­è¯ä¼ åª’",
    "å…¨æŒ‡é‡‘è.csv": "å…¨æŒ‡é‡‘è",
    "è¯åˆ¸å…¬å¸.csv": "è¯åˆ¸å…¬å¸",
    "å…¨æŒ‡æ¶ˆè´¹.csv": "å…¨æŒ‡æ¶ˆè´¹",
    "å…¨æŒ‡ä¿¡æ¯.csv": "å…¨æŒ‡ä¿¡æ¯",
    "ä¸­è¯åŒ»ç–—.csv": "ä¸­è¯åŒ»ç–—",
    "ä¸­è¯ç™½é…’.csv": "ä¸­è¯ç™½é…’",
}

DATA_DIR = "index_data"
STATE_FILE = "portfolio_status.json"

# V22.0: ç­–ç•¥å‚æ•°ä¸å†ç¡¬ç¼–ç ï¼Œå®ƒä»¬å°†åœ¨ Streamlit Session State ä¸­åˆå§‹åŒ–ã€‚
# åˆå§‹é»˜è®¤å€¼ï¼Œç”¨äºé¦–æ¬¡åŠ è½½ Session State
DEFAULT_STRATEGY_PARAMS = {
    "MAX_UNITS": 10,                 # æœ€å¤§ä¹°å…¥ä»½æ•°
    "STEP_PERCENT": 0.06,            # é˜¶æ¢¯ä¹°å…¥è·Œå¹… (6%)
    "MIN_INTERVAL_DAYS": 30,         # æœ€å°æ“ä½œé—´éš”å¤©æ•° (30å¤©)
    "VOLATILITY_OVERRIDE_PCT": 0.12, # æ³¢åŠ¨ç‡é™åˆ¶è¦†ç›–æ¯”ä¾‹ (12%)
}

# ================= çŠ¶æ€ä¸ç­–ç•¥å‡½æ•° (V22.0 ä¼˜åŒ–) =================

def initialize_session_state():
    """åˆå§‹åŒ– Streamlit Session Stateï¼ŒåŒ…æ‹¬ç­–ç•¥å‚æ•°ã€‚"""
    if 'strategy_params' not in st.session_state:
        st.session_state['strategy_params'] = DEFAULT_STRATEGY_PARAMS

def get_strategy_param(key):
    """è·å–å½“å‰ç­–ç•¥å‚æ•°å€¼ã€‚"""
    initialize_session_state()
    return st.session_state['strategy_params'].get(key, DEFAULT_STRATEGY_PARAMS.get(key))

# V22.0: ä¼˜åŒ– load_state/save_state æµç¨‹ï¼ŒåŒ…å«ç²¾ç¡®çš„æˆæœ¬å’ŒæŒä»“ã€‚
def load_state():
    """åŠ è½½æœ¬åœ°æŒä»“çŠ¶æ€ï¼Œå¹¶ç¡®ä¿ç»“æ„å®Œæ•´ã€‚"""
    initial_state = {code: {"holdings": 0, "total_cost": 0.0, "history": []} for code in TARGETS.keys()}
    
    if os.path.exists(STATE_FILE):
        try:
            state = json.load(open(STATE_FILE, 'r', encoding='utf-8'))
            # ç¡®ä¿æ‰€æœ‰æŒ‡æ•°éƒ½æœ‰å®Œæ•´çš„ç»“æ„
            for code in TARGETS.keys():
                 if code not in state:
                    state[code] = initial_state[code]
                 else:
                    # V22.0: ç¡®ä¿ total_cost å­—æ®µå­˜åœ¨
                    if "total_cost" not in state[code]:
                        state[code]["total_cost"] = 0.0 
                    if "holdings" not in state[code]:
                        state[code]["holdings"] = 0
                    if "history" not in state[code]:
                        state[code]["history"] = []
            return state
        except json.JSONDecodeError:
            print("è­¦å‘Š: çŠ¶æ€æ–‡ä»¶æŸåï¼Œå·²é‡ç½®ã€‚")
            return initial_state
            
    return initial_state

def save_state(state):
    """ä¿å­˜æœ¬åœ°æŒä»“çŠ¶æ€ (åœ¨ä¿å­˜å‰å·²è°ƒç”¨ recalculate_holdings_and_cost)"""
    # V22.0: åœ¨è¿™é‡Œä¸è°ƒç”¨ recalculate_holdings_and_costï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤è®¡ç®—
    with open(STATE_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=4)

def calculate_index_cost(history):
    """
    V22.0: æ ¹æ®å†å²è®°å½•ï¼Œä½¿ç”¨å…ˆè¿›å…ˆå‡º(FIFO)æˆ–å¹³å‡æˆæœ¬æ³•(Average Cost)
    ç²¾ç¡®è®¡ç®—å½“å‰æŒä»“ä»½æ•°å’Œæ€»æˆæœ¬ã€‚è¿™é‡Œä½¿ç”¨ç®€åŒ–ä¸”æ˜“äºç†è§£çš„**å¹³å‡æˆæœ¬æ³•**ã€‚
    
    è¿”å›: total_units, total_cost
    """
    total_units = 0.0
    total_cost = 0.0
    
    for transaction in history:
        unit = transaction.get('unit', 1)
        price = transaction.get('price', 0)
        
        if transaction.get('type') == 'ä¹°å…¥':
            total_cost += price * unit
            total_units += unit
        elif transaction.get('type') == 'å–å‡º':
            if total_units > 0:
                # å–å‡ºæ—¶ï¼Œæˆæœ¬æŒ‰å¹³å‡æˆæœ¬æ³•æ‰£é™¤
                avg_cost_per_unit = total_cost / total_units
                total_cost -= avg_cost_per_unit * unit
                total_units -= unit
                
                # ç¡®ä¿ä¸ä¼šå› æµ®ç‚¹è¯¯å·®å¯¼è‡´è´Ÿå€¼
                if total_units < 1e-6:
                    total_units = 0.0
                    total_cost = 0.0
            
    return max(0.0, total_units), max(0.0, total_cost)

def recalculate_holdings_and_cost(state):
    """V22.0: éå†æ‰€æœ‰æŒ‡æ•°ï¼Œé‡æ–°è®¡ç®—å¹¶æ›´æ–°çŠ¶æ€ä¸­çš„æŒä»“å’Œæ€»æˆæœ¬ã€‚"""
    for code, data in state.items():
        if 'history' in data:
            total_units, total_cost = calculate_index_cost(data['history'])
            state[code]['holdings'] = total_units
            state[code]['total_cost'] = total_cost
    return state

# ================= æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•° (V22.0 ä¼˜åŒ–) =================

# V22.0: æ”¹è¿› find_pe_by_dateï¼Œæ”¯æŒå‘å‰æŸ¥æ‰¾ (Forward Fill)
def find_pe_by_date(df, target_date_str):
    """æ ¹æ®æ—¥æœŸæŸ¥æ‰¾å¯¹åº”çš„ PE å€¼å’Œæ”¶ç›˜ç‚¹ä½ã€‚å¦‚æœå½“å¤©æ— æ•°æ®ï¼Œå‘å‰æŸ¥æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥ã€‚"""
    try:
        target_date = pd.to_datetime(target_date_str)
        # ç¡®ä¿ df ç´¢å¼•æ˜¯ datetime
        df_temp = df.copy()
        df_temp['Date'] = pd.to_datetime(df_temp['Date'], errors='coerce')
        df_temp = df_temp.set_index('Date').sort_index()
        
        # å°è¯•ç²¾ç¡®åŒ¹é…å½“å¤©æ•°æ®
        if target_date in df_temp.index:
             row = df_temp.loc[target_date]
             return row['pe'], row['Close']
             
        # å¦‚æœå½“å¤©æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨ reindex/ffill æŸ¥æ‰¾æœ€è¿‘çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥æ•°æ®
        # åˆ›å»ºä¸€ä¸ªåŒ…å«ç›®æ ‡æ—¥æœŸçš„ä¸´æ—¶ç´¢å¼•
        temp_index = df_temp.index.union([target_date]).sort_values()
        df_reindexed = df_temp.reindex(temp_index)
        
        # ä½¿ç”¨å‰ä¸€ä¸ªæœ‰æ•ˆå€¼å¡«å……ç›®æ ‡æ—¥æœŸ
        df_reindexed = df_reindexed.ffill()
        
        # æŸ¥æ‰¾ç›®æ ‡æ—¥æœŸçš„ PE å’Œ Close
        if target_date in df_reindexed.index:
            row = df_reindexed.loc[target_date]
            # ç¡®ä¿è¿™ä¸æ˜¯ä¸€ä¸ª NaN å¡«å……çš„ç»“æœ
            if pd.notna(row['pe']):
                return row['pe'], row['Close']

        return np.nan, np.nan
    except Exception as e:
        # st.error(f"æŸ¥æ‰¾ PE/Close å¤±è´¥: {e}")
        return np.nan, np.nan


def find_latest_data_file(prefix):
    """æŸ¥æ‰¾åŒ¹é…å‰ç¼€çš„æœ€æ–°æ•°æ®æ–‡ä»¶ï¼Œå¹¶è¿”å›æ–‡ä»¶è·¯å¾„å’Œä¿®æ”¹æ—¶é—´ (æ”¯æŒæ¨¡ç³ŠåŒ¹é…)"""
    # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒåœ¨æ‚¨çš„ V21.1 ä¸­å·²ç»å·¥ä½œæ­£å¸¸) ...
    search_pattern = os.path.join(DATA_DIR, f"{prefix}_*.csv")
    matching_files = glob.glob(search_pattern)
    
    actual_file_path = None
    file_source_name = None
    last_modified_time = None
    
    if matching_files:
        actual_file_path = max(matching_files, key=os.path.getmtime)
        file_source_name = os.path.basename(actual_file_path)
        last_modified_time = datetime.fromtimestamp(os.path.getmtime(actual_file_path)).strftime('%Y-%m-%d %H:%M:%S')
    else:
        # æŸ¥æ‰¾å›ºå®šæ–‡ä»¶åä½œä¸ºå¤‡ä»½
        fixed_path = os.path.join(DATA_DIR, f"{prefix}.csv")
        if os.path.exists(fixed_path):
            actual_file_path = fixed_path
            file_source_name = f"{prefix}.csv"
            last_modified_time = datetime.fromtimestamp(os.path.getmtime(fixed_path)).strftime('%Y-%m-%d %H:%M:%S')
        
    return actual_file_path, file_source_name, last_modified_time


@st.cache_data(ttl=3600)
def get_metrics_from_csv(file_path):
    """
    V22.0: ä»æœ¬åœ° CSV æ–‡ä»¶è¯»å– PE æ•°æ®å¹¶è®¡ç®—æŒ‡æ ‡ã€‚
    ï¼ˆé€»è¾‘ä¸æ‚¨çš„ V21.1 ä¿æŒä¸€è‡´ï¼Œä»¥ç¡®ä¿å…¼å®¹æ€§ï¼‰
    """
    if not os.path.exists(file_path): return None
    try:
        df = pd.read_csv(file_path, encoding='utf-8', sep=',')
        if len(df) == 0: return None
        
        # V22.0: å…¼å®¹æ€§è°ƒæ•´ï¼Œä¼˜å…ˆä½¿ç”¨ç®€çŸ­çš„åˆ—å
        df = df.rename(columns={'PE-TTMæ­£æ•°ç­‰æƒ': 'pe', 'æ—¥æœŸ': 'Date', 
                                'PE-TTM åˆ†ä½ç‚¹': 'pe_percentile', 
                                'æ”¶ç›˜ç‚¹ä½': 'Close', 'æ”¶ç›˜': 'Close', 
                                'Close': 'Close', 'Date': 'Date'})
        
        for col in ['pe', 'pe_percentile', 'Close']:
             if col in df.columns:
                 df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
                 df[col] = pd.to_numeric(df[col], errors='coerce') 
        
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df[['Date', 'pe', 'pe_percentile', 'Close']].dropna(subset=['pe', 'Date', 'pe_percentile', 'Close'])
        df = df.sort_values('Date', ascending=True).reset_index(drop=True)
        if df.empty: return None
        
        df = df.set_index('Date')
        WINDOW_3Y = '1095D'; WINDOW_5Y = '1825D'; 
        df['avg_3yr_roll'] = df['pe'].rolling(window=WINDOW_3Y, min_periods=1, closed='left').mean()
        df['avg_5yr_roll'] = df['pe'].rolling(window=WINDOW_5Y, min_periods=1, closed='left').mean()
        df['benchmark_roll'] = df['avg_3yr_roll'] 
        df['deviation_pct'] = (df['pe'] - df['benchmark_roll']) / df['benchmark_roll'] * 100
        
        max_dev = df['deviation_pct'].max(); min_dev = df['deviation_pct'].min()
        
        if not np.isnan(max_dev): max_dev_date = df[df['deviation_pct'] == max_dev].iloc[-1].name.strftime('%Y-%m-%d')
        else: max_dev_date = 'N/A'
        if not np.isnan(min_dev): min_dev_date = df[df['deviation_pct'] == min_dev].iloc[-1].name.strftime('%Y-%m-%d')
        else: min_dev_date = 'N/A'
        
        avg_3yr = df['avg_3yr_roll'].iloc[-1]; avg_5yr = df['avg_5yr_roll'].iloc[-1]; avg_10yr = np.nan 
        df = df.reset_index().rename(columns={'index': 'Date'}); df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')
        current_pe = df.iloc[-1]['pe']; current_percentile = df.iloc[-1]['pe_percentile']
        
        return (current_pe, current_percentile, avg_3yr, avg_5yr, avg_10yr, 
                df, max_dev, min_dev, max_dev_date, min_dev_date)
        
    except Exception as e:
        st.error(f"[{file_path}] è¯»å–æˆ–å¤„ç†æ•°æ®å¤±è´¥: {e}")
        return None

# V22.0: é‡å‘½åå¹¶æ”¹è¿›ç›ˆäºè®¡ç®—ï¼ŒåŸºäºç²¾ç¡®çš„æ€»æˆæœ¬
def calculate_index_pl_metrics(s, current_close_index, df_full):
    """
    V22.0: è®¡ç®—å•ä¸ªæŒ‡æ•°çš„å¹³å‡æˆæœ¬å’Œæµ®åŠ¨ç›ˆäºã€‚
    ä½¿ç”¨ç²¾ç¡®çš„ total_cost å’Œ holdings è®¡ç®—å¹³å‡æˆæœ¬ã€‚
    """
    total_units = s.get('holdings', 0.0)
    total_cost = s.get('total_cost', 0.0)

    if total_units == 0:
        return np.nan, np.nan, np.nan  # avg_cost, floating_pl_pct, total_market_value

    # 1. è®¡ç®—å¹³å‡æˆæœ¬
    avg_cost = total_cost / total_units

    # 2. ä¼°ç®—å½“å‰å¸‚åœºä»·å€¼ (ä½¿ç”¨æœ€æ–°çš„ ETF ä»·æ ¼)
    
    # æŸ¥æ‰¾æœ€è¿‘ä¸€æ¬¡æ“ä½œçš„ ETF æˆäº¤ä»·å’Œå¯¹åº”çš„æŒ‡æ•°ç‚¹ä½
    last_trade = next((t for t in reversed(s['history']) if t.get('price') is not None and t.get('close') is not None), None)

    if last_trade and last_trade['close'] > 0:
        last_trade_etf_price = last_trade['price']
        last_trade_index_close = last_trade['close']
        
        # æ ¸å¿ƒå‡è®¾ï¼šETFä»·æ ¼æ³¢åŠ¨ä¸æŒ‡æ•°ç‚¹ä½æ³¢åŠ¨ä¸€è‡´
        estimated_current_etf_price = last_trade_etf_price * (current_close_index / last_trade_index_close)
        
        total_market_value = estimated_current_etf_price * total_units
        floating_pl_pct = (total_market_value / total_cost) - 1
        
        return avg_cost, floating_pl_pct, total_market_value
    else:
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„äº¤æ˜“è®°å½•æ¥å»ºç«‹ä¼°ç®—åŸºå‡†ï¼Œåˆ™æ— æ³•è®¡ç®—ç›ˆäº
        return avg_cost, np.nan, np.nan

def get_full_index_metrics(index_key, state, full_data_frames):
    """
    V22.0: è·å–å•ä¸ªæŒ‡æ•°çš„å®Œæ•´æŒ‡æ ‡ã€æŒä»“å’Œç›ˆäºä¿¡æ¯ï¼Œç”¨äºå­é¡µé¢è°ƒç”¨ã€‚
    """
    
    # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒæ˜¯ V21.1 ä¸­çš„è°ƒç”¨æ¥å£ï¼Œæˆ‘ä»¬åªæ”¹å˜å…¶è°ƒç”¨çš„å­å‡½æ•°) ...
    result = {
        "current_pe": np.nan, "current_close": np.nan, "holdings": 0.0, 
        "avg_cost": np.nan, "pl_pct": np.nan, "df_full": None, 
        "history": state.get(index_key, {}).get("history", [])
    }
    
    df_full = full_data_frames.get(index_key)
    s = state.get(index_key, {})
    result["holdings"] = s.get("holdings", 0.0)
    
    if df_full is None:
        prefix = index_key.split('.')[0]
        actual_file_path, _, _ = find_latest_data_file(prefix)
        metrics_result = get_metrics_from_csv(actual_file_path)
        if metrics_result:
            df_full = metrics_result[5]
            result["current_pe"] = metrics_result[0]
            result["current_close"] = df_full.iloc[-1]['Close']
            
    if df_full is not None and not df_full.empty:
        result["df_full"] = df_full
        result["current_pe"] = df_full.iloc[-1]['pe']
        result["current_close"] = df_full.iloc[-1]['Close']
        
        # V22.0: è°ƒç”¨æ–°çš„ç›ˆäºè®¡ç®—å‡½æ•°
        avg_cost, pl_pct, _ = calculate_index_pl_metrics(s, result["current_close"], df_full)
        result["avg_cost"] = avg_cost
        result["pl_pct"] = pl_pct
        
    return result

# ================= é¢œè‰²é«˜äº®å‡½æ•° =================

# ... (é«˜äº®å‡½æ•°ä¿æŒä¸å˜) ...

def highlight_percentile(val):
    """æ ¹æ®ä¼°å€¼ç™¾åˆ†ä½è¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    try:
        if isinstance(val, str) and val.endswith('%'):
            pct = float(val.strip('%'))
        else: return '' 
            
        if pct < 20: return 'background-color: #d4edda; color: #155724; font-weight: bold' 
        elif 20 <= pct <= 50: return 'background-color: #fff3cd; color: #856404;' 
        elif 50 < pct <= 80: return 'background-color: #f8d7da; color: #721c24;' 
        elif pct > 80: return 'background-color: #dc3545; color: white; font-weight: bold' 
        else: return ''
    except: return ''

def highlight_signal(val):
    """æ ¹æ®å»ºè®®ä¿¡å·è¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    if 'ä¹°å…¥' in str(val):
        return f'background-color: #d4edda; color: #155724; font-weight: bold' 
    elif 'å–å‡º' in str(val):
        return f'background-color: #f8d7da; color: #721c24; font-weight: bold'
    elif 'æ•°æ®ç§¯ç´¯ä¸­' in str(val):
         return f'background-color: #fffac0; color: #b58d09; font-weight: bold'
    elif 'è·Œå¹…ä¸è¶³' in str(val):
         return 'background-color: #e0f7fa; color: #00796b; font-weight: bold' 
    elif 'é™åˆ¶' in str(val): 
         return 'background-color: #e9ecef; color: #495057; font-weight: bold'
    else:
        return 'background-color: #f0f0f0; color: black;'

def highlight_pl(val):
    """æ ¹æ®æµ®åŠ¨ç›ˆäºè¿”å›èƒŒæ™¯é¢œè‰²æ ·å¼"""
    try:
        if isinstance(val, str) and val.endswith('%'):
            pct = float(val.strip('%'))
        else: return '' 
            
        if pct > 0: return 'color: #155724; font-weight: bold' # ç»¿è‰²å­—ä½“
        elif pct < 0: return 'color: #721c24; font-weight: bold' # çº¢è‰²å­—ä½“
        else: return ''
    except: return ''

# ================= é¡µé¢å¸ƒå±€ï¼ˆä¸»ä½“é€»è¾‘ï¼‰ (V22.0 ä¼˜åŒ–) =================

st.set_page_config(page_title="æŒ‡æ•°å®šæŠ•çœ‹æ¿", layout="wide", page_icon="ğŸ“ˆ")

# V22.0: åˆå§‹åŒ– Session State
initialize_session_state()

# --- é¡µé¢å¤´éƒ¨ç¾åŒ– ---
with st.container(border=True):
    st.markdown("## ğŸ“Š æ™ºèƒ½å®šæŠ•çœ‹æ¿ï¼šä¼°å€¼æ€»è§ˆä¸ç­–ç•¥å»ºè®® (V22.0 - ä¼˜åŒ–ç‰ˆ)")
    
    # V22.0: ä» Session State è¯»å–å‚æ•°
    MIN_INTERVAL_DAYS = get_strategy_param("MIN_INTERVAL_DAYS")
    VOLATILITY_OVERRIDE_PCT = get_strategy_param("VOLATILITY_OVERRIDE_PCT")
    
    st.markdown(f"**ç­–ç•¥é™åˆ¶**: æ¯æ¬¡æ“ä½œé—´éš”éœ€å¤§äº **{MIN_INTERVAL_DAYS}** å¤©ï¼Œé™¤é PE æ³¢åŠ¨å¹…åº¦å¤§äº **{VOLATILITY_OVERRIDE_PCT*100:.0f}%**ã€‚")

# --- ä¾§è¾¹æ å’Œæ•°æ®æ–°é²œåº¦æ£€æŸ¥ (V22.0 ç­–ç•¥é…ç½®) ---
st.sidebar.header("ğŸ•¹ï¸ ç­–ç•¥é…ç½® (V22.0)")

# V22.0: ç­–ç•¥å‚æ•°åŒ–é…ç½®
with st.sidebar.expander("âš™ï¸ ç­–ç•¥å‚æ•°è®¾ç½®"):
    
    MAX_UNITS = st.number_input(
        "æœ€å¤§æŒä»“ä»½æ•° (MAX_UNITS):", 
        min_value=1, value=get_strategy_param("MAX_UNITS"), step=1, key='param_max_units'
    )
    STEP_PERCENT = st.number_input(
        "é˜¶æ¢¯ä¹°å…¥è·Œå¹… (STEP_PERCENT, %):", 
        min_value=1.0, max_value=20.0, value=get_strategy_param("STEP_PERCENT")*100, step=0.5, format="%.1f"
    ) / 100
    MIN_INTERVAL_DAYS = st.number_input(
        "æœ€å°æ“ä½œé—´éš” (å¤©):", 
        min_value=1, value=get_strategy_param("MIN_INTERVAL_DAYS"), step=1, key='param_min_days'
    )
    VOLATILITY_OVERRIDE_PCT = st.number_input(
        "æ³¢åŠ¨ç‡è¦†ç›–æ¯”ä¾‹ (%):", 
        min_value=1.0, max_value=50.0, value=get_strategy_param("VOLATILITY_OVERRIDE_PCT")*100, step=1.0, format="%.0f"
    ) / 100
    
    if st.button("ä¿å­˜ç­–ç•¥å‚æ•°å¹¶åˆ·æ–°", type="primary"):
        st.session_state['strategy_params'] = {
            "MAX_UNITS": MAX_UNITS,
            "STEP_PERCENT": STEP_PERCENT,
            "MIN_INTERVAL_DAYS": MIN_INTERVAL_DAYS,
            "VOLATILITY_OVERRIDE_PCT": VOLATILITY_OVERRIDE_PCT,
        }
        st.success("å‚æ•°å·²æ›´æ–°ï¼")
        st.cache_data.clear()
        st.rerun()

# V22.0: è¯»å–æœ€æ–°çš„å‚æ•°å€¼
MAX_UNITS = get_strategy_param("MAX_UNITS")
STEP_PERCENT = get_strategy_param("STEP_PERCENT")
MIN_INTERVAL_DAYS = get_strategy_param("MIN_INTERVAL_DAYS")
VOLATILITY_OVERRIDE_PCT = get_strategy_param("VOLATILITY_OVERRIDE_PCT")


st.sidebar.info(f"æ•°æ®ç›®å½•: **{DATA_DIR}/**")

# æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶ï¼Œè·å–æ›´æ–°æ—¶é—´
latest_modified_time = None
for prefix in [f.split('.')[0] for f in TARGETS.keys()]:
    _, _, mod_time = find_latest_data_file(prefix)
    if mod_time:
        if latest_modified_time is None or mod_time > latest_modified_time:
            latest_modified_time = mod_time

if latest_modified_time:
    st.sidebar.markdown(f"**æœ€åæ•°æ®æ›´æ–°æ—¶é—´ï¼š** `{latest_modified_time}`")
else:
    st.sidebar.warning("âš ï¸ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ index_data æ–‡ä»¶å¤¹ã€‚")

# V22.0: åŠ è½½çŠ¶æ€ï¼Œå¹¶é‡æ–°è®¡ç®—æŒä»“å’Œæˆæœ¬ (é‡è¦æ­¥éª¤)
state = load_state()
state = recalculate_holdings_and_cost(state)
# save_state(state) # é¿å…åœ¨ rerurn ä¹‹å‰é‡å¤ä¿å­˜

# ä¸»æ•°æ®è¡¨æ ¼æ„å»º
table_data = []
decision_logs = {} 

progress_bar = st.progress(0, text="è®¡ç®—ä¸­...")
total_targets = len(TARGETS)
full_data_frames = {} 

# --- å¤§ç›˜æ•´ä½“ä»“ä½æŒ‡æ ‡è®¡ç®— (ä¿æŒä¸å˜) ---
overall_position_pct = 0
overall_pe_percentile = np.nan

if "å¤§ç›˜.csv" in TARGETS:
    prefix = "å¤§ç›˜"
    actual_file_path, file_source_name, _ = find_latest_data_file(prefix)
    if actual_file_path:
        metrics_result_overall = get_metrics_from_csv(actual_file_path)
        if metrics_result_overall:
            _, overall_pe_percentile, _, _, _, _, _, _, _, _ = metrics_result_overall
            if not np.isnan(overall_pe_percentile):
                overall_position_pct = (1 - overall_pe_percentile) * 100
    
# --- æ•°æ®åŠ è½½ã€è‡ªåŠ¨å›å¡«å’ŒæŒ‡æ ‡è®¡ç®— ---
updated_records_count = 0 

for i, (fixed_filename_key, name) in enumerate(TARGETS.items()): 
    
    prefix = fixed_filename_key.split('.')[0]
    progress_bar.progress((i + 1) / total_targets, text=f"æ­£åœ¨å¤„ç† {name} ({i+1}/{total_targets}) - åŒ¹é…æ–‡ä»¶...")
    
    actual_file_path, file_source_name, _ = find_latest_data_file(prefix)
        
    if not actual_file_path:
        continue

    metrics_result = get_metrics_from_csv(actual_file_path) 
    code = fixed_filename_key
    s = state[code]
    current_holdings = s["holdings"]
    
    # V22.0: ä»çŠ¶æ€ä¸­ç›´æ¥è¯»å–æ€»æˆæœ¬
    current_total_cost = s["total_cost"]
    
    days_since_last_op_display = 'â€”'
    avg_cost_display = 'â€”'
    pl_pct_display = 'â€”'

    current_decision_log = [] 

    if metrics_result:
        (curr_pe, curr_percentile, avg3, avg_5yr, avg_10yr, df_full, 
         max_dev, min_dev, max_dev_date, min_dev_date) = metrics_result
        
        full_data_frames[fixed_filename_key] = df_full 

        # --- V22.0: è‡ªåŠ¨å›å¡«ç¼ºå¤±æ•°æ® (ä½¿ç”¨æ”¹è¿›çš„ find_pe_by_date) ---
        for trade in s['history']:
            if trade['pe'] is None or trade['close'] is None or np.isnan(trade.get('pe', np.nan)):
                new_pe, new_close = find_pe_by_date(df_full, trade['date'])
                if not np.isnan(new_pe) and not np.isnan(new_close):
                    trade['pe'] = round(new_pe, 2)
                    trade['close'] = round(new_close, 2)
                    updated_records_count += 1
        
        # --- V22.0: P&L è®¡ç®— (ä½¿ç”¨æ–°çš„ calculate_index_pl_metrics) ---
        current_close_index = df_full.iloc[-1]['Close']
        avg_cost, pl_pct, _ = calculate_index_pl_metrics(s, current_close_index, df_full)

        if not np.isnan(avg_cost):
            avg_cost_display = f"{avg_cost:.4f}"
        if not np.isnan(pl_pct):
            pl_pct_display = f"{pl_pct * 100:.2f}%"

        # --- é˜¶æ¢¯ä¹°å…¥/æ—¶é—´é™åˆ¶åˆ¤æ–­ ---
        last_op = s["history"][-1] if s["history"] else None
        time_limit_suppression = False
        
        # ... (æ­¤å¤„é€»è¾‘ä¸ V21.1 ä¿æŒä¸€è‡´ï¼Œä½†ä½¿ç”¨ V22.0 çš„åŠ¨æ€å‚æ•°) ...
        if last_op and 'pe' in last_op and last_op['pe'] is not None and not np.isnan(last_op['pe']):
            last_op_date_str = last_op.get("date", datetime.now().strftime("%Y-%m-%d"))
            last_op_date = datetime.strptime(last_op_date_str, "%Y-%m-%d").date()
            days_since_last_op = (datetime.now().date() - last_op_date).days
            days_since_last_op_display = str(days_since_last_op)
            
            current_decision_log.append(f"ä¸Šæ¬¡æ“ä½œè·ä»Š: {days_since_last_op} å¤© (è¦æ±‚ â‰¥ {MIN_INTERVAL_DAYS} å¤©)")
            
            if days_since_last_op < MIN_INTERVAL_DAYS:
                last_op_pe = last_op['pe']
                pe_change_pct = (curr_pe - last_op_pe) / last_op_pe
                current_decision_log.append(f"ä¸Šæ¬¡æ“ä½œPE: {last_op_pe:.2f}, å½“å‰PE: {curr_pe:.2f}, å˜åŠ¨: {pe_change_pct*100:.1f}% (è¦æ±‚ Â±{VOLATILITY_OVERRIDE_PCT*100:.0f}% è¦†ç›–)")
                if abs(pe_change_pct) < VOLATILITY_OVERRIDE_PCT:
                    time_limit_suppression = True
                    current_decision_log.append("ç»“æœ: æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶ç”Ÿæ•ˆï¼ŒæŠ‘åˆ¶æ“ä½œã€‚")
                else:
                    current_decision_log.append("ç»“æœ: æ³¢åŠ¨ç‡è¾¾åˆ°è¦†ç›–æ¡ä»¶ï¼Œç»§ç»­è¯„ä¼°ã€‚")
            else:
                current_decision_log.append("ç»“æœ: å·²è¶…è¿‡æœ€å°æ—¶é—´é—´éš”ï¼Œç»§ç»­è¯„ä¼°ã€‚")
        else:
             current_decision_log.append("æ— ä¸Šæ¬¡æ“ä½œè®°å½•ï¼Œä¸æ£€æŸ¥æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶ã€‚")
        
        # --- æŸ¥æ‰¾ä¸Šæ¬¡ä¹°å…¥çš„PE (ç”¨äº6%é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥) ---
        last_buy_pe = None
        for trade in reversed(s["history"]):
            if trade['type'] == 'ä¹°å…¥' and trade['pe'] is not None and not np.isnan(trade['pe']):
                last_buy_pe = trade['pe']
                break
        
        last_op_hist = s["history"][-1] if s["history"] else {"date": "1900-01-01", "pe": 0, "close": 0}
        last_date = last_op_hist.get("date", "1900-01-01")
        last_pe = last_op_hist.get("pe") 
        if last_pe is None: last_pe = np.nan

        benchmark_pe = avg3 if not np.isnan(avg3) else 0 
        diff_pct = (curr_pe - benchmark_pe) / benchmark_pe * 100 if benchmark_pe > 0 else np.nan
        signal = "è§‚æœ›"
        
        # ==================== ä¿¡å·åˆ¤æ–­é€»è¾‘ (å«å†³ç­–æ—¥å¿— - V22.0 ä½¿ç”¨åŠ¨æ€å‚æ•°) ====================
        current_decision_log.append("--- ç­–ç•¥è¯„ä¼° ---")

        if benchmark_pe == 0 or np.isnan(benchmark_pe):
            signal = "âš ï¸ æ•°æ®ç§¯ç´¯ä¸­ (ä¸æ»¡ 3 å¹´)"
            current_decision_log.append(f"æ¡ä»¶: 3å¹´å‡å€¼ PE ({benchmark_pe:.2f}) ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°ã€‚")
        
        elif time_limit_suppression:
            signal = f"â¸ï¸ è§‚æœ› ({MIN_INTERVAL_DAYS}å¤©/Â±{VOLATILITY_OVERRIDE_PCT*100:.0f}%é™åˆ¶)" 
            current_decision_log.append("æ¡ä»¶: è¢«æ—¶é—´/æ³¢åŠ¨ç‡é™åˆ¶æŠ‘åˆ¶ã€‚")

        else:
            current_decision_log.append(f"å½“å‰PE: {curr_pe:.2f}, PEåˆ†ä½ç‚¹: {curr_percentile*100:.1f}%, 3å¹´å‡å€¼PE: {avg3:.2f}")

            buy_condition_1 = curr_percentile < 0.20 
            buy_condition_2 = (not np.isnan(avg3) and curr_pe < avg3) and (not np.isnan(avg_5yr) and curr_pe < avg_5yr) 
            
            sell_condition_1 = curr_percentile > 0.75 
            sell_condition_2 = diff_pct > 30 
            
            if sell_condition_1 or sell_condition_2:
                current_decision_log.append(f"æ¡ä»¶: å–å‡ºæ¡ä»¶æ»¡è¶³ (åˆ†ä½ç‚¹ > 75% [{curr_percentile*100:.1f}%] æˆ–åç¦»åº¦ > 30% [{diff_pct:.1f}%])ã€‚")
                if current_holdings > 0: 
                    signal = "ğŸ”´ å»ºè®®å–å‡º"
                    current_decision_log.append("ç»“æœ: å»ºè®®å–å‡ºã€‚")
                else: 
                    signal = "ğŸ”´ å»ºè®®å–å‡º (æ— æŒä»“)ã€‚"
            
            elif buy_condition_1 or buy_condition_2:
                current_decision_log.append(f"æ¡ä»¶: ä¹°å…¥æ¡ä»¶æ»¡è¶³ (åˆ†ä½ç‚¹ < 20% [{curr_percentile*100:.1f}%] æˆ– PE < 3/5å¹´å‡å€¼)ã€‚")
                
                suppress_by_step = False
                if current_holdings > 0 and last_buy_pe is not None:
                    # V22.0: ä½¿ç”¨åŠ¨æ€ STEP_PERCENT
                    required_entry_pe = last_buy_pe * (1 - STEP_PERCENT)
                    current_decision_log.append(f"é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥: ä¸Šæ¬¡ä¹°å…¥PE {last_buy_pe:.2f}, ä¸‹æ¬¡ä¹°å…¥PEé˜ˆå€¼ {required_entry_pe:.2f} (è¦æ±‚è·Œå¹… â‰¥ {STEP_PERCENT*100:.0f}%)ã€‚")
                    if curr_pe > required_entry_pe:
                        suppress_by_step = True
                        current_decision_log.append(f"ç»“æœ: è·Œå¹…ä¸è¶³ {STEP_PERCENT*100:.0f}%ï¼ŒæŠ‘åˆ¶ä¹°å…¥ã€‚")
                else:
                    current_decision_log.append(f"é˜¶æ¢¯ä¹°å…¥æ£€æŸ¥: æ— æŒä»“æˆ–æ— ä¸Šæ¬¡ä¹°å…¥PEï¼Œä¸æ£€æŸ¥è·Œå¹…é™åˆ¶ã€‚")
                        
                if suppress_by_step:
                    signal = f"â¸ï¸ è§‚æœ› (è·Œå¹…ä¸è¶³ {STEP_PERCENT*100:.0f}%)"
                elif current_holdings < MAX_UNITS:
                    signal = "ğŸŸ¢ å»ºè®®ä¹°å…¥"
                    current_decision_log.append("ç»“æœ: å»ºè®®ä¹°å…¥ã€‚")
                else:
                    signal = "ğŸŸ¢ å»ºè®®ä¹°å…¥ (å·²æ»¡ä»“)"
                    current_decision_log.append("ç»“æœ: å»ºè®®ä¹°å…¥ (å·²æ»¡ä»“)ã€‚")
            else:
                current_decision_log.append("æ¡ä»¶: æ— æ˜ç¡®ä¹°å…¥/å–å‡ºä¿¡å·ã€‚")
            
        decision_logs[code] = current_decision_log 

        table_data.append({
            "æŒ‡æ•°åç§°": name,
            "å½“å‰PE": f"{curr_pe:.2f}", 
            "PEåˆ†ä½ç‚¹": f"{curr_percentile * 100:.1f}%", 
            "åç¦»åº¦(3å¹´%)": f"{diff_pct:.1f}%" if not np.isnan(diff_pct) else 'â€”', 
            "å»ºè®®ä¿¡å·": signal,
            "ä¸Šæ¬¡æ“ä½œè·ä»Š(å¤©)": days_since_last_op_display,
            "å¹³å‡æˆæœ¬(ETF)": avg_cost_display,
            "æµ®åŠ¨ç›ˆäº(%)": pl_pct_display,
            "å½“å‰æŒä»“(ä»½)": f"{current_holdings:.1f}", # V22.0: å…è®¸å°æ•°æ˜¾ç¤º
            "ä¸Šæ¬¡æ“ä½œæ—¥æœŸ": last_date, 
            "ä¸Šæ¬¡æ“ä½œPE": f"{last_pe:.2f}" if not np.isnan(last_pe) else 'â€”', 
        })
    else:
        # ... (æ•°æ®åŠ è½½å¤±è´¥å¤„ç†ä¿æŒä¸å˜) ...
        decision_logs[code] = ["æ•°æ®å¤„ç†å¤±è´¥æˆ–æ–‡ä»¶ç¼ºå¤±ï¼Œæ— æ³•è¯„ä¼°ç­–ç•¥ã€‚"]
        table_data.append({
            "æŒ‡æ•°åç§°": name, 
            "å»ºè®®ä¿¡å·": "âš ï¸ æ•°æ®å¤„ç†å¤±è´¥/æ–‡ä»¶ç¼ºå¤±",
            "PEåˆ†ä½ç‚¹": "â€”", "åç¦»åº¦(3å¹´%)": "â€”", "å½“å‰PE": "â€”", 
            "ä¸Šæ¬¡æ“ä½œè·ä»Š(å¤©)": 'â€”',
            "å¹³å‡æˆæœ¬(ETF)": 'â€”', "æµ®åŠ¨ç›ˆäº(%)": 'â€”',
            "å½“å‰æŒä»“(ä»½)": f"{s['holdings']:.1f}", 
            "ä¸Šæ¬¡æ“ä½œæ—¥æœŸ": last_date, "ä¸Šæ¬¡æ“ä½œPE": "â€”"
        })

progress_bar.empty()

# --- æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜çŠ¶æ€å’Œé‡æ–°è¿è¡Œ (V22.0 ä¼˜åŒ–) ---
if updated_records_count > 0:
    save_state(state) # ä»…ä¿å­˜å†å²è®°å½•ï¼ŒæŒä»“å’Œæˆæœ¬å·²åœ¨ load æ—¶é‡æ–°è®¡ç®—
    st.success(f"âœ… å·²è‡ªåŠ¨è¡¥å½• {updated_records_count} æ¡äº¤æ˜“è®°å½•çš„ PE/ç‚¹ä½æ•°æ®!")
    st.cache_data.clear() 
    time.sleep(1)
    st.rerun()

# ... (æ ¸å¿ƒæŒ‡æ ‡æ˜¾ç¤ºåŒºä¿æŒä¸å˜) ...

# --- æ ¸å¿ƒæŒ‡æ ‡æ˜¾ç¤ºåŒº (é¡¶éƒ¨å¢åŠ æ•´ä½“ä»“ä½æŒ‡æ ‡) ---
st.subheader("æ ¸å¿ƒæŒ‡æ ‡")
col_overall_pos, col_curr_pe, col_percentile, col_deviation = st.columns([1,1,1,1]) 

with col_overall_pos.container(border=True):
    st.markdown("### ğŸŒ æ•´ä½“ä»“ä½æŒ‡æ ‡")
    if not np.isnan(overall_pe_percentile):
        overall_position_str = f"{overall_position_pct:.1f}%"
        st.metric(label="å»ºè®®æ•´ä½“ä»“ä½ (1-å¤§ç›˜åˆ†ä½)", value=overall_position_str)
        if overall_position_pct > 75:
            st.success("å¸‚åœºæ•´ä½“ä½ä¼°ï¼Œå¯ç§¯æå¸ƒå±€ã€‚")
        elif overall_position_pct < 25:
            st.error("å¸‚åœºæ•´ä½“é«˜ä¼°ï¼Œæ³¨æ„é£é™©ã€‚")
        else:
            st.info("å¸‚åœºä¼°å€¼é€‚ä¸­ã€‚")
    else:
        st.info("å¤§ç›˜æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•è®¡ç®—ã€‚")

with col_curr_pe.container(border=True):
    st.markdown(f"### ğŸ¯ å½“å‰æŒ‡æ•°æ€»æ•°")
    st.metric(label="ç›‘æ§ä¸­æŒ‡æ•°æ•°é‡", value=len(TARGETS))
    st.markdown("æ•°æ®é©±åŠ¨æ‚¨çš„åˆ†æ•£æŠ•èµ„å†³ç­–ã€‚")

with col_percentile.container(border=True):
    st.markdown("### ğŸ“ˆ PEåˆ†ä½ç‚¹")
    st.info("ç»¿è‰²: <20% (ä½ä¼°) | çº¢è‰²: >80% (é«˜ä¼°)")
    st.markdown("è¯„ä¼°å½“å‰ä¼°å€¼åœ¨å†å²ä¸Šçš„ç›¸å¯¹ä½ç½®ã€‚")

with col_deviation.container(border=True):
    st.markdown("### ğŸ’¡ å»ºè®®ä¿¡å·")
    st.success("ğŸŸ¢: å»ºè®®ä¹°å…¥")
    st.error("ğŸ”´: å»ºè®®å–å‡º")
    st.markdown("åŸºäºå¤šé‡æŒ‡æ ‡(3/5å¹´å‡å€¼, åˆ†ä½ç‚¹)ç”Ÿæˆçš„ç­–ç•¥å»ºè®®ã€‚")

st.markdown("---")

st.subheader("ğŸ“‹ æŒ‡æ•°ä¼°å€¼ä¸ç­–ç•¥æ€»è§ˆ")

df_display = pd.DataFrame(table_data)

st.dataframe(
    df_display.style
        .applymap(highlight_signal, subset=['å»ºè®®ä¿¡å·'])
        .applymap(highlight_percentile, subset=['PEåˆ†ä½ç‚¹'])
        .applymap(highlight_pl, subset=['æµ®åŠ¨ç›ˆäº(%)']),
    use_container_width=True,
    height=500
)


# --- è¯¦ç»†çš„å†³ç­–ä¾æ®æ˜¾ç¤º (æ‰©å±•åˆ°æ‰€æœ‰æŒ‡æ•°) ---
st.markdown("---")
st.subheader("ğŸ” è¯¦ç»†å†³ç­–ä¾æ® (æ‰€æœ‰æŒ‡æ•°)")
for code, name in TARGETS.items(): 
    with st.expander(f"**{name}** å»ºè®®ä¿¡å·å†³ç­–æ—¥å¿—"):
        if code in decision_logs and decision_logs[code]:
            for log_entry in decision_logs[code]:
                st.markdown(f"- {log_entry}")
        else:
            st.info("æ— å†³ç­–æ—¥å¿—ä¿¡æ¯ã€‚")

# --- äº¤æ˜“ç™»è®°é€»è¾‘ (æ–°å¢äº¤æ˜“ç®¡ç†) ---
st.markdown("---")
st.header("ğŸ›’ äº¤æ˜“ç™»è®°ä¸ç®¡ç†")

tab_record, tab_manage = st.tabs(["ğŸ“ ç™»è®°æ–°äº¤æ˜“", "ğŸ—‘ï¸ ç®¡ç†/ä¿®æ”¹äº¤æ˜“è®°å½•"])

# ======================= Tab 1: ç™»è®°æ–°äº¤æ˜“ (V22.0 ä¼˜åŒ–) =======================
with tab_record:
    st.markdown(f"æ¯æ¬¡é»˜è®¤æ“ä½œ **1 ä»½**ã€‚å½“å‰æœ€å¤§æŒä»“é™åˆ¶ï¼š**{MAX_UNITS}** ä»½ã€‚")
    with st.container(border=True):
        col1, col2, col3, col4, col5 = st.columns([2, 1, 2, 2, 2])

        name_options = list(TARGETS.values())

        with col1:
            selected_name_r = st.selectbox("é€‰æ‹©æŒ‡æ•°", name_options, key="select_record_index")
            selected_file_r = [f for f, n in TARGETS.items() if n == selected_name_r][0]
            current_holdings_r = state[selected_file_r]['holdings']

        with col2:
            action_r = st.selectbox("æ“ä½œç±»å‹", ["ä¹°å…¥", "å–å‡º"], key="select_action")
            
        with col3:
            trade_date_r = st.date_input("æˆäº¤æ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date(), key="input_date")
            trade_date_str_r = trade_date_r.strftime("%Y-%m-%d")

        with col4:
            trade_price_r = st.number_input("ETF å®é™…æˆäº¤ä»·æ ¼", min_value=0.0001, format="%.4f", value=1.0000, step=0.0001, key="input_price")
            trade_unit_r = st.number_input("äº¤æ˜“ä»½æ•°", min_value=1, value=1, step=1, key="input_unit")

        with col5:
            st.markdown("##### ") 
            st.markdown("##### ") 
            if st.button("æäº¤æ–°è®°å½•", type="primary", use_container_width=True):
                s = state[selected_file_r] 
                df_selected_r = full_data_frames.get(selected_file_r)
                
                if df_selected_r is None:
                    st.error(f"âš ï¸ æ— æ³•æäº¤è®°å½•ï¼šæ•°æ®æ–‡ä»¶ {selected_file_r} è¯»å–å¤±è´¥ã€‚è¯·ç¨åé‡è¯•ã€‚")
                    time.sleep(1); st.cache_data.clear(); st.rerun()

                # V22.0: ä½¿ç”¨æ”¹è¿›çš„ find_pe_by_date
                trade_pe_r, trade_close_r = find_pe_by_date(df_selected_r, trade_date_str_r)
                
                saved_pe_r = round(trade_pe_r, 2) if not np.isnan(trade_pe_r) else None
                saved_close_r = round(trade_close_r, 2) if not np.isnan(trade_close_r) else None
                
                pe_display_str_r = f"{saved_pe_r:.2f}" if saved_pe_r is not None else 'N/A'
                    
                transaction_r = {
                    "date": trade_date_str_r,
                    "type": action_r,
                    "pe": saved_pe_r, 
                    "close": saved_close_r,
                    "price": trade_price_r, 
                    "unit": trade_unit_r
                }
                
                if action_r == "ä¹°å…¥":
                    if current_holdings_r + trade_unit_r <= MAX_UNITS:
                        s["history"].append(transaction_r) 
                        state = recalculate_holdings_and_cost(state) # ç«‹å³é‡æ–°è®¡ç®—
                        save_state(state)
                        st.success(f"å·²è®°å½•ï¼š{selected_name_r} ä¹°å…¥{trade_unit_r}ä»½ã€‚PE: {pe_display_str_r}, ETFæˆäº¤ä»·: {trade_price_r:.4f}ã€‚å½“å‰æŒä»“ {state[selected_file_r]['holdings']:.1f} ä»½ã€‚")
                    else:
                        st.info(f"è¶…è¿‡æœ€å¤§æŒä»“ä»½æ•° ({MAX_UNITS})ï¼Œæœ¬æ¬¡ä¹°å…¥ {trade_unit_r} ä»½åå°†è¶…é™ã€‚")
                    
                elif action_r == "å–å‡º":
                    if current_holdings_r >= trade_unit_r:
                        s["history"].append(transaction_r) 
                        state = recalculate_holdings_and_cost(state) # ç«‹å³é‡æ–°è®¡ç®—
                        save_state(state)
                        st.warning(f"å·²è®°å½•ï¼š{selected_name_r} å–å‡º{trade_unit_r}ä»½ã€‚PE: {pe_display_str_r}, ETFæˆäº¤ä»·: {trade_price_r:.4f}ã€‚å½“å‰æŒä»“ {state[selected_file_r]['holdings']:.1f} ä»½ã€‚")
                    else:
                        st.error(f"æŒä»“ä¸è¶³ã€‚å½“å‰æŒä»“ {current_holdings_r:.1f} ä»½ï¼Œæ— æ³•å–å‡º {trade_unit_r} ä»½ã€‚")
                        
                time.sleep(1)
                st.cache_data.clear() 
                st.rerun()
# ----------------------------------------------------
# V22.2: æ•°æ®æ—¶æ•ˆæ€§æ ¡éªŒ (è°ƒæ•´ä¸º 30 å¤©é˜ˆå€¼)
# ----------------------------------------------------

def check_data_freshness():
    """
    æ£€æŸ¥æ‰€æœ‰é…ç½®æŒ‡æ•°çš„æ•°æ®æ–‡ä»¶æ˜¯å¦åœ¨åˆç†çš„æ—¶æ•ˆå†…æ›´æ–°ã€‚
    è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«éœ€è¦è­¦å‘Šçš„æŒ‡æ•°åç§°åŠå…¶åŸå› ã€‚
    """
    stale_files = {}
    
    # è®¾å®šé˜ˆå€¼ï¼šå¦‚æœæ•°æ®è½åäºå½“å‰æ—¥æœŸè¶…è¿‡ 30 ä¸ªæ—¥å†æ—¥ï¼Œåˆ™å‘å‡ºè­¦å‘Šã€‚
    # å®½æ¾é˜ˆå€¼ï¼Œåªåœ¨æ•°æ®æºä¸¥é‡ä¸­æ–­æ—¶æé†’ (1ä¸ªæœˆ)
    freshness_threshold = datetime.now() - timedelta(days=30)

    for fixed_filename_key, name in TARGETS.items():
        prefix = fixed_filename_key.split('.')[0]
        actual_file_path, _, _ = find_latest_data_file(prefix)
        
        if not actual_file_path or not os.path.exists(actual_file_path):
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç«‹å³è­¦å‘Š (è¿™ä»ç„¶æ˜¯ä¸€ä¸ªä¸¥é‡é—®é¢˜)
            stale_files[name] = "æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ã€‚"
            continue
        
        try:
            # å°è¯•åŠ è½½æ•°æ®ä»¥è·å–å†…éƒ¨æœ€æ–°æ—¥æœŸ
            metrics_result = get_metrics_from_csv(actual_file_path)
            if metrics_result:
                df_full = metrics_result[5]
                df_full['Date'] = pd.to_datetime(df_full['Date'])
                
                latest_data_date = df_full['Date'].max().normalize()
                
                if latest_data_date < freshness_threshold.normalize():
                    # åªæœ‰å½“æœ€æ–°æ•°æ®æ—¥æœŸè¶…è¿‡ 30 å¤©é˜ˆå€¼æ—¶æ‰å‘å‡ºè­¦å‘Š
                    stale_files[name] = f"æ•°æ®å·²åœæ­¢åœ¨ {latest_data_date.strftime('%Y-%m-%d')}ã€‚"
            else:
                stale_files[name] = "æ— æ³•è¯»å–æ•°æ®å†…å®¹ã€‚"

        except Exception as e:
            # æ–‡ä»¶å­˜åœ¨ï¼Œä½†è¯»å–å¤±è´¥ï¼Œä¹Ÿè§†ä¸ºéœ€è¦æ£€æŸ¥
            stale_files[name] = f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}"
            
    return stale_files
# ======================= Tab 2: ç®¡ç†/ä¿®æ”¹äº¤æ˜“è®°å½• (V22.0 ä¼˜åŒ–) =======================
with tab_manage:
    st.markdown("âš ï¸ **å±é™©æ“ä½œï¼** åˆ é™¤å’Œä¿®æ”¹è®°å½•å°†ç›´æ¥å½±å“æŒä»“å’Œæˆæœ¬è®¡ç®—ã€‚")

    name_options_m = list(TARGETS.values())
    selected_name_m = st.selectbox("é€‰æ‹©è¦ç®¡ç†è®°å½•çš„æŒ‡æ•°", name_options_m, key="select_manage_index")
    selected_file_m = [f for f, n in TARGETS.items() if n == selected_name_m][0]
    
    s_m = state[selected_file_m]
    
    if not s_m['history']:
        st.info("è¯¥æŒ‡æ•°å°šæ— äº¤æ˜“è®°å½•å¯ä¾›ç®¡ç†ã€‚")
    else:
        # å°†å†å²è®°å½•è½¬æ¢ä¸º DataFrame ä»¥ä¾¿å±•ç¤ºç´¢å¼•
        history_df_m = pd.DataFrame(s_m['history'])
        history_df_m['ç´¢å¼•'] = history_df_m.index # æ·»åŠ ç´¢å¼•åˆ—ç”¨äºè¯†åˆ«è®°å½•
        
        df_display_m = history_df_m[['ç´¢å¼•', 'date', 'type', 'price', 'unit', 'pe', 'close']].copy()
        df_display_m = df_display_m.rename(columns={'date': 'æˆäº¤æ—¥æœŸ', 'type': 'æ“ä½œç±»å‹', 'price': 'ETFæˆäº¤ä»·', 'unit': 'äº¤æ˜“ä»½æ•°', 'pe': 'æˆäº¤PE(è‡ªåŠ¨)', 'close': 'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)'})
        
        # æ ¼å¼åŒ– PE/Close/Price
        for col in ['ETFæˆäº¤ä»·', 'æˆäº¤PE(è‡ªåŠ¨)', 'æˆäº¤ç‚¹ä½(è‡ªåŠ¨)']:
             if col in df_display_m.columns:
                 if col == 'ETFæˆäº¤ä»·':
                     df_display_m[col] = df_display_m[col].apply(lambda x: f"{x:.4f}" if pd.notna(x) and x is not None else 'N/A')
                 else:
                     df_display_m[col] = df_display_m[col].apply(lambda x: f"{x:.2f}" if pd.notna(x) and x is not None else 'N/A')
        
        st.dataframe(df_display_m, use_container_width=True)

        # --- åˆ é™¤æ“ä½œ ---
        st.subheader("åˆ é™¤è®°å½•")
        col_del, col_button_del = st.columns([1, 1])
        with col_del:
            index_to_delete = st.number_input("è¾“å…¥è¦åˆ é™¤çš„è®°å½•è¡Œç´¢å¼• (æœ€å·¦ä¾§åˆ—)", min_value=0, max_value=len(history_df_m) - 1, step=1, key="delete_index")
        
        with col_button_del:
            st.markdown("##### ")
            if st.button(f"ğŸ”´ ç¡®è®¤åˆ é™¤ç¬¬ {index_to_delete} è¡Œè®°å½•", key="confirm_delete_button"):
                if 0 <= index_to_delete < len(s_m['history']):
                    del s_m['history'][index_to_delete]
                    state = recalculate_holdings_and_cost(state) # ç«‹å³é‡æ–°è®¡ç®—
                    save_state(state)
                    st.success(f"âœ… è®°å½• {index_to_delete} å·²åˆ é™¤ï¼ŒæŒä»“å·²é‡æ–°è®¡ç®—ã€‚")
                    time.sleep(1)
                    st.cache_data.clear() 
                    st.rerun()
                else:
                    st.error("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")

        st.markdown("---")
        
        # --- ä¿®æ”¹æ“ä½œ (ä»…æ”¯æŒä¿®æ”¹ä»·æ ¼/æ—¥æœŸ/ç±»å‹/ä»½æ•°) ---
        st.subheader("ä¿®æ”¹è®°å½•")
        
        df_selected_m = full_data_frames.get(selected_file_m)
        if df_selected_m is None:
            st.error("æ— æ³•è·å–æŒ‡æ•°æ•°æ®ï¼Œæ— æ³•è¿›è¡Œä¿®æ”¹ã€‚è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ã€‚")
        else:
            col_mod_index, col_mod_type, col_mod_date, col_mod_price = st.columns(4)
            
            # 1. é€‰æ‹©è¦ä¿®æ”¹çš„ç´¢å¼•
            with col_mod_index:
                index_to_modify = st.number_input("è¾“å…¥è¦ä¿®æ”¹çš„è®°å½•è¡Œç´¢å¼•", min_value=0, max_value=len(history_df_m) - 1, step=1, key="modify_index")
            
            if 0 <= index_to_modify < len(s_m['history']):
                record_to_modify = s_m['history'][index_to_modify]
                
                # 2. ä¿®æ”¹æ“ä½œç±»å‹
                with col_mod_type:
                    new_type = st.selectbox("æ–°æ“ä½œç±»å‹", ["ä¹°å…¥", "å–å‡º"], index=0 if record_to_modify.get('type') == 'ä¹°å…¥' else 1, key="modify_type")

                # 3. ä¿®æ”¹æˆäº¤æ—¥æœŸ
                with col_mod_date:
                    try:
                        current_date = datetime.strptime(record_to_modify.get('date'), "%Y-%m-%d").date()
                    except:
                         current_date = datetime.now().date()
                    new_date = st.date_input("æ–°æˆäº¤æ—¥æœŸ", value=current_date, max_value=datetime.now().date(), key="modify_date")
                    new_date_str = new_date.strftime("%Y-%m-%d")

                # 4. ä¿®æ”¹ ETF ä»·æ ¼å’Œä»½æ•°
                with col_mod_price:
                    new_price = st.number_input("æ–°ETFæˆäº¤ä»·", min_value=0.0001, format="%.4f", value=record_to_modify.get('price', 1.0000), step=0.0001, key="modify_price")
                new_unit = st.number_input("æ–°äº¤æ˜“ä»½æ•°", min_value=1, value=record_to_modify.get('unit', 1), step=1, key="modify_unit")

                if st.button(f"ğŸŸ¡ ç¡®è®¤ä¿®æ”¹ç¬¬ {index_to_modify} è¡Œè®°å½•", key="confirm_modify_button"):
                    
                    # V22.0: é‡æ–°æŸ¥æ‰¾æ–°çš„ PE/Close (ä½¿ç”¨æ”¹è¿›çš„ find_pe_by_date)
                    trade_pe_mod, trade_close_mod = find_pe_by_date(df_selected_m, new_date_str)
                    saved_pe_mod = round(trade_pe_mod, 2) if not np.isnan(trade_pe_mod) else None
                    saved_close_mod = round(trade_close_mod, 2) if not np.isnan(trade_close_mod) else None

                    # æ›´æ–°è®°å½•
                    s_m['history'][index_to_modify] = {
                        "date": new_date_str,
                        "type": new_type,
                        "pe": saved_pe_mod, 
                        "close": saved_close_mod,
                        "price": new_price, 
                        "unit": new_unit
                    }

                    state = recalculate_holdings_and_cost(state) # ç«‹å³é‡æ–°è®¡ç®—
                    save_state(state)
                    st.success(f"âœ… è®°å½• {index_to_modify} å·²æ›´æ–°å¹¶é‡æ–°è®¡ç®—æŒä»“ã€‚")
                    time.sleep(1)
                    st.cache_data.clear() 
                    st.rerun()
            else:
                st.error("ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚")
